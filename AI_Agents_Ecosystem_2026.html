<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Title</th>
      <th>Source</th>
      <th>Date</th>
      <th>Description</th>
      <th>Link</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Client Support Specialist at Clipboard Health</td>
      <td>RemoteJob</td>
      <td>2026-01-16</td>
      <td>About the Role\n \nClipboard Health is looking for highly motivated, customer-focused individuals to join our team as B2B Support Specialists (Workplace Support Agents). This is not a traditional call center role—you will be the frontline specialist for our most valuable business clients, our workplace customers. Your job is to proactively solve client issues, prevent churn, and ensure a seamless experience for our customers. \nThis is primarily a voice-based role, with additional responsibilities</td>
      <td>https://remotive.com/remote-jobs/customer-service/client-support-specialist-2086826</td>
    </tr>
    <tr>
      <td>Senior Independent AI Engineer / Architect at A.Team</td>
      <td>RemoteJob</td>
      <td>2026-01-16</td>
      <td>Location: Americas, Europe, or Israel\nThe Opportunity\nJoin A.Team’s invite-only network of senior builders and access exclusive missions with Fortune 500s and top startups. This isn’t client work or employment—it’s a vetted collective where you’re matched to impactful projects.At A.Team, you won’t just implement someone else’s plan. You’ll be the technical decision-maker, owning everything from model design to enterprise integration.\nWhy A.Team\n\n\nElite peers: ex-OpenAI, Google, Meta, Amazon.\n\n\nP</td>
      <td>https://remotive.com/remote-jobs/software-development/senior-independent-ai-engineer-architect-1919266</td>
    </tr>
    <tr>
      <td>Senior Independent Software Developer at A.Team</td>
      <td>RemoteJob</td>
      <td>2026-01-16</td>
      <td>You must be located in the Americas, Europe, or Israel to apply.A·Team is a VC-backed, stealth, application-only home on the internet for senior independent software builders to team up with hand-picked, high-growth companies on their next big thing. \nAfter talking with hundreds of independent engineers, designers, and product folks, we heard over and over that finding vetted, high-quality, consistent clients is hard, and projects are often too small to be rewarding. A·Team matches small teams o</td>
      <td>https://remotive.com/remote-jobs/software-development/senior-independent-software-developer-1919265</td>
    </tr>
    <tr>
      <td>Show HN: Gambit, an open-source agent harness for building reliable AI agents</td>
      <td>HackerNews</td>
      <td>2026-01-16</td>
      <td>Hey HN!&lt;p&gt;Wanted to show our open source agent harness called Gambit.&lt;p&gt;If you’re not familiar, agent harnesses are sort of like an operating system for an agent... they handle tool calling, planning, context window management, and don’t require as much developer orchestration.&lt;p&gt;Normally you might see an agent orchestration framework pipeline like:&lt;p&gt;compute -&amp;gt; compute -&amp;gt; compute -&amp;gt; LLM -&amp;gt; compute -&amp;gt; compute -&amp;gt; LLM&lt;p&gt;we invert this so with an agent harness, it’s more like:&lt;p&gt;L</td>
      <td>https://github.com/bolt-foundry/gambit</td>
    </tr>
    <tr>
      <td>Show HN: Use-AI: trivially add AI automation to react apps</td>
      <td>HackerNews</td>
      <td>2026-01-16</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://github.com/meetsmore/use-ai</td>
    </tr>
    <tr>
      <td>Two dimensional covering systems and possible prime producing $a^m-b^n$</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We exhibit a new application of two dimensional covering systems, examples of integer pairs $a,b$ for which $a^m-b^n$ has a prime divisor from some given finite set of primes, for every pair of integers $m,n\geq 0$. This leads us to conjecture what are the only possible obstructions to $|a^m-b^n|$ taking on infinitely many distinct prime values.</td>
      <td>http://arxiv.org/abs/2601.10296v1</td>
    </tr>
    <tr>
      <td>On gradient stability in nonlinear PDE models and inference in interacting particle systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We consider general parameter to solution maps $θ\mapsto \mathcal G(θ)$ of non-linear partial differential equations and describe an approach based on a Banach space version of the implicit function theorem to verify the gradient stability condition of Nickl&amp;Wang (JEMS 2024) for the underlying non-linear inverse problem, providing also injectivity estimates and corresponding statistical identifiability results. We illustrate our methods in two examples involving a non-linear reaction diffusion s</td>
      <td>http://arxiv.org/abs/2601.10326v1</td>
    </tr>
    <tr>
      <td>Principles of Optics in the Fock Space: Scalable Manipulation of Giant Quantum States</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The manipulation of distinct degrees of freedom of photons plays a critical role in both classical and quantum information processing. While the principles of wave optics provide elegant and scalable control over classical light in spatial and temporal domains, engineering quantum states in Fock space has been largely restricted to few-photon regimes, hindered by the computational and experimental challenges of large Hilbert spaces. Here, we introduce ``Fock-space optics", establishing a concept</td>
      <td>http://arxiv.org/abs/2601.10325v1</td>
    </tr>
    <tr>
      <td>SRAW-Attack: Space-Reweighted Adversarial Warping Attack for SAR Target Recognition</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Synthetic aperture radar (SAR) imagery exhibits intrinsic information sparsity due to its unique electromagnetic scattering mechanism. Despite the widespread adoption of deep neural network (DNN)-based SAR automatic target recognition (SAR-ATR) systems, they remain vulnerable to adversarial examples and tend to over-rely on background regions, leading to degraded adversarial robustness. Existing adversarial attacks for SAR-ATR often require visually perceptible distortions to achieve effective p</td>
      <td>http://arxiv.org/abs/2601.10324v1</td>
    </tr>
    <tr>
      <td>Conjugate Gradient Methods are Not Efficient: Experimental Study of the Locality Limitation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The convergence of the Conjugate Gradient method is subject to a locality limitation which imposes a lower bound on the number of iterations required before a qualitatively accurate approximation can be obtained. This limitation originates from the restricted transport of information in the graph induced by the sparsity pattern of the system matrix. In each iteration, information from the right-hand side can propagate only across directly connected graph nodes. The diameter of this graph therefo</td>
      <td>http://arxiv.org/abs/2601.10322v1</td>
    </tr>
    <tr>
      <td>Addition to the dynamic Stark shift of the coherent population trapping resonance</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This paper presents a theoretical study of the light-induced shift of the coherent population trapping resonance. An analytical model is proposed that describes the interaction of two radiation components with an atomic system using a $Λ$ scheme and takes into account an additional level of excited state. Both weak and strong coupling regimes with off-resonant transitions are considered. It is shown that, in addition to the conventional dynamic Stark shift, an extra shift arises due to the disto</td>
      <td>http://arxiv.org/abs/2601.10319v1</td>
    </tr>
    <tr>
      <td>ADVOSYNTH: A Synthetic Multi-Advocate Dataset for Speaker Identification in Courtroom Scenarios</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>As large-scale speech-to-speech models achieve high fidelity, the distinction between synthetic voices in structured environments becomes a vital area of study. This paper introduces Advosynth-500, a specialized dataset comprising 100 synthetic speech files featuring 10 unique advocate identities. Using the Speech Llama Omni model, we simulate five distinct advocate pairs engaged in courtroom arguments. We define specific vocal characteristics for each advocate and present a speaker identificati</td>
      <td>http://arxiv.org/abs/2601.10315v1</td>
    </tr>
    <tr>
      <td>Quantum Monte Carlo study of systems interacting via long-range interactions mediated by a cavity</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We study one-dimensional quantum gases in continuous space with cavity-mediated infinite-range interactions using variational and diffusion Monte Carlo methods. Starting from the exact two-body solution, we construct a non-translationally invariant Jastrow wavefunction that accurately captures the spatial structure induced by the cavity field and provides an efficient many-body ansatz for both bosonic and fermionic systems. We analize properties of three characteristic quantum systems, subject t</td>
      <td>http://arxiv.org/abs/2601.10301v1</td>
    </tr>
    <tr>
      <td>Grounding Agent Memory in Contextual Intent</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Deploying large language models in long-horizon, goal-oriented interactions remains challenging because similar entities and facts recur under different latent goals and constraints, causing memory systems to retrieve context-mismatched evidence. We propose STITCH (Structured Intent Tracking in Contextual History), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step's intent. Contextual</td>
      <td>http://arxiv.org/abs/2601.10702v1</td>
    </tr>
    <tr>
      <td>Computer Generation of Disordered Networks with Targeted Structural Properties</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Disordered spatial networks are model systems that describe structures and interactions across multiple length scales. Scattering and interference of waves in these networks can give rise to structural phase transitions, localization, diffusion, and band gaps. The study of these complex phenomena requires efficient numerical methods to computer-generate disordered networks with targeted structural properties. In the established Wooten-Weaire-Winer algorithm, a series of bond switch moves introdu</td>
      <td>http://arxiv.org/abs/2601.10333v1</td>
    </tr>
    <tr>
      <td>Updated electrical design of the Diagnostic Neutral Beam Injector in RFX-mod2</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The Diagnostic Neutral Beam Injector of the RFX-mod2 experiment (Consorzio RFX, Padova) is expected to provide novel and significant information about the Reversed Field Pinch confinement of fusion plasmas. The injection of the hydrogen beam in the plasma will allow Charge Exchange Recombination Spectroscopy (CXRS) and Motional Stark Effect diagnostics (MSE) to measure several quantities: ion speed, ion temperature, impurity content, intensity and pitch of the magnetic field. The DNBI is of part</td>
      <td>http://arxiv.org/abs/2601.10293v1</td>
    </tr>
    <tr>
      <td>Single-Feed Circularly Polarized Super Realized Gain Antenna</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This paper presents a super realized gain, circularly polarized strip-crossed dipole antenna operating at 3.5 GHz. Superdirective behavior is achieved by leveraging strong inter-element mutual coupling through careful adjustment of the strip dimensions. The antenna features a single driven element, with the other element passively loaded with a reactive impedance. The structure is optimized to maximize left-hand circularly polarized (LHCP) realized gain, ensuring high polarization purity and goo</td>
      <td>http://arxiv.org/abs/2601.10292v1</td>
    </tr>
    <tr>
      <td>High-Contrast Transmission Resonances for the Lamé System</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We consider the Lamé transmission problem in $\mathbb{R}^3$ with a bounded isotropic elastic inclusion in a high-contrast setting, where the interior-to-exterior Lamé moduli and densities scale like $1/τ$ as $τ\to0$. We study the scattering resonances of the associated self-adjoint Hamiltonian, defined as the poles of the meromorphic continuation of its resolvent. We obtain a sharp asymptotic description of resonances near the real axis as $τ\to0$. Near each nonzero Neumann eigenvalue of the int</td>
      <td>http://arxiv.org/abs/2601.10290v1</td>
    </tr>
    <tr>
      <td>SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Physics-Informed Neural Networks (PINNs) provide a mesh-free approach for solving differential equations by embedding physical constraints into neural network training. However, PINNs tend to overfit within the training domain, leading to poor generalization when extrapolating beyond trained spatiotemporal regions. This work presents SPIKE (Sparse Physics-Informed Koopman-Enhanced), a framework that regularizes PINNs with continuous-time Koopman operators to learn parsimonious dynamics represent</td>
      <td>http://arxiv.org/abs/2601.10282v1</td>
    </tr>
    <tr>
      <td>Optimal control of a dissipative micromaser quantum battery in the ultrastrong coupling regime</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We investigate the open system dynamics of a micromaser quantum battery operating in the ultrastrong coupling (USC) regime under environmental dissipation. The battery consists of a single-mode electromagnetic cavity sequentially interacting, via the Rabi Hamiltonian, with a stream of qubits acting as chargers. Dissipative effects arise from the weak coupling of the qubit-cavity system to a thermal bath. Non-negligible in the USC regime, the counter-rotating terms substantially improve the charg</td>
      <td>http://arxiv.org/abs/2601.10281v1</td>
    </tr>
    <tr>
      <td>SCRamble: Adaptive Decentralized Overlay Construction for Blockchain Networks</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Despite being under development for over 15 years, transaction throughput remains one of the key challenges confronting blockchains, which typically has a cap of a limited number of transactions per second. A fundamental factor limiting this metric is the network latency associated with the block propagation throughout of the underlying peer-to-peer network, typically formed through random connections. Accelerating the dissemination of blocks not only improves transaction rates, but also enhance</td>
      <td>http://arxiv.org/abs/2601.10277v1</td>
    </tr>
    <tr>
      <td>Take Out Your Calculators: Estimating the Real Difficulty of Question Items with LLM Student Simulations</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Standardized math assessments require expensive human pilot studies to establish the difficulty of test items. We investigate the predictive value of open-source large language models (LLMs) for evaluating the difficulty of multiple-choice math questions for real-world students. We show that, while LLMs are poor direct judges of problem difficulty, simulation-based approaches with LLMs yield promising results under the right conditions. Under the proposed approach, we simulate a "classroom" of 4</td>
      <td>http://arxiv.org/abs/2601.09953v1</td>
    </tr>
    <tr>
      <td>Low-Complexity Blind Estimator of SNR and MSE for mmWave Multi-Antenna Communications</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>To enhance the robustness and resilience of wireless communication and meet performance requirements, various environment-reflecting metrics, such as the signal-to-noise ratio (SNR), are utilized as the system parameter. To obtain these metrics, training signals such as pilot sequences are generally employed. However, the rapid fluctuations of the millimeter-wave (mmWave) propagation channel often degrade the accuracy of such estimations. To address this challenge, various blind estimators that</td>
      <td>http://arxiv.org/abs/2601.10331v1</td>
    </tr>
    <tr>
      <td>Enhanced multi-parameter metrology in dissipative Rydberg atom time crystals</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The pursuit of unprecedented sensitivity in quantum enhanced metrology has spurred interest in non-equilibrium quantum phases of matter and their symmetry breaking. In particular, criticality-enhanced metrology through time-translation symmetry breaking in many-body systems, a distinct paradigm compared to spatial symmetry breaking, is a field still in its infancy. Here, we have investigated the enhanced sensing at the boundary of a continuous time-crystal (CTC) phase in a driven Rydberg atomic</td>
      <td>http://arxiv.org/abs/2601.10347v1</td>
    </tr>
    <tr>
      <td>Distinguishing Quantum Matter by Gravity with Differential Scattering Cross Section at Tree Level</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The definition of weak equivalence principle of quantum matter is an open problem at present. In order to reflect the probability of quantum system in the quantum version of weak equivalence principle, we proposed a quantum weak equivalence principle based on differential scattering cross section at tree level, that is, the differential scattering cross section does not depend on the mass and properties of the scattered particles when the target particles take the large mass limit. This version</td>
      <td>http://arxiv.org/abs/2601.10339v1</td>
    </tr>
    <tr>
      <td>Long Period Transients (LPTs): a comprehensive review</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Long Period Transients (LPTs) are a recently identified class of sources characterized by periodic radio bursts lasting seconds to minutes, with flux densities that might reach several tens of Jy. These radio bursts repeat with periodicity from minutes to hours, and they exhibit strong polarization and transient activity periods. To date, about 12 such sources have been identified, which might encompass the same or different physical scenarios. Proposed explanations include binary systems with a</td>
      <td>http://arxiv.org/abs/2601.10393v1</td>
    </tr>
    <tr>
      <td>Enhancing the quality of gauge images captured in smoke and haze scenes through deep learning</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Images captured in hazy and smoky environments suffer from reduced visibility, posing a challenge when monitoring infrastructures and hindering emergency services during critical situations. The proposed work investigates the use of the deep learning models to enhance the automatic, machine-based readability of gauge in smoky environments, with accurate gauge data interpretation serving as a valuable tool for first responders. The study utilizes two deep learning architectures, FFA-Net and AECR-</td>
      <td>http://arxiv.org/abs/2601.10537v1</td>
    </tr>
    <tr>
      <td>DeepUrban: Interaction-Aware Trajectory Prediction and Planning for Automated Driving by Aerial Imagery</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The efficacy of autonomous driving systems hinges critically on robust prediction and planning capabilities. However, current benchmarks are impeded by a notable scarcity of scenarios featuring dense traffic, which is essential for understanding and modeling complex interactions among road users. To address this gap, we collaborated with our industrial partner, DeepScenario, to develop DeepUrban-a new drone dataset designed to enhance trajectory prediction and planning benchmarks focusing on den</td>
      <td>http://arxiv.org/abs/2601.10554v1</td>
    </tr>
    <tr>
      <td>Late-time acceleration without a vacuum term in ${f(R,L_m)}$ gravity: scaling deSitter dynamics and parameter constraints</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We investigate late-time cosmic acceleration in $f(R,L_m)$ gravity driven by nonlinear matter contributions, focusing on the class $f(R,L_m)=R/2+c_1 L_m+c_n L_m^{n}+c_0$ with the explicit choice $L_m=ρ_m$ and an uncoupled radiation sector. We analyze two realizations: (i) Case A: $f(R,L_m)=R/2+βρ_m^{n}+γ$, where $γ$ acts as a vacuum term, and (ii) Case B: $f(R,L_m)=R/2+βρ_m+γρ_m^{n}$, where the nonlinear sector can mimic dark energy without an explicit cosmological constant. For each case, we co</td>
      <td>http://arxiv.org/abs/2601.10699v1</td>
    </tr>
    <tr>
      <td>See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors highly redundant. We quantify redundancy in such (BLIP2) features via PCA and cross-patch similarity: $90$%</td>
      <td>http://arxiv.org/abs/2601.10707v1</td>
    </tr>
    <tr>
      <td>A Geometric Multigrid Preconditioner for Shifted Boundary Method</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The Shifted Boundary Method (SBM) trades some part of the burden of body-fitted meshing for increased algebraic complexity. While the resulting linear systems retain the standard $\mathcal{O}(h^{-2})$ conditioning of second-order operators, the non-symmetry and non-local boundary coupling render them resistant to standard Algebraic Multigrid (AMG) and simple smoothers for high-order discretisations. We present a geometric multigrid preconditioner that effectively tames these systems. At its core</td>
      <td>http://arxiv.org/abs/2601.10399v1</td>
    </tr>
    <tr>
      <td>Multiaccess Coded Caching with Heterogeneous Retrieval Costs</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The multiaccess coded caching (MACC) system, as formulated by Hachem {\it et al.}, consists of a central server with a library of $N$ files, connected to $K$ cache-less users via an error-free shared link, and $K$ cache nodes, each equipped with cache memory of size $M$ files. Each user can access $L$ neighboring cache nodes under a cyclic wrap-around topology. Most existing studies operate under the strong assumption that users can retrieve content from their connected cache nodes at no communi</td>
      <td>http://arxiv.org/abs/2601.10394v1</td>
    </tr>
    <tr>
      <td>Codebook Design for Limited Feedback in Near-Field XL-MIMO Systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In this paper, we study efficient codebook design for limited feedback in extremely large-scale multiple-input-multiple-output (XL-MIMO) frequency division duplexing (FDD) systems. It is worth noting that existing codebook designs for XL-MIMO, such as polar-domain codebook, have not well taken into account user (location) distribution in practice, thereby incurring excessive feedback overhead. To address this issue, we propose in this paper a novel and efficient feedback codebook tailored to use</td>
      <td>http://arxiv.org/abs/2601.10391v1</td>
    </tr>
    <tr>
      <td>Convertible Codes for Data and Device Heterogeneity</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Distributed storage systems must handle both data heterogeneity, arising from non-uniform access demands, and device heterogeneity, caused by time-varying node reliability. In this paper, we study convertible codes, which enable the transformation of one code into another with minimum cost in the merge regime, addressing the latter. We derive general lower bounds on the read and write costs of linear code conversion, applicable to arbitrary linear codes. We then focus on Reed-Muller codes, which</td>
      <td>http://arxiv.org/abs/2601.10341v1</td>
    </tr>
    <tr>
      <td>Learning Hamiltonians in the Heisenberg limit with static single-qubit fields</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Learning the Hamiltonian governing a quantum system is a central task in quantum metrology, sensing, and device characterization. Existing Heisenberg-limited Hamiltonian learning protocols either require multi-qubit operations that are prone to noise, or single-qubit operations whose frequency or strength increases with the desired precision. These two requirements limit the applicability of Hamiltonian learning on near-term quantum platforms. We present a protocol that learns a quantum Hamilton</td>
      <td>http://arxiv.org/abs/2601.10380v1</td>
    </tr>
    <tr>
      <td>Online identification of nonlinear time-varying systems with uncertain information</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Digital twins (DTs), serving as the core enablers for real-time monitoring and predictive maintenance of complex cyber-physical systems, impose critical requirements on their virtual models: high predictive accuracy, strong interpretability, and online adaptive capability. However, existing techniques struggle to meet these demands simultaneously: Bayesian methods excel in uncertainty quantification but lack model interpretability, while interpretable symbolic identification methods (e.g., SINDy</td>
      <td>http://arxiv.org/abs/2601.10379v1</td>
    </tr>
    <tr>
      <td>Capillary Slinky: Equilibrium and Dynamics of Droplets in a Soft Spring</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Springs can be found in many applications and biological systems, and when these are soft, they easily deform. At small scales, capillarity can induce a force leading to spring deformations when the elastocapillary number is small. We demonstrate through experiments the non-trivial equilibrium shape liquid droplets adopt in these soft springs, which form an annulus, Eruciform, and spherical shapes. When these droplets are set in motion, they display different flow regimes with significant dissip</td>
      <td>http://arxiv.org/abs/2601.10366v1</td>
    </tr>
    <tr>
      <td>On UC-multipliers for multiple trigonometric systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We investigate the class of sequences $w(n)$ that can serve as almost-everywhere convergence Weyl multipliers for all rearrangements of multiple trigonometric systems. We show that any such sequence must satisfy the bounds $\log n\lesssim w(n)\lesssim\log^2 n$. Our main result establishes a general equivalence principle between one-dimensional and multidimensional trigonometric systems, which allows one to extend certain estimates known for the one-dimensional case to higher dimensions.</td>
      <td>http://arxiv.org/abs/2601.10360v1</td>
    </tr>
    <tr>
      <td>A New Construction Structure on MISO Coded Caching with Linear Subpacketization: Half-Sum Disjoint Packing</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In the $(L,K,M,N)$ cache-aided multiple-input single-output (MISO) broadcast channel (BC) system, the server is equipped with $L$ antennas and communicates with $K$ single-antenna users through a wireless broadcast channel where the server has a library containing $N$ files, and each user is equipped with a cache of size $M$ files. Under the constraints of uncoded placement and one-shot linear delivery strategies, many schemes achieve the maximum sum Degree-of-Freedom (sum-DoF). However, for gen</td>
      <td>http://arxiv.org/abs/2601.10353v1</td>
    </tr>
    <tr>
      <td>SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Personalizing Large Language Models typically relies on static retrieval or one-time adaptation, assuming user preferences remain invariant over time. However, real-world interactions are dynamic, where user interests continuously evolve, posing a challenge for models to adapt to preference drift without catastrophic forgetting. Standard continual learning approaches often struggle in this context, as they indiscriminately update on noisy interaction streams, failing to distinguish genuine prefe</td>
      <td>http://arxiv.org/abs/2601.09974v1</td>
    </tr>
    <tr>
      <td>An Exploratory Study to Repurpose LLMs to a Unified Architecture for Time Series Classification</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Time series classification (TSC) is a core machine learning problem with broad applications. Recently there has been growing interest in repurposing large language models (LLMs) for TSC, motivated by their strong reasoning and generalization ability. Prior work has primarily focused on alignment strategies that explicitly map time series data into the textual domain; however, the choice of time series encoder architecture remains underexplored. In this work, we conduct an exploratory study of hy</td>
      <td>http://arxiv.org/abs/2601.09971v1</td>
    </tr>
    <tr>
      <td>Context Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Neural Machine Translation (NMT) models for low-resource languages suffer significant performance degradation under domain shift. We quantify this challenge using Dhao, an indigenous language of Eastern Indonesia with no digital footprint beyond the New Testament (NT). When applied to the unseen Old Testament (OT), a standard NMT model fine-tuned on the NT drops from an in-domain score of 36.17 chrF++ to 27.11 chrF++. To recover this loss, we introduce a hybrid framework where a fine-tuned NMT m</td>
      <td>http://arxiv.org/abs/2601.09982v1</td>
    </tr>
    <tr>
      <td>LangLasso: Interactive Cluster Descriptions through LLM Explanation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Dimensionality reduction is a powerful technique for revealing structure and potential clusters in data. However, as the axes are complex, non-linear combinations of features, they often lack semantic interpretability. Existing visual analytics (VA) methods support cluster interpretation through feature comparison and interactive exploration, but they require technical expertise and intense human effort. We present \textit{LangLasso}, a novel method that complements VA approaches through interac</td>
      <td>http://arxiv.org/abs/2601.10458v1</td>
    </tr>
    <tr>
      <td>GeoSteer: Faithful Chain-of-Thought Steering via Latent Manifold Gradients</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Recent advances in Large Language Models (LLMs) have improved multi-step reasoning. Most approaches rely on Chain-of-Thought (CoT) rationales. Previous studies have shown that LLMs often generate logically inconsistent reasoning steps even when their final answers are correct. These inconsistencies reduce the reliability of step-level reasoning. We propose GeoSteer, a manifold-based framework that improves the quality of intermediate reasoning. The method consists of: (1) constructing a CoT data</td>
      <td>http://arxiv.org/abs/2601.10229v1</td>
    </tr>
    <tr>
      <td>TRIM: Hybrid Inference via Targeted Stepwise Routing in Multi-Step Reasoning Tasks</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Multi-step reasoning tasks like mathematical problem solving are vulnerable to cascading failures, where a single incorrect step leads to complete solution breakdown. Current LLM routing methods assign entire queries to one model, treating all reasoning steps as equal. We propose TRIM (Targeted routing in multi-step reasoning tasks), which routes only critical steps$\unicode{x2013}$those likely to derail the solution$\unicode{x2013}$to larger models while letting smaller models handle routine co</td>
      <td>http://arxiv.org/abs/2601.10245v1</td>
    </tr>
    <tr>
      <td>NoReGeo: Non-Reasoning Geometry Benchmark</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We present NoReGeo, a novel benchmark designed to evaluate the intrinsic geometric understanding of large language models (LLMs) without relying on reasoning or algebraic computation. Unlike existing benchmarks that primarily assess models' proficiency in reasoning-based geometry-where solutions are derived using algebraic methods-NoReGeo focuses on evaluating whether LLMs can inherently encode spatial relationships and recognize geometric properties directly. Our benchmark comprises 2,500 trivi</td>
      <td>http://arxiv.org/abs/2601.10254v1</td>
    </tr>
    <tr>
      <td>Untangling Input Language from Reasoning Language: A Diagnostic Framework for Cross-Lingual Moral Alignment in LLMs</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>When LLMs judge moral dilemmas, do they reach different conclusions in different languages, and if so, why? Two factors could drive such differences: the language of the dilemma itself, or the language in which the model reasons. Standard evaluation conflates these by testing only matched conditions (e.g., English dilemma with English reasoning). We introduce a methodology that separately manipulates each factor, covering also mismatched conditions (e.g., English dilemma with Chinese reasoning),</td>
      <td>http://arxiv.org/abs/2601.10257v1</td>
    </tr>
    <tr>
      <td>In-Context Source and Channel Coding</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Separate Source-Channel Coding (SSCC) remains attractive for text transmission due to its modularity and compatibility with mature entropy coders and powerful channel codes. However, SSCC often suffers from a pronounced cliff effect in low Signal-to-Noise Ratio (SNR) regimes, where residual bit errors after channel decoding can catastrophically break lossless source decoding, especially for Arithmetic Coding (AC) driven by Large Language Models (LLMs). This paper proposes a receiver-side In-Cont</td>
      <td>http://arxiv.org/abs/2601.10267v1</td>
    </tr>
    <tr>
      <td>Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We consider a single large language model (LLM) server that serves a heterogeneous stream of queries belonging to $N$ distinct task types. Queries arrive according to a Poisson process, and each type occurs with a known prior probability. For each task type, the server allocates a fixed number of internal thinking tokens, which determines the computational effort devoted to that query. The token allocation induces an accuracy-latency trade-off: the service time follows an approximately affine fu</td>
      <td>http://arxiv.org/abs/2601.10274v1</td>
    </tr>
    <tr>
      <td>Reasoning Hijacking: Subverting LLM Classification via Decision-Criteria Injection</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Current LLM safety research predominantly focuses on mitigating Goal Hijacking, preventing attackers from redirecting a model's high-level objective (e.g., from "summarizing emails" to "phishing users"). In this paper, we argue that this perspective is incomplete and highlight a critical vulnerability in Reasoning Alignment. We propose a new adversarial paradigm: Reasoning Hijacking and instantiate it with Criteria Attack, which subverts model judgments by injecting spurious decision criteria wi</td>
      <td>http://arxiv.org/abs/2601.10294v1</td>
    </tr>
    <tr>
      <td>Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>While Reinforcement Learning (RL) has advanced LLM reasoning, applying it to long-context scenarios is hindered by sparsity of outcome rewards. This limitation fails to penalize ungrounded "lucky guesses," leaving the critical process of needle-in-a-haystack evidence retrieval largely unsupervised. To address this, we propose EAPO (Evidence-Augmented Policy Optimization). We first establish the Evidence-Augmented Reasoning paradigm, validating via Tree-Structured Evidence Sampling that precise e</td>
      <td>http://arxiv.org/abs/2601.10306v1</td>
    </tr>
    <tr>
      <td>An Efficient Long-Context Ranking Architecture With Calibrated LLM Distillation: Application to Person-Job Fit</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Finding the most relevant person for a job proposal in real time is challenging, especially when resumes are long, structured, and multilingual. In this paper, we propose a re-ranking model based on a new generation of late cross-attention architecture, that decomposes both resumes and project briefs to efficiently handle long-context inputs with minimal computational overhead. To mitigate historical data biases, we use a generative large language model (LLM) as a teacher, generating fine-graine</td>
      <td>http://arxiv.org/abs/2601.10321v1</td>
    </tr>
    <tr>
      <td>Think-Then-Generate: Reasoning-Aware Text-to-Image Diffusion with LLM Encoders</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Recent progress in text-to-image (T2I) diffusion models (DMs) has enabled high-quality visual synthesis from diverse textual prompts. Yet, most existing T2I DMs, even those equipped with large language model (LLM)-based text encoders, remain text-pixel mappers -- they employ LLMs merely as text encoders, without leveraging their inherent reasoning capabilities to infer what should be visually depicted given the textual prompt. To move beyond such literal generation, we propose the think-then-gen</td>
      <td>http://arxiv.org/abs/2601.10332v1</td>
    </tr>
    <tr>
      <td>LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In LLM-based text-to-SQL systems, unanswerable and underspecified user queries may generate not only incorrect text but also executable programs that yield misleading results or violate safety constraints, posing a major barrier to safe deployment. Existing refusal strategies for such queries either rely on output-level instruction following, which is brittle due to model hallucinations, or estimate output uncertainty, which adds complexity and overhead. To address this challenge, we formalize s</td>
      <td>http://arxiv.org/abs/2601.10398v1</td>
    </tr>
    <tr>
      <td>ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. However, existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit</td>
      <td>http://arxiv.org/abs/2601.10406v1</td>
    </tr>
    <tr>
      <td>TF3-RO-50M: Training Compact Romanian Language Models from Scratch on Synthetic Moral Microfiction</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Recent advances in synthetic data generation have shown that compact language models can be trained effectively when the underlying corpus is structurally controlled and linguistically coherent. However, for morphologically rich and computationally under-resourced languages such as Romanian, there is still no openly documented, end-to-end pipeline that unifies tokenizer design, preprocessing, pretraining, compression, evaluation, and large-scale synthetic data generation in a reproducible framew</td>
      <td>http://arxiv.org/abs/2601.10410v1</td>
    </tr>
    <tr>
      <td>LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Privacy policies help inform people about organisations' personal data processing practices, covering different aspects such as data collection, data storage, and sharing of personal data with third parties. Privacy policies are often difficult for people to fully comprehend due to the lengthy and complex legal language used and inconsistent practices across different sectors and organisations. To help conduct automated and large-scale analyses of privacy policies, many researchers have studied</td>
      <td>http://arxiv.org/abs/2601.10413v1</td>
    </tr>
    <tr>
      <td>LLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Aligning Large Language Models (LLMs) with human preferences is critical, yet traditional fine-tuning methods are computationally expensive and inflexible. While test-time alignment offers a promising alternative, existing approaches often rely on distorted trajectory-level signals or inefficient sampling, fundamentally capping performance and failing to preserve the generative diversity of the base model. This paper introduces LLMdoctor, a novel framework for efficient test-time alignment that</td>
      <td>http://arxiv.org/abs/2601.10416v1</td>
    </tr>
    <tr>
      <td>Are Language Models Models?</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Futrell and Mahowald claim LMs "serve as model systems", but an assessment at each of Marr's three levels suggests the claim is clearly not true at the implementation level, poorly motivated at the algorithmic-representational level, and problematic at the computational theory level. LMs are good candidates as tools; calling them cognitive models overstates the case and unnecessarily feeds LLM hype.</td>
      <td>http://arxiv.org/abs/2601.10421v1</td>
    </tr>
    <tr>
      <td>Alertissimo -- a tool for orchestration of LSST broker streams</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The Vera C. Rubin Observatory, through its Legacy Survey of Space and Time, will soon start producing 10 million alerts on transient astronomical objects per night. Due to logistics and bandwidth, alerts will not be dispatched directly to the public but to 'brokers' i.e. tools selected by LSST to handle alert streams. Brokers offer both common, specific and micro-specific functionalities related to alert handling, analysis, representation and dissemination. In this ecosystem, potentially augment</td>
      <td>http://arxiv.org/abs/2601.10454v1</td>
    </tr>
    <tr>
      <td>SurgGoal: Rethinking Surgical Planning Evaluation via Goal-Satisfiability</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Surgical planning integrates visual perception, long-horizon reasoning, and procedural knowledge, yet it remains unclear whether current evaluation protocols reliably assess vision-language models (VLMs) in safety-critical settings. Motivated by a goal-oriented view of surgical planning, we define planning correctness via phase-goal satisfiability, where plan validity is determined by expert-defined surgical rules. Based on this definition, we introduce a multicentric meta-evaluation benchmark w</td>
      <td>http://arxiv.org/abs/2601.10455v1</td>
    </tr>
    <tr>
      <td>Loop as a Bridge: Can Looped Transformers Truly Link Representation Space and Natural Language Outputs?</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) often exhibit a gap between their internal knowledge and their explicit linguistic outputs. In this report, we empirically investigate whether Looped Transformers (LTs)--architectures that increase computational depth by iterating shared layers--can bridge this gap by utilizing their iterative nature as a form of introspection. Our experiments reveal that while increasing loop iterations narrows the gap, it is partly driven by a degradation of their internal knowledg</td>
      <td>http://arxiv.org/abs/2601.10242v1</td>
    </tr>
    <tr>
      <td>Optimizing Multimodal LLMs for Egocentric Video Understanding: A Solution for the HD-EPIC VQA Challenge</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Multimodal Large Language Models (MLLMs) struggle with complex video QA benchmarks like HD-EPIC VQA due to ambiguous queries/options, poor long-range temporal reasoning, and non-standardized outputs. We propose a framework integrating query/choice pre-processing, domain-specific Qwen2.5-VL fine-tuning, a novel Temporal Chain-of-Thought (T-CoT) prompting for multi-step reasoning, and robust post-processing. This system achieves 41.6% accuracy on HD-EPIC VQA, highlighting the need for holistic pip</td>
      <td>http://arxiv.org/abs/2601.10228v1</td>
    </tr>
    <tr>
      <td>FaTRQ: Tiered Residual Quantization for LLM Vector Search in Far-Memory-Aware ANNS Systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Approximate Nearest-Neighbor Search (ANNS) is a key technique in retrieval-augmented generation (RAG), enabling rapid identification of the most relevant high-dimensional embeddings from massive vector databases. Modern ANNS engines accelerate this process using prebuilt indexes and store compressed vector-quantized representations in fast memory. However, they still rely on a costly second-pass refinement stage that reads full-precision vectors from slower storage like SSDs. For modern text and</td>
      <td>http://arxiv.org/abs/2601.09985v1</td>
    </tr>
    <tr>
      <td>PRL: Process Reward Learning Improves LLMs' Reasoning Ability and Broadens the Reasoning Boundary</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Improving the reasoning abilities of Large Language Models (LLMs) has been a continuous topic recently. But most relevant works are based on outcome rewards at the trajectory level, missing fine-grained supervision during the reasoning process. Other existing training frameworks that try to combine process signals together to optimize LLMs also rely heavily on tedious additional steps like MCTS, training a separate reward model, etc., doing harm to the training efficiency. Moreover, the intuitio</td>
      <td>http://arxiv.org/abs/2601.10201v1</td>
    </tr>
    <tr>
      <td>Towards Native Intelligence: 6G-LLM Trained with Reinforcement Learning from NDT Feedback</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Owing to its comprehensive understanding of upper-layer application requirements and the capabilities of practical communication systems, the 6G-LLM (6G domain large language model) offers a promising pathway toward realizing network native intelligence. Serving as the system orchestrator, the 6G-LLM drives a paradigm shift that fundamentally departs from existing rule-based approaches, which primarily rely on modular, experience-driven optimization. By contrast, the 6G-LLM substantially enhance</td>
      <td>http://arxiv.org/abs/2601.09992v1</td>
    </tr>
    <tr>
      <td>SocraticKG: Knowledge Graph Construction via QA-Driven Fact Extraction</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Constructing Knowledge Graphs (KGs) from unstructured text provides a structured framework for knowledge representation and reasoning, yet current LLM-based approaches struggle with a fundamental trade-off: factual coverage often leads to relational fragmentation, while premature consolidation causes information loss. To address this, we propose SocraticKG, an automated KG construction method that introduces question-answer pairs as a structured intermediate representation to systematically unfo</td>
      <td>http://arxiv.org/abs/2601.10003v1</td>
    </tr>
    <tr>
      <td>EmplifAI: a Fine-grained Dataset for Japanese Empathetic Medical Dialogues in 28 Emotion Labels</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This paper introduces EmplifAI, a Japanese empathetic dialogue dataset designed to support patients coping with chronic medical conditions. They often experience a wide range of positive and negative emotions (e.g., hope and despair) that shift across different stages of disease management. EmplifAI addresses this complexity by providing situation-based dialogues grounded in 28 fine-grained emotion categories, adapted and validated from the GoEmotions taxonomy. The dataset includes 280 medically</td>
      <td>http://arxiv.org/abs/2601.10033v1</td>
    </tr>
    <tr>
      <td>Instruction Finetuning LLaMA-3-8B Model Using LoRA for Financial Named Entity Recognition</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Particularly, financial named-entity recognition (NER) is one of the many important approaches to translate unformatted reports and news into structured knowledge graphs. However, free, easy-to-use large language models (LLMs) often fail to differentiate organisations as people, or disregard an actual monetary amount entirely. This paper takes Meta's Llama 3 8B and applies it to financial NER by combining instruction fine-tuning and Low-Rank Adaptation (LoRA). Each annotated sentence is converte</td>
      <td>http://arxiv.org/abs/2601.10043v1</td>
    </tr>
    <tr>
      <td>Unlabeled Data Can Provably Enhance In-Context Learning of Transformers</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large language models (LLMs) exhibit impressive in-context learning (ICL) capabilities, yet the quality of their predictions is fundamentally limited by the few costly labeled demonstrations that can fit into a prompt. Meanwhile, there exist vast and continuously growing amounts of unlabeled data that may be closely related to the ICL task. How to utilize such unlabeled data to provably enhance the performance of ICL thus becomes an emerging fundamental question. In this work, we propose a novel</td>
      <td>http://arxiv.org/abs/2601.10058v1</td>
    </tr>
    <tr>
      <td>Long-Chain Reasoning Distillation via Adaptive Prefix Alignment</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) have demonstrated remarkable reasoning capabilities, particularly in solving complex mathematical problems. Recent studies show that distilling long reasoning trajectories can effectively enhance the reasoning performance of small-scale student models. However, teacher-generated reasoning trajectories are often excessively long and structurally complex, making them difficult for student models to learn. This mismatch leads to a gap between the provided supervision si</td>
      <td>http://arxiv.org/abs/2601.10064v1</td>
    </tr>
    <tr>
      <td>Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Reinforcement Learning (RL) has become essential for eliciting complex reasoning capabilities in Large Language Models (LLMs). However, the substantial memory overhead of storing Key-Value (KV) caches during long-horizon rollouts acts as a critical bottleneck, often prohibiting efficient training on limited hardware. While existing KV compression techniques offer a remedy for inference, directly applying them to RL training induces a severe policy mismatch, leading to catastrophic performance co</td>
      <td>http://arxiv.org/abs/2601.10079v1</td>
    </tr>
    <tr>
      <td>MATRIX AS PLAN: Structured Logical Reasoning with Feedback-Driven Replanning</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>As knowledge and semantics on the web grow increasingly complex, enhancing Large Language Models (LLMs) comprehension and reasoning capabilities has become particularly important. Chain-of-Thought (CoT) prompting has been shown to enhance the reasoning capabilities of LLMs. However, it still falls short on logical reasoning tasks that rely on symbolic expressions and strict deductive rules. Neuro-symbolic methods address this gap by enforcing formal correctness through external solvers. Yet thes</td>
      <td>http://arxiv.org/abs/2601.10101v1</td>
    </tr>
    <tr>
      <td>Following the Teacher's Footsteps: Scheduled Checkpoint Distillation for Domain-Specific LLMs</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large language models (LLMs) are challenging to deploy for domain-specific tasks due to their massive scale. While distilling a fine-tuned LLM into a smaller student model is a promising alternative, the capacity gap between teacher and student often leads to suboptimal performance. This raises a key question: when and how can a student model match or even surpass its teacher on domain-specific tasks? In this work, we propose a novel theoretical insight: a student can outperform its teacher if i</td>
      <td>http://arxiv.org/abs/2601.10114v1</td>
    </tr>
    <tr>
      <td>A Generalizable Framework for Building Executable Domain-Specific LLMs under Data Scarcity: Demonstration on Semiconductor TCAD Simulation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Scientific and engineering verticals often suffer from data scarcity and strict executability requirements: models must generate not only fluent text, but also syntactically valid, tool-compilable scripts. We present a schema-first alignment framework for building compact, executable domain-specific LLMs in low-resource settings. The framework integrates three core components: (i) large-scale synthetic QA data generation from expert documentation to instill foundational domain knowledge; (ii) a</td>
      <td>http://arxiv.org/abs/2601.10128v1</td>
    </tr>
    <tr>
      <td>Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning and prediction across different domains. Yet, their ability to infer temporal regularities from structured behavioral data remains underexplored. This paper presents a systematic study investigating whether LLMs can predict time intervals between recurring user actions, such as repeated purchases, and how different levels of contextual information shape their predictive behavior. Using a simple but representative</td>
      <td>http://arxiv.org/abs/2601.10132v1</td>
    </tr>
    <tr>
      <td>Understanding and Preserving Safety in Fine-Tuned LLMs</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Fine-tuning is an essential and pervasive functionality for applying large language models (LLMs) to downstream tasks. However, it has the potential to substantially degrade safety alignment, e.g., by greatly increasing susceptibility to jailbreak attacks, even when the fine-tuning data is entirely harmless. Despite garnering growing attention in defense efforts during the fine-tuning stage, existing methods struggle with a persistent safety-utility dilemma: emphasizing safety compromises task p</td>
      <td>http://arxiv.org/abs/2601.10141v1</td>
    </tr>
    <tr>
      <td>Actors, Frames and Arguments: A Multi-Decade Computational Analysis of Climate Discourse in Financial News using Large Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Financial news media shapes trillion-dollar climate investment decisions, yet discourse in this elite domain remains underexplored. We analyze two decades of climate-related articles (2000-2023) from Dow Jones Newswire using an Actor-Frame-Argument (AFA) pipeline that extracts who speaks, how issues are framed, and which arguments are deployed. We validate extractions against 2,000 human-annotated articles using a Decompositional Verification Framework that evaluates completeness, faithfulness,</td>
      <td>http://arxiv.org/abs/2601.10142v1</td>
    </tr>
    <tr>
      <td>DecisionLLM: Large Language Models for Long Sequence Decision Exploration</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Long-sequence decision-making, which is usually addressed through reinforcement learning (RL), is a critical component for optimizing strategic operations in dynamic environments, such as real-time bidding in computational advertising. The Decision Transformer (DT) introduced a powerful paradigm by framing RL as an autoregressive sequence modeling problem. Concurrently, Large Language Models (LLMs) have demonstrated remarkable success in complex reasoning and planning tasks. This inspires us whe</td>
      <td>http://arxiv.org/abs/2601.10148v1</td>
    </tr>
    <tr>
      <td>What Gets Activated: Uncovering Domain and Driver Experts in MoE Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Most interpretability work focuses on layer- or neuron-level mechanisms in Transformers, leaving expert-level behavior in MoE LLMs underexplored. Motivated by functional specialization in the human brain, we analyze expert activation by distinguishing domain and driver experts. In this work, we study expert activation in MoE models across three public domains and address two key questions: (1) which experts are activated, and whether certain expert types exhibit consistent activation patterns; a</td>
      <td>http://arxiv.org/abs/2601.10159v1</td>
    </tr>
    <tr>
      <td>HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) have achieved remarkable strides in multilingual translation but are hindered by a systemic cross-lingual verbosity bias, rendering them unsuitable for strict time-constrained tasks like subtitling and dubbing. Current prompt-engineering approaches struggle to resolve this conflict between semantic fidelity and rigid temporal feasibility. To bridge this gap, we first introduce Sand-Glass, a benchmark specifically designed to evaluate translation under syllable-level</td>
      <td>http://arxiv.org/abs/2601.10187v1</td>
    </tr>
    <tr>
      <td>GFM4GA: Graph Foundation Model for Group Anomaly Detection</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Group anomaly detection is crucial in many network applications, but faces challenges due to diverse anomaly patterns. Motivated by the success of large language models (LLMs) in natural language processing, graph foundation models (GFMs) is proposed to handle few-shot learning task with fewer labeling efforts. GFMs have been successfully applied to detection of individual anomalies but cannot be generalized to group anomalies, as group anomaly patterns must be detected as a whole and individual</td>
      <td>http://arxiv.org/abs/2601.10193v1</td>
    </tr>
    <tr>
      <td>BikeActions: An Open Platform and Benchmark for Cyclist-Centric VRU Action Recognition</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Anticipating the intentions of Vulnerable Road Users (VRUs) is a critical challenge for safe autonomous driving (AD) and mobile robotics. While current research predominantly focuses on pedestrian crossing behaviors from a vehicle's perspective, interactions within dense shared spaces remain underexplored. To bridge this gap, we introduce FUSE-Bike, the first fully open perception platform of its kind. Equipped with two LiDARs, a camera, and GNSS, it facilitates high-fidelity, close-range data c</td>
      <td>http://arxiv.org/abs/2601.10521v1</td>
    </tr>
    <tr>
      <td>SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Online high-definition (HD) map construction is an essential part of a safe and robust end-to-end autonomous driving (AD) pipeline. Onboard camera-based approaches suffer from limited depth perception and degraded accuracy due to occlusion. In this work, we propose SatMap, an online vectorized HD map estimation method that integrates satellite maps with multi-view camera observations and directly predicts a vectorized HD map for downstream prediction and planning modules. Our method leverages la</td>
      <td>http://arxiv.org/abs/2601.10512v1</td>
    </tr>
    <tr>
      <td>CHORAL: Traversal-Aware Planning for Safe and Efficient Heterogeneous Multi-Robot Routing</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Monitoring large, unknown, and complex environments with autonomous robots poses significant navigation challenges, where deploying teams of heterogeneous robots with complementary capabilities can substantially improve both mission performance and feasibility. However, effectively modeling how different robotic platforms interact with the environment requires rich, semantic scene understanding. Despite this, existing approaches often assume homogeneous robot teams or focus on discrete task comp</td>
      <td>http://arxiv.org/abs/2601.10340v1</td>
    </tr>
    <tr>
      <td>Quantifying the properties of evolutionary quantum states of the XXZ spin model using quantum computing</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The entanglement distance of evolutionary quantum states of a two-spin system with the XXZ model has been studied. The analysis has been conducted both analytically and using quantum computing. An analytical dependence of the entanglement distance on the values of the model coupling constants and the parameters of the initial states has been obtained. The speed of evolution of a two-spin system has been investigated. The analysis has been performed analytically and using quantum computing. An ex</td>
      <td>http://arxiv.org/abs/2601.10650v1</td>
    </tr>
    <tr>
      <td>Counterdiabatic driving for random-gap Landau-Zener transitions</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The Landau--Zener (LZ) model describes a two-level quantum system that undergoes an avoided crossing. In the adiabatic limit, the transition probability vanishes. An auxiliary control field $H_\text{CD}$ can be reverse-engineered so that the full Hamiltonian $H_0 + H_\text{CD}$ reproduces adiabaticity for all parameter values. Our aim is to construct a single control field $H_1$ that drives an ensemble of LZ-type Hamiltonians with a distribution of energy gaps. $H_1$ works best statistically, mi</td>
      <td>http://arxiv.org/abs/2601.10659v1</td>
    </tr>
    <tr>
      <td>Safe Trajectory Gradient Flow Control of a Grid-Interfacing Inverter</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Grid-interfacing inverters serve as the interface between renewable energy resources and the electric power grid, offering fast, programmable control capabilities. However, their operation is constrained by hardware limitations, such as bounds on the current magnitude. Existing control methods for these systems often neglect these constraints during controller design and instead rely on ad hoc limiters, which can introduce instability or degrade performance. In this work, we present a control fr</td>
      <td>http://arxiv.org/abs/2601.10671v1</td>
    </tr>
    <tr>
      <td>Efficiency, Curvature, and Complexity of Quantum Evolutions for Qubits in Nonstationary Magnetic Fields</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In optimal quantum-mechanical evolutions, motion can take place along paths of minimal length within an optimal time frame. Alternatively, optimal evolutions may occur along established paths without any waste of energy resources and achieving 100% speed efficiency. Unfortunately, realistic physical scenarios often lead to less-than-ideal evolutions that demonstrate suboptimal efficiency, nonzero curvature, and a high level of complexity. In this paper, we provide an exact analytical expression</td>
      <td>http://arxiv.org/abs/2601.10672v1</td>
    </tr>
    <tr>
      <td>Breaking the Storage-Bandwidth Tradeoff in Distributed Storage with Quantum Entanglement</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This work investigates the use of quantum resources in distributed storage systems. Consider an $(n,k,d)$ distributed storage system in which a file is stored across $n$ nodes such that any $k$ nodes suffice to reconstruct the file. When a node fails, any $d$ helper nodes transmit information to a newcomer to rebuild the system. In contrast to the classical repair, where helper nodes transmit classical bits, we allow them to send classical information over quantum channels to the newcomer. The n</td>
      <td>http://arxiv.org/abs/2601.10676v1</td>
    </tr>
    <tr>
      <td>Irregular higher-spin generating equations and chiral perturbation theory</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We present a complementary approach to the standard Vasiliev framework for nonlinear higher-spin interactions in four dimensions, aimed at identifying their minimally nonlocal form. Our proposal introduces a generating system for higher-spin vertices at the level of classical equations, which we refer to as irregular, in contrast to the regular case described by Vasiliev. This system extends the recently proposed equations for (anti)holomorphic interactions by incorporating the mixed sector. Its</td>
      <td>http://arxiv.org/abs/2601.10680v1</td>
    </tr>
    <tr>
      <td>Vertex operator algebra bundles on modular curves and their associated modular forms</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This paper describes the vector bundle on the elliptic modular curve that is associated to a vertex operator algebra $V$ (VOA) or more generally a quasi-vertex operator algebra (QVOA), with a view towards future applications aimed at studying the characters of VOAs. We explain how the modes of sections of $V$ give rise naturally to $V$-valued quasi-modular forms. The space $Q(V)$ of $V$-valued quasi-modular forms is endowed with the structure of a doubled QVOA, and in particular the algebra $Q$</td>
      <td>http://arxiv.org/abs/2601.10686v1</td>
    </tr>
    <tr>
      <td>Mitigating nonlinear transduction noise in high-cooperativity cavity optomechanics</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Coupling mechanical motion to an optical resonator enables displacement measurements approaching the standard quantum limit (SQL). However, increasing the optomechanical coupling strength will inevitably lead to probing of the nonlinear response of the optical resonator. Thermal intermodulation noise (TIN) arising from the nonlinear mixing of thermomechanical motion can further increase the imprecision well above the SQL and has hitherto been canceled up to second order of nonlinearity via opera</td>
      <td>http://arxiv.org/abs/2601.10689v1</td>
    </tr>
    <tr>
      <td>Data-driven stochastic reduced-order modeling of parametrized dynamical systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Modeling complex dynamical systems under varying conditions is computationally intensive, often rendering high-fidelity simulations intractable. Although reduced-order models (ROMs) offer a promising solution, current methods often struggle with stochastic dynamics and fail to quantify prediction uncertainty, limiting their utility in robust decision-making contexts. To address these challenges, we introduce a data-driven framework for learning continuous-time stochastic ROMs that generalize acr</td>
      <td>http://arxiv.org/abs/2601.10690v1</td>
    </tr>
    <tr>
      <td>Finite-momentum Cooper plasmons in superconducting terahertz microcavities</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The phase mode of a superconductor's order parameter encodes fundamental information about pairing and dissipation, but is typically inaccessible at low frequencies due to the Anderson-Higgs mechanism. Superconducting samples thinner than the London penetration depth, however, support a gapless phase mode whose dispersion can be reshaped by a proximal screening layer. Here, we theoretically and experimentally show that this screened phase mode in a superconducting thin film integrated into on-ch</td>
      <td>http://arxiv.org/abs/2601.10692v1</td>
    </tr>
    <tr>
      <td>Madelung hydrodynamics of spin-orbit coupling: action principles, currents, and correlations</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We exploit the variational and Hamiltonian structures of quantum hydrodynamics with spin to unfold the correlation and torque mechanisms accompanying spin-orbit coupling (SOC) in electronic motion. Using Hamilton's action principle for the Pauli equation, we isolate SOC-induced quantum forces that act on the orbital Madelung--Bohm trajectories and complement the usual force terms known to appear in quantum hydrodynamics with spin. While the latter spin-hydrodynamic forces relate to the quantum g</td>
      <td>http://arxiv.org/abs/2601.10698v1</td>
    </tr>
    <tr>
      <td>Scalable Spin Squeezing in Power-Law Interacting XXZ Models with Disorder</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>While spin squeezing has been traditionally considered in all-to-all interacting models, recent works have shown that spin squeezing can occur in systems with power-law interactions, leading to direct testing in Rydberg atoms, trapped ions, ultracold atoms and nitrogen vacancy (NV) centers in diamond. For the latter, Wu. et al. Nature 646 (2025) demonstrated that spin squeezing is heavily affected by positional disorder, reducing any capacity for a practical squeezing advantage, which requires s</td>
      <td>http://arxiv.org/abs/2601.10703v1</td>
    </tr>
    <tr>
      <td>Distributed Perceptron under Bounded Staleness, Partial Participation, and Noisy Communication</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We study a semi-asynchronous client-server perceptron trained via iterative parameter mixing (IPM-style averaging): clients run local perceptron updates and a server forms a global model by aggregating the updates that arrive in each communication round. The setting captures three system effects in federated and distributed deployments: (i) stale updates due to delayed model delivery and delayed application of client computations (two-sided version lag), (ii) partial participation (intermittent</td>
      <td>http://arxiv.org/abs/2601.10705v1</td>
    </tr>
    <tr>
      <td>Emergence and transition of incompressible phases in decorated Landau levels</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We show a single Landau level (LL) dressed with periodic electrostatic potentials can realize a plethora of interacting topological phases where the Hall conductivity generally does not equal to the LL filling factor. Their physics can be captured by a minimal model of a delta potential lattice within a single LL, realizing exact zero energy Chern bands (denoted as decorated Landau levels or dLL) gapped from dispersive bands with rich geometric properties. With $p/q$ magnetic fluxes per unit cel</td>
      <td>http://arxiv.org/abs/2601.10717v1</td>
    </tr>
    <tr>
      <td>CoGen: Creation of Reusable UI Components in Figma via Textual Commands</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The evolution of User Interface design has emphasized the need for efficient, reusable, and editable components to ensure an efficient design process. This research introduces CoGen, a system that uses machine learning techniques to generate reusable UI components directly in Figma, one of the most popular UI design tools. Addressing gaps in current systems, CoGen focuses on creating atomic components such as buttons, labels, and input fields using structured JSON and natural language prompts. T</td>
      <td>http://arxiv.org/abs/2601.10536v1</td>
    </tr>
    <tr>
      <td>Topologically switchable transport in a bundled cable of wires</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Advances in the next generation of mesoscopic electronics require an understanding of topological phases in inhomogeneous media and the principles that govern them. Motivated by the nature of motifs available in printable conducting inks, we introduce and study quantum transport in a minimal model that describes a bundle of one-dimensional metallic wires that are randomly interconnected by semiconducting chains. Each of these interconnects is represented by a Su-Schrieffer-Heeger chain, which ca</td>
      <td>http://arxiv.org/abs/2601.10534v1</td>
    </tr>
    <tr>
      <td>Coarsening Causal DAG Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Directed acyclic graphical (DAG) models are a powerful tool for representing causal relationships among jointly distributed random variables, especially concerning data from across different experimental settings. However, it is not always practical or desirable to estimate a causal model at the granularity of given features in a particular dataset. There is a growing body of research on causal abstraction to address such problems. We contribute to this line of research by (i) providing novel gr</td>
      <td>http://arxiv.org/abs/2601.10531v1</td>
    </tr>
    <tr>
      <td>Correlated states in charge-transfer heterostructures based on rhombohedral multilayer graphene</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Charge transfer is a common phenomenon in van der Waals heterostructures with proper work function mismatch, which enables electrostatic gating to control band alignment and interlayer charge distributions. This provides a tunable platform for studying coupled bilayer correlated electronic systems. Here, we theoretically investigate heterostructures of rhombohedral multilayer graphene (RMG) and an insulating substrate with gate-tunable band alignment. We first develop a self-consistent electrost</td>
      <td>http://arxiv.org/abs/2601.10530v1</td>
    </tr>
    <tr>
      <td>Symmetry-based Perspectives on Hamiltonian Quantum Search Algorithms and Schrodinger's Dynamics between Orthogonal States</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>It is known that the continuous-time variant of Grover's search algorithm is characterized by quantum search frameworks that are governed by stationary Hamiltonians, which result in search trajectories confined to the two-dimensional subspace of the complete Hilbert space formed by the source and target states. Specifically, the search approach is ineffective when the source and target states are orthogonal. In this paper, we employ normalization, orthogonality, and energy limitations to demonst</td>
      <td>http://arxiv.org/abs/2601.10655v1</td>
    </tr>
    <tr>
      <td>Synchronization with Annealed Disorder and Higher-Harmonic Interactions in Arbitrary Dimensions: When Two Dimensions Are Special</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The impact of disorder on collective phenomena depends crucially on whether it is quenched or annealed. In synchronization problems, quenched disorder in higher dimensional Kuramoto models is known to produce unconventional dimensional effects, including a striking odd even dichotomy: synchronization transitions are continuous in even dimensions and discontinuous in odd dimensions. By contrast, the impact of annealed disorder has received comparatively little attention. Here we study a D dimensi</td>
      <td>http://arxiv.org/abs/2601.10646v1</td>
    </tr>
    <tr>
      <td>ROMA: Real-time Omni-Multimodal Assistant with Interactive Streaming Understanding</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Recent Omni-multimodal Large Language Models show promise in unified audio, vision, and text modeling. However, streaming audio-video understanding remains challenging, as existing approaches suffer from disjointed capabilities: they typically exhibit incomplete modality support or lack autonomous proactive monitoring. To address this, we present ROMA, a real-time omni-multimodal assistant for unified reactive and proactive interaction. ROMA processes continuous inputs as synchronized multimodal</td>
      <td>http://arxiv.org/abs/2601.10323v1</td>
    </tr>
    <tr>
      <td>Converse Bounds for Sun-Jafar-type Weak Private Information Retrieval</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Building on the well-established capacity-achieving schemes of Sun-Jafar (for replicated storage) and the closely related scheme of Banawan-Ulukus (for MDS-coded setting), a recent work by Chandan et al. proposed new classes of weak private information retrieval (WPIR) schemes for the collusion-free (replication and MDS-coded) setting, as well as for the $T$-colluding scenario. In their work, Chandan et al. characterized the expressions for the rate-privacy trade-offs for these classes of WPIR s</td>
      <td>http://arxiv.org/abs/2601.10643v1</td>
    </tr>
    <tr>
      <td>Kolmogorov Arnold Networks and Multi-Layer Perceptrons: A Paradigm Shift in Neural Modelling</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The research undertakes a comprehensive comparative analysis of Kolmogorov-Arnold Networks (KAN) and Multi-Layer Perceptrons (MLP), highlighting their effectiveness in solving essential computational challenges like nonlinear function approximation, time-series prediction, and multivariate classification. Rooted in Kolmogorov's representation theorem, KANs utilize adaptive spline-based activation functions and grid-based structures, providing a transformative approach compared to traditional neu</td>
      <td>http://arxiv.org/abs/2601.10563v1</td>
    </tr>
    <tr>
      <td>Rewriting Systems on Arbitrary Monoids</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In this paper, we introduce monoidal rewriting systems (MRS), an abstraction of string rewriting in which reductions are defined over an arbitrary ambient monoid rather than a free monoid of words. This shift is partly motivated by logic: the class of free monoids is not first-order axiomatizable, so "working in the free setting" cannot be treated internally when applying first-order methods to rewriting presentations. To analyze these systems categorically, we define $\mathbf{NCRS_2}$ as the 2-</td>
      <td>http://arxiv.org/abs/2601.10564v1</td>
    </tr>
    <tr>
      <td>Hydrodynamic Limit with a Weierstrass-type result</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We show that any positive, continuous, and bounded function can be realised as the diffusion coefficient of an evolution equation associated with a gradient interacting particle system. The proof relies on the construction of an appropriate model and on the entropy method.</td>
      <td>http://arxiv.org/abs/2601.10568v1</td>
    </tr>
    <tr>
      <td>Sparse Signal Recovery from Random Measurements</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Given the compressed sensing measurements of an unknown vector $z \in \mathbb{R}^n$ using random matrices, we present a simple method to determine $z$ without solving any optimization problem or linear system. Our method uses $Θ(\log n)$ random sensing matrices in $\mathbb{R}^{k \times n}$ and runs in $O(kn\log n)$ time, where $k = Θ(s\log n)$ and $s$ is the number of nonzero coordinates in $z$. We adapt our method to determine the support set of $z$ and experimentally compare with some optimiza</td>
      <td>http://arxiv.org/abs/2601.10569v1</td>
    </tr>
    <tr>
      <td>Achievable Degrees of Freedom Analysis and Optimization in Massive MIMO via Characteristic Mode Analysis</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Massive multiple-input multiple-output (MIMO) is esteemed as a critical technology in 6G communications, providing large degrees of freedom (DoF) to improve multiplexing gain. This paper introduces characteristic mode analysis (CMA) to derive the achievable DoF. Unlike existing works primarily focusing on the DoF of the wireless channel,the excitation and radiation properties of antennas are also involved in our DoF analysis, which influences the number of independent data streams for communicat</td>
      <td>http://arxiv.org/abs/2601.10576v1</td>
    </tr>
    <tr>
      <td>Searching for Quantum Effects in the Brain: A Bell-Type Test for Nonclassical Latent Representations in Autoencoders</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Whether neural information processing is entirely classical or involves quantum-mechanical elements remains an open question. Here we propose a model-agnostic, information-theoretic test of nonclassicality that bypasses microscopic assumptions and instead probes the structure of neural representations themselves. Using autoencoders as a transparent model system, we introduce a Bell-type consistency test in latent space, and ask whether decoding statistics obtained under multiple readout contexts</td>
      <td>http://arxiv.org/abs/2601.10588v1</td>
    </tr>
    <tr>
      <td>High-fidelity stellar extinction with Gaia and APOGEE -- I. The method and a new extinction curve</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The scarcity of high-fidelity extinction measurements remains a bottleneck in deriving accurate stellar properties from Gaia parallaxes. In this work, we aim to derive precision extinction estimates for APOGEE DR19 stars, establishing a new benchmark for Galactic stellar population studies. We first determine reddening by comparing observed colorsr, etrieved from photometric surveys or standardized synthetic magnitudes from Gaia BP/RP spectra, to intrinsic colors predicted via an XGBoost model.</td>
      <td>http://arxiv.org/abs/2601.10595v1</td>
    </tr>
    <tr>
      <td>A young progenitor for the most common planetary systems in the Galaxy</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The Galaxy's most common known planetary systems have several Earth-to-Neptune-size planets in compact orbits. At small orbital separations, larger planets are less common than their smaller counterparts by an order of magnitude. The young star V1298 Tau hosts one such compact planetary system, albeit with four planets that are uncommonly large (5 to 10 Earth radii). The planets form a chain of near-resonances that result in transit-timing variations of several hours. Here we present a multi-yea</td>
      <td>http://arxiv.org/abs/2601.10598v1</td>
    </tr>
    <tr>
      <td>Translating database mathematical schemes into relational database software applications with MatBase</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We present a pseudocode algorithm for translating our (Elementary) Mathematical Data Model schemes into relational ones and associated sets of non-relational constraints, used by MatBase, our intelligent database management system prototype. We prove that this algorithm is very fast, solid, complete, and optimal. We apply it to a mathematical scheme modeling the genealogical trees subuniverse. We also provide examples of SQL and VBA code for enforcing some of its non-relational constraints, as w</td>
      <td>http://arxiv.org/abs/2601.10604v1</td>
    </tr>
    <tr>
      <td>A user subscription model in mobile radio access networks with network slicing</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Network slicing is an architectural enabling technology that logically decouples the current cellular networks into infrastructure providers (InPs) and Network Slice Tenants (NSTs). The network resources (e.g., radio access resources at each cell) are owned by the InP, and are shared by the NSTs to provide a service to their mobile users. In this context, we proposed a business model that includes resource allocation and user subscription to NSTs in a competitive setting, and provides, among oth</td>
      <td>http://arxiv.org/abs/2601.10605v1</td>
    </tr>
    <tr>
      <td>Multi-Objective Pareto-Front Optimization for Efficient Adaptive VVC Streaming</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Adaptive video streaming has facilitated improved video streaming over the past years. A balance among coding performance objectives such as bitrate, video quality, and decoding complexity is required to achieve efficient, content- and codec-dependent, adaptive video streaming. This paper proposes a multi-objective Pareto-front (PF) optimization framework to construct quality-monotonic, content-adaptive bitrate ladders Versatile Video Coding (VVC) streaming that jointly optimize video quality, b</td>
      <td>http://arxiv.org/abs/2601.10607v1</td>
    </tr>
    <tr>
      <td>Beyond Hubbard: the role of correlated hopping interaction in superconductors and quantum dot devices</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We investigate the role of strong Coulomb interactions beyond the standard Hubbard model in two distinct physical contexts. First, we analyze the superconducting phase transition occurring near the Mott metal-insulator transition. Second, we study transport properties of artificial nano-scale structures containing quantum dots coupled to external electrodes. In both cases, we focus on the impact of the correlated (assisted) hopping (CH) interaction. For superconductors, CH acts as a driving mech</td>
      <td>http://arxiv.org/abs/2601.10619v1</td>
    </tr>
    <tr>
      <td>Discrete-time maximally superintegrable systems and deformed symmetry algebras: the Calogero-Moser case</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We determine the complete structure of the symmetry algebras associated with the N-body Calogero-Moser system and its maximally superintegrable discretization. We prove that the discretization naturally leads to a nontrivial deformation of the continuous symmetry algebra, with the discretization parameter playing the rôle of a deformation parameter. This phenomenon illustrates how discrete superintegrable systems can be viewed as natural sources of deformed polynomial algebraic structures. As a</td>
      <td>http://arxiv.org/abs/2601.10625v1</td>
    </tr>
    <tr>
      <td>Parametric RDT approach to computational gap of symmetric binary perceptron</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We study potential presence of statistical-computational gaps (SCG) in symmetric binary perceptrons (SBP) via a parametric utilization of \emph{fully lifted random duality theory} (fl-RDT) [96]. A structural change from decreasingly to arbitrarily ordered $c$-sequence (a key fl-RDT parametric component) is observed on the second lifting level and associated with \emph{satisfiability} ($α_c$) -- \emph{algorithmic} ($α_a$) constraints density threshold change thereby suggesting a potential existen</td>
      <td>http://arxiv.org/abs/2601.10628v1</td>
    </tr>
    <tr>
      <td>VoiceSculptor: Your Voice, Designed By You</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Despite rapid progress in text-to-speech (TTS), open-source systems still lack truly instruction-following, fine-grained control over core speech attributes (e.g., pitch, speaking rate, age, emotion, and style). We present VoiceSculptor, an open-source unified system that bridges this gap by integrating instruction-based voice design and high-fidelity voice cloning in a single framework. It generates controllable speaker timbre directly from natural-language descriptions, supports iterative refi</td>
      <td>http://arxiv.org/abs/2601.10629v1</td>
    </tr>
    <tr>
      <td>Circumplanetary Disk Candidate in the Disk of HD 163296 Traced by Localized Emission from Simple Organics</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Atacama Large Millimeter/submillimeter Array observations suggest that the disc of HD 163296 is being actively shaped by embedded, yet unseen protoplanets, as indicated by numerous gas and dust substructures consistent with planet-disc interaction models. We report the first detection of simple organic molecules, HCN and C2H, tracing a candidate circumplanetary disc (CPD) in the HD 163296 system, located at an orbital radius of $R=88\pm7$ au and azimuth $φ=46\pm3^\circ$ (or $R=0.75''$, $\rm{PA}=</td>
      <td>http://arxiv.org/abs/2601.10631v1</td>
    </tr>
    <tr>
      <td>Molecularly Thin Polyaramid Nanomechanical Resonators</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Two-dimensional polyaramids exhibit strong hydrogen bonding to create molecularly thin nanosheets analogous to graphene. Here, we report the first nanomechanical resonators made out of a two-dimensional polyaramid, 2DPA-1, with thicknesses as small as 8 nm. To fabricate these molecular-scale resonators, we transferred nanofilms of 2DPA-1 onto chips with previously etched arrays of circular microwells. We then characterized the thermal resonances of these resonators under different conditions. Wh</td>
      <td>http://arxiv.org/abs/2601.10633v1</td>
    </tr>
    <tr>
      <td>Nested hyperedges promote the onset of collective transitions but suppress explosive behavior</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Higher-order interactions can dramatically reshape collective dynamics, yet how their microscopic organization controls macroscopic critical behavior remains unclear. Here we develop a new theory to study contagion dynamics on hypergraphs and show that nested hyperedges not only facilitate the onset of spreading, but also suppress backward bifurcations, thereby inhibiting explosive behavior. By disentangling contagion pathways, we find that overlap redirects transmission from external links to i</td>
      <td>http://arxiv.org/abs/2601.10522v1</td>
    </tr>
    <tr>
      <td>Transformer-Based Cognitive Radio: Adaptive Modulation Strategies Using Transformer Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Cognitive Radio (CR) systems, which dynamically adapt to changing spectrum environments, could benefit significantly from advancements in machine learning technologies. These systems can be enhanced in terms of spectral efficiency, robustness, and security through innovative approaches such as the use of Transformer models. This work investigates the application of Transformer models, specifically the GPT-2 architecture, to generate novel modulation schemes for wireless communications. By traini</td>
      <td>http://arxiv.org/abs/2601.10519v1</td>
    </tr>
    <tr>
      <td>Discovery of the First Five Carbon-Enhanced Metal-Poor Stars in the LMC</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>A substantial fraction of metal-poor stars in the local Milky Way halo exhibit large overabundances of carbon. These stars, dubbed Carbon-Enhanced Metal-Poor (CEMP) stars, provide crucial constraints on the nature of the early universe including the earliest nucleosynthetic events. Whether these stars exist at similar rates in nearby galaxies is a major open question with implications for the environmental dependence of early chemical evolution. Here, we present the discovery of the first five C</td>
      <td>http://arxiv.org/abs/2601.10514v1</td>
    </tr>
    <tr>
      <td>A New Construction Structure on Multi-access Coded Caching with Linear Subpacketization: Cyclic Multi-Access Non-Half-Sum Disjoint Packing</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We consider the $(K,L,M,N)$ multi-access coded caching system introduced by Hachem et al., which consists of a central server with $N$ files and $K$ cache nodes, each of memory size $M$, where each user can access $L$ cache nodes in a cyclic wrap-around fashion. At present, several existing schemes achieve competitive transmission performance, but their subpacketization levels grow exponentially with the number of users. In contrast, schemes with linear or polynomial subpacketization always incu</td>
      <td>http://arxiv.org/abs/2601.10510v1</td>
    </tr>
    <tr>
      <td>The transformation mechanisms among cuboctahedra, Ino's decahedra and icosahedra structures of magic-size gold nanoclusters</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Gold nanoclusters possess multiple competing structural motifs with small energy differences, enabling structural coexistence and interconversion. Using a high-accuracy machine learned potential trained on some 20'000 density functional theory reference data points, we investigate transformation pathways connecting both high-symmetry and amorphous cuboctahedra, Ino's decahedra and icosahedra for Au55, Au147, Au309 and Au561 nanoclusters. Our saddle point searches reveal that high-symmetry transf</td>
      <td>http://arxiv.org/abs/2601.10434v1</td>
    </tr>
    <tr>
      <td>Geometric characterization of frictional impacts by means of breakable kinetic constraints</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In the context of geometric Impulsive Mechanics of systems with a finite number of degrees of freedom, we model the roughness of a unilateral constraint ${\mathcal S\/}$ by introducing a suitable instantaneous kinetic constraint ${\mathcal B\/}\subset {\mathcal S\/}$. A constitutive characterization of ${\mathcal B\/}$ based only on the geometric properties of the setup and on the dry friction laws can then be introduced to model the frictional behavior of ${\mathcal S\/}$ in an impact of the sy</td>
      <td>http://arxiv.org/abs/2601.10432v1</td>
    </tr>
    <tr>
      <td>Active interrogation of underground piezoelectric fabrics using high energy muon beams propagating across seismogenic faults</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In this paper we extend a previous analysis of a newly conceived technique based on active interrogation of tectonic stress evolution in regions hosting active seismogenic faults. The aim is to monitor and detect stable and reliable precursor signals on an adequate time scale, well before an earthquake event, that can play a crucial role in activating alarms for civil protection systems. The precursor signal relies on continuous measurements of the time evolution of tectonic stress, obtained by</td>
      <td>http://arxiv.org/abs/2601.10430v1</td>
    </tr>
    <tr>
      <td>Reduction of thermodynamic uncertainty by a virtual qubit</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The thermodynamic uncertainty relation (TUR) imposes a fundamental constraint between current fluctuations and entropy production, providing a refined formulation of the second law for micro- and nanoscale systems. Quantum violations of the classical TUR reveal genuinely quantum thermodynamic effects, which are essential for improving performance and enabling optimization in quantum technologies. In this work, we analyze the TUR in a class of paradigmatic quantum thermal-machine models whose ope</td>
      <td>http://arxiv.org/abs/2601.10429v1</td>
    </tr>
    <tr>
      <td>The eigenvalues and eigenvectors of finite-rank normal perturbations of large rotationally invariant non-Hermitian matrices</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We study finite-rank normal deformations of rotationally invariant non-Hermitian random matrices. Extending the classical Baik-Ben Arous-Péché (BBP) framework, we characterize the emergence and fluctuations of outlier eigenvalues in models of the form $\mathbf{A} + \mathbf{T}$, where $\mathbf{A}$ is a large rotationally invariant non-Hermitian random matrix and $\mathbf{T}$ is a finite-rank normal perturbation. We also describe the corresponding eigenvector behavior. Our results provide a unifie</td>
      <td>http://arxiv.org/abs/2601.10427v1</td>
    </tr>
    <tr>
      <td>Placement Delivery Array for Cache-Aided MIMO Systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We consider a $(G,L,K,M,N)$ cache-aided multiple-input multiple-output (MIMO) network, where a server equipped with $L$ antennas and a library of $N$ equal-size files communicates with $K$ users, each equipped with $G$ antennas and a cache of size $M$ files, over a wireless interference channel. Each user requests an arbitrary file from the library. The goal is to design coded caching schemes that simultaneously achieve the maximum sum degrees of freedom (sum-DoF) and low subpacketization. In th</td>
      <td>http://arxiv.org/abs/2601.10422v1</td>
    </tr>
    <tr>
      <td>On the Canonical Construction of Simple Lie Superalgebras</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Axioms for the generalization of root systems were defined and classified (irreducible) by V. Serganova, which precisely correspond to the root systems of basic classical Lie Superalgebras. Here, we present a unified method for constructing simple Lie Superalgebras from the abstract root system, with the choice of base having the minimal number of isotropic roots.</td>
      <td>http://arxiv.org/abs/2601.10419v1</td>
    </tr>
    <tr>
      <td>Cloud parameter estimation for interacting BEC after time-of-flight</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Experiments on Bose-Einstein condensates at finite temperature typically extract the system parameters, such as temperature, atom number, and condensed fraction from time-of-flight images taken after a free expansion time. This paper systematically examines the effect of repulsive interactions between the condensed and thermal atoms in partially condensed clouds on the expansion profile of the thermal cloud. An analytical expression for the expansion can be obtained only if the interactions betw</td>
      <td>http://arxiv.org/abs/2601.10415v1</td>
    </tr>
    <tr>
      <td>Basal-plane anisotropy of field-induced multipolar order in tetragonal CeRh$_2$As$_2$</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Unconventional superconductivity in Ce-based Kondo-lattice materials emerges almost exclusively in the vicinity of weak dipolar magnetic orders, while higher multipolar orders are only known to occur in a few Pr-based unconventional superconductors and possibly URu$_2$Si$_2$. The multiphase superconductor CeRh$_2$As$_2$ appears to be a notable exception from this trend. Showing clear signatures of magnetism, this tetragonal system is suspected to host a concomitant quadrupolar order, which could</td>
      <td>http://arxiv.org/abs/2601.10414v1</td>
    </tr>
    <tr>
      <td>An effective interactive brain cytoarchitectonic parcellation framework using pretrained foundation model</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Cytoarchitectonic mapping provides anatomically grounded parcellations of brain structure and forms a foundation for integrative, multi-modal neuroscience analyses. These parcellations are defined based on the shape, density, and spatial arrangement of neuronal cell bodies observed in histological imaging. Recent works have demonstrated the potential of using deep learning models toward fully automatic segmentation of cytoarchitectonic areas in large-scale datasets, but performance is mainly con</td>
      <td>http://arxiv.org/abs/2601.10412v1</td>
    </tr>
    <tr>
      <td>Tight bounds on recurrence time in closed quantum systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The evolution of an isolated quantum system inevitably exhibits recurrence: the state returns to the vicinity of its initial condition after finite time. Despite its fundamental nature, a rigorous quantitative understanding of recurrence has been lacking. We establish upper bounds on the recurrence time, $t_{\mathrm{rec}} \lesssim t_{\mathrm{exit}}(ε)(1/ε)^d$, where $d$ is the Hilbert-space dimension, $ε$ the neighborhood size, and $t_{\mathrm{exit}}(ε)$ the escape time from this neighborhood. F</td>
      <td>http://arxiv.org/abs/2601.10409v1</td>
    </tr>
    <tr>
      <td>Bounding many-body properties under partial information and finite measurement statistics</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Calculating bounds of properties of many-body quantum systems is of paramount importance, since they guide our understanding of emergent quantum phenomena and complement the insights obtained from estimation methods. Recent semidefinite programming approaches enable probabilistic bounds from finite-shot measurements of easily accessible, yet informationally incomplete, observables. Here we render these methods scalable in the number of qubits by instead utilizing moment-matrix relaxations. After</td>
      <td>http://arxiv.org/abs/2601.10408v1</td>
    </tr>
    <tr>
      <td>A Predictive Model for Synergistic Oncolytic Virotherapy: Unveiling the Ping-Pong Mechanism and Optimal Timing of Combined Vesicular Stomatitis and Vaccinia Viruses</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We present a mathematical model that describes the synergistic mechanism of combined Vesicular Stomatitis Virus (VSV) and Vaccinia Virus (VV). The model captures the dynamic interplay between tumor cells, viral replication, and the interferon-mediated immune response, revealing a `ping-pong' synergy where VV-infected cells produce B18R protein that neutralizes interferon-$α$, thereby enhancing VSV replication within the tumor. Numerical simulations demonstrate that this combination achieves comp</td>
      <td>http://arxiv.org/abs/2601.10405v1</td>
    </tr>
    <tr>
      <td>A comparison of simulation tools for Muon-Induced X-ray Emission (MIXE) in thin films: a study case with lithium batteries</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We present a comparative study of three Monte Carlo simulation frameworks -SRIM, GEANT4, and PHITS- for modeling the transport, stopping, and atomic cascade of negative muons in micrometer-scale, multilayer systems relevant to Muon-Induced X-ray Emission (MIXE) experiments at the Paul Scherrer Institute (PSI). Using a lithium-ion battery as a benchmark target, simulated implantation profiles are compared with experimental data from the GIANT spectrometer. All three codes reproduce the overall mu</td>
      <td>http://arxiv.org/abs/2601.10401v1</td>
    </tr>
    <tr>
      <td>OT-Drive: Out-of-Distribution Off-Road Traversable Area Segmentation via Optimal Transport</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Reliable traversable area segmentation in unstructured environments is critical for planning and decision-making in autonomous driving. However, existing data-driven approaches often suffer from degraded segmentation performance in out-of-distribution (OOD) scenarios, consequently impairing downstream driving tasks. To address this issue, we propose OT-Drive, an Optimal Transport--driven multi-modal fusion framework. The proposed method formulates RGB and surface normal fusion as a distribution</td>
      <td>http://arxiv.org/abs/2601.09952v1</td>
    </tr>
    <tr>
      <td>Proactive Local-Minima-Free Robot Navigation: Blending Motion Prediction with Safe Control</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This work addresses the challenge of safe and efficient mobile robot navigation in complex dynamic environments with concave moving obstacles. Reactive safe controllers like Control Barrier Functions (CBFs) design obstacle avoidance strategies based only on the current states of the obstacles, risking future collisions. To alleviate this problem, we use Gaussian processes to learn barrier functions online from multimodal motion predictions of obstacles generated by neural networks trained with e</td>
      <td>http://arxiv.org/abs/2601.10233v1</td>
    </tr>
    <tr>
      <td>Model order reduction of piecewise linear mechanical systems using invariant cones</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We present a methodology that extends invariant manifold theory to a class of autonomous piecewise linear systems with nonsmoothness at the equilibrium, providing a framework for model order reduction in mechanical structures with compliant contact laws. The key idea is to make the absence of a local linearization around the equilibrium tractable by leveraging the positive homogeneity property. This property simplifies the invariance equations defining the geometry of the invariant cones, from a</td>
      <td>http://arxiv.org/abs/2601.10241v1</td>
    </tr>
    <tr>
      <td>Non-Intrusive Hyperreduction by a Physics-Augmented Neural Network with Second-Order Sobolev Training</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The finite element method is an indispensable tool in engineering, but its computational complexity prevents applications for control or at system-level. Model order reduction bridges this gap, creating highly efficient yet accurate surrogate models. Reducing nonlinear setups additionally requires hyperreduction. Compatibility with commercial finite element software requires non-intrusive methods based on data. Methods include the trajectory piecewise linear approach, or regression, typically vi</td>
      <td>http://arxiv.org/abs/2601.10442v1</td>
    </tr>
    <tr>
      <td>Localization Landscape in Non-Hermitian and Floquet quantum systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We propose a generalization of the Filoche--Mayboroda localization landscape that extends the theory well beyond the static, elliptic and Hermitian settings while preserving its geometric interpretability. Using the positive operator $H^\dagger H$, we obtain a landscape that predicts localization across non-Hermitian, Floquet, and topological systems without computing eigenstates. Singular-value collapse reveals spectral instabilities and skin effects, the Sambe formulation captures coherent des</td>
      <td>http://arxiv.org/abs/2601.10451v1</td>
    </tr>
    <tr>
      <td>Energy-Efficient Probabilistic Semantic Communication Over Visible Light Networks With Rate Splitting</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Visible light communication (VLC) is emerging as a key technology for future wireless communication systems due to its unique physical-layer advantages over traditional radio-frequency (RF)-based systems. However, its integration with higher-layer techniques, such as semantic communication, remains underexplored. This paper investigates the energy efficiency maximization problem in a resource-constrained VLC-based probabilistic semantic communication (PSCom) system. In the considered model, ligh</td>
      <td>http://arxiv.org/abs/2601.10452v1</td>
    </tr>
    <tr>
      <td>Finite lattice kinetic equations for bosons, fermions, and discrete NLS</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We introduce and study finite lattice kinetic equations for bosons, fermions, and discrete NLS. For each model this closed evolution equation provides an approximate description for the evolution of the appropriate covariance function in the system. It is obtained by truncating the cumulant hierarchy and dropping the higher order cumulants in the usual manner. To have such a reference solution should simplify controlling the full hierarchy and thus allow estimating the error from the truncation.</td>
      <td>http://arxiv.org/abs/2601.10486v1</td>
    </tr>
    <tr>
      <td>sponchpop II: Population Synthesis to Investigate Volatile Sulfur as a Fingerprint of Gas Giant Formation Histories</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Planet population synthesis is an integral tool for linking exoplanets to their formation environments. Most planet population synthesis studies have focused on the carbon-to-oxygen ratio (C/O) in gas or solids, yet more insight into planet formation may be afforded by considering a wider suite of elements. Sulfur is one such key element. It has been assumed to be entirely refractory in population synthesis models, restricting it to being a tracer of accreted rocky solids. However, sulfur also h</td>
      <td>http://arxiv.org/abs/2601.10508v1</td>
    </tr>
    <tr>
      <td>The incompatibility of the Condorcet winner and loser criteria with positive involvement and resolvability</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We prove that there is no preferential voting method satisfying the Condorcet winner and loser criteria, positive involvement (if a candidate $x$ wins in an initial preference profile, then adding a voter who ranks $x$ uniquely first cannot cause $x$ to lose), and resolvability (if $x$ initially ties for winning, then $x$ can be made the unique winner by adding a single voter). In a previous note, we proved an analogous result assuming an additional axiom of ordinal margin invariance, which we n</td>
      <td>http://arxiv.org/abs/2601.10506v1</td>
    </tr>
    <tr>
      <td>Higher order trade-offs in hypergraph community detection</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Extending community detection from pairwise networks to hypergraphs introduces fundamental theoretical challenges. Hypergraphs exhibit structural heterogeneity with no direct graph analogue: hyperedges of varying orders can connect nodes across communities in diverse configurations, introducing new trade-offs in defining and detecting community structure. We address these challenges by developing a unified framework for community detection in non-uniform hypergraphs under the Hypergraph Stochast</td>
      <td>http://arxiv.org/abs/2601.10502v1</td>
    </tr>
    <tr>
      <td>CROCS: A Two-Stage Clustering Framework for Behaviour-Centric Consumer Segmentation with Smart Meter Data</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>With grid operators confronting rising uncertainty from renewable integration and a broader push toward electrification, Demand-Side Management (DSM) -- particularly Demand Response (DR) -- has attracted significant attention as a cost-effective mechanism for balancing modern electricity systems. Unprecedented volumes of consumption data from a continuing global deployment of smart meters enable consumer segmentation based on real usage behaviours, promising to inform the design of more effectiv</td>
      <td>http://arxiv.org/abs/2601.10494v1</td>
    </tr>
    <tr>
      <td>Plasmon dynamics in graphene</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Plasmons are collective oscillations of mobile electrons. Using terahertz spacetime metrology, we probe plasmon dynamics of mono- and bi-layer graphene. In both systems, the experimentally measured Drude weight systematically exceeds the prediction based on non-interacting electronic system. This enhancement is most pronounced at ultra-low carrier densities. We attribute the observed deviation to pseudospin dynamics of the Dirac fermions in multi-layer graphene, which leads to a breakdown of Gal</td>
      <td>http://arxiv.org/abs/2601.10493v1</td>
    </tr>
    <tr>
      <td>Optimized readout strategies for neutral atom quantum processors</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Neutral atom quantum processors have emerged as a promising platform for scalable quantum information processing, offering high-fidelity operations and exceptional qubit scalability. A key challenge in realizing practical applications is efficiently extracting readout outcomes while maintaining high system throughput, i.e., the rate of quantum task executions. In this work, we develop a theoretical framework to quantify the trade-off between readout fidelity and atomic retention. Moreover, we in</td>
      <td>http://arxiv.org/abs/2601.10492v1</td>
    </tr>
    <tr>
      <td>Magnetic field-induced phases in a model S=1 Haldane chain system</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>An $S=1$ Haldane chain is a one-dimensional (1D) quantum magnet where strong fluctuations result in quantum disordered singlet ground state with a gapped excitation spectrum. The gap magnitude is primarily set by the dominant intrachain interaction ($J_\text{1D}$). An applied magnetic field closes the gap at $B_\text{c1}$ and drives the system into a gapless Tomonaga-Luttinger liquid (TLL) regime, followed by, at lower temperatures, a Bose-Einstein condensate (BEC) ground state, persisting up to</td>
      <td>http://arxiv.org/abs/2601.10489v1</td>
    </tr>
    <tr>
      <td>A Construction Framework of Coded Caching Scheme for Multi-Access MIMO Systems via Knapsack Problem</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This paper investigates the coded caching problem in a multi-access multiple-input single-output (MAMISO) network with the combinatorial topology. The considered system consists of a server containing $N$ files, $Λ$ cache nodes, and $K$ cache-less users, where each user can access a unique subset of $r$ cache nodes. The server is equipped with $L$ transmit antennas. Our objective is to design a caching scheme that simultaneously achieves a high sum Degree of Freedom (sum-DoF) and low subpacketiz</td>
      <td>http://arxiv.org/abs/2601.10484v1</td>
    </tr>
    <tr>
      <td>Stable Differentiable Modal Synthesis for Learning Nonlinear Dynamics</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Modal methods are a long-standing approach to physical modelling synthesis. Extensions to nonlinear problems are possible, including the case of a high-amplitude vibration of a string. A modal decomposition leads to a densely coupled nonlinear system of ordinary differential equations. Recent work in scalar auxiliary variable techniques has enabled construction of explicit and stable numerical solvers for such classes of nonlinear systems. On the other hand, machine learning approaches (in parti</td>
      <td>http://arxiv.org/abs/2601.10453v1</td>
    </tr>
    <tr>
      <td>High-Dimensional Analysis of Gradient Flow for Extensive-Width Quadratic Neural Networks</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We study the high-dimensional training dynamics of a shallow neural network with quadratic activation in a teacher-student setup. We focus on the extensive-width regime, where the teacher and student network widths scale proportionally with the input dimension, and the sample size grows quadratically. This scaling aims to describe overparameterized neural networks in which feature learning still plays a central role. In the high-dimensional limit, we derive a dynamical characterization of the gr</td>
      <td>http://arxiv.org/abs/2601.10483v1</td>
    </tr>
    <tr>
      <td>Positive Damping Region: A Graphic Tool for Passivization Analysis with Passivity Index</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This paper presents a geometric framework for analyzing output-feedback and input-feedforward passivization of linear time-invariant systems. We reveal that a system is passivizable with a given passivity index when the Nyquist plot for SISO systems or the Rayleigh quotient of the transfer function for MIMO systems lies within a specific, index-dependent region in the complex plane, termed the positive damping region. The criteria enable a convenient graphic tool for analyzing the passivization,</td>
      <td>http://arxiv.org/abs/2601.10475v1</td>
    </tr>
    <tr>
      <td>Joint Source-Channel Coding for ISAC: Distortion Tradeoffs and Separation Theorems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Integrated Sensing and Communication (ISAC) systems have garnered significant attention due to their capability to simultaneously achieve efficient communication and environmental sensing. A core objective in this field is characterizing the performance tradeoff between sensing and communication. In this paper, we consider a joint source-channel coding (JSCC) framework for the ISAC system that consists of a transmitter with a channel state estimator and a joint source-channel encoder, a state-de</td>
      <td>http://arxiv.org/abs/2601.10470v1</td>
    </tr>
    <tr>
      <td>On the projective dimension of some deformations of Weyl arrangements</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We show that the logarithmic derivation module of (the cone of) the deformation A of a Weyl arrangement associated with a root system of simply laced type has projective dimension one if the deforming parameter ranges from -j to j+2. In addition, we give an explicit minimal free resolution when the root system is of type A3 and B2. Moreover, in the second case, we determine the jumping lines of maximal jumping order of the associated vector bundle. When the deforming parameter of A (respectively</td>
      <td>http://arxiv.org/abs/2601.10466v1</td>
    </tr>
    <tr>
      <td>Nonlinear quantum Kibble-Zurek ramps in open systems at finite temperature</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We analyze quantum systems under a broad class of protocols in which the temperature and a Hamiltonian control parameter are ramped simultaneously and, in general, in a nonlinear fashion toward a quantum critical point. Using an open-system version of a Kitaev quantum wire as an example, we show that, unlike finite-temperature protocols at fixed temperature, these protocols allow us to probe, in an out-of-equilibrium situation and at finite temperature, the universality class (characterized by t</td>
      <td>http://arxiv.org/abs/2601.10465v1</td>
    </tr>
    <tr>
      <td>Architectural Classification of XR Workloads: Cross-Layer Archetypes and Implications</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Edge and mobile platforms for augmented and virtual reality, collectively referred to as extended reality (XR) must deliver deterministic ultra-low-latency performance under stringent power and area constraints. However, the diversity of XR workloads is rapidly increasing, characterized by heterogeneous operator types and complex dataflow structures. This trend poses significant challenges to conventional accelerator architectures centered around convolutional neural networks (CNNs), resulting i</td>
      <td>http://arxiv.org/abs/2601.10463v1</td>
    </tr>
    <tr>
      <td>The Wiener Wintner and Return Times Theorem Along the Primes</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We prove the following Return Times Theorem along the sequence of prime times, the first extension of the Return Times Theorem to arithmetic sequences: For every probability space, $(Ω,ν)$, equipped with a measure-preserving transformation, $T \colon Ω\to Ω$, and every $f \in L^\infty(Ω)$, there exists a set of full probability, $Ω_f \subset Ω$ with $ν(Ω_f) =1$, so that for all $ω\in Ω_f$, for any other probability space $(X,μ)$, equipped with a measure-preserving transformation $S : X \to X$, f</td>
      <td>http://arxiv.org/abs/2601.10459v1</td>
    </tr>
    <tr>
      <td>NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Although the Gradient Boosted Decision Trees (GBDTs) dominate industrial tabular applications, upgrading legacy models in high-concurrency production environments still faces prohibitive retraining costs and systemic risks. To address this problem, we present NSR-Boost, a neuro-symbolic residual boosting framework designed specifically for industrial scenarios. Its core advantage lies in being "non-intrusive". It treats the legacy model as a frozen model and performs targeted repairs on "hard re</td>
      <td>http://arxiv.org/abs/2601.10457v1</td>
    </tr>
    <tr>
      <td>PERM: Psychology-grounded Empathetic Reward Modeling for Large Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) are increasingly deployed in human-centric applications, yet they often fail to provide substantive emotional support. While Reinforcement Learning (RL) has been utilized to enhance empathy of LLMs, existing reward models typically evaluate empathy from a single perspective, overlooking the inherently bidirectional interaction nature of empathy between the supporter and seeker as defined by Empathy Cycle theory. To address this limitation, we propose Psychology-groun</td>
      <td>http://arxiv.org/abs/2601.10532v1</td>
    </tr>
    <tr>
      <td>Model See, Model Do? Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code LLMs</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large language models are increasingly used for code generation and debugging, but their outputs can still contain bugs, that originate from training data. Distinguishing whether an LLM prefers correct code, or a familiar incorrect version might be influenced by what it's been exposed to during training. We introduce an exposure-aware evaluation framework that quantifies how prior exposure to buggy versus fixed code influences a model's preference. Using the ManySStuBs4J benchmark, we apply Data</td>
      <td>http://arxiv.org/abs/2601.10496v1</td>
    </tr>
    <tr>
      <td>A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The rapid evolution of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has produced substantial gains in reasoning, perception, and generative capability across language and vision. However, whether these advances yield commensurate improvements in safety remains unclear, in part due to fragmented evaluation practices limited to single modalities or threat models. In this report, we present an integrated safety evaluation of 7 frontier models: GPT-5.2, Gemini 3 Pro, Qwe</td>
      <td>http://arxiv.org/abs/2601.10527v1</td>
    </tr>
    <tr>
      <td>Leveraging Digital Twin Technologies: All-Photonics Networks-as-a-Service for Data Center Xchange in the Era of AI [Invited Tutorial]</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This paper presents a data center exchange (Data Center Xchange, DCX) architecture for all-photonics networks-as-a-service in distributed data center infrastructures, enabling the creation of a virtual large-scale data center by directly interconnecting distributed data centers in metropolitan areas. Key requirements for such an architecture are identified: support for low-latency operations, scalability, reliability, and flexibility within a single network architecture; the ability to add new o</td>
      <td>http://arxiv.org/abs/2601.10153v1</td>
    </tr>
    <tr>
      <td>MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Artificial intelligence (AI) has the potential to transform medical imaging by automating image analysis and accelerating clinical research. However, research and clinical use are limited by the wide variety of AI implementations and architectures, inconsistent documentation, and reproducibility issues. Here, we introduce MHub.ai, an open-source, container-based platform that standardizes access to AI models with minimal configuration, promoting accessibility and reproducibility in medical imagi</td>
      <td>http://arxiv.org/abs/2601.10154v1</td>
    </tr>
    <tr>
      <td>ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>While LLM-based agents can interact with environments via invoking external tools, their expanded capabilities also amplify security risks. Monitoring step-level tool invocation behaviors in real time and proactively intervening before unsafe execution is critical for agent deployment, yet remains under-explored. In this work, we first construct TS-Bench, a novel benchmark for step-level tool invocation safety detection in LLM agents. We then develop a guardrail model, TS-Guard, using multi-task</td>
      <td>http://arxiv.org/abs/2601.10156v1</td>
    </tr>
    <tr>
      <td>Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Pretraining corpora contain extensive discourse about AI systems, yet the causal influence of this discourse on downstream alignment remains poorly understood. If prevailing descriptions of AI behaviour are predominantly negative, LLMs may internalise corresponding behavioural priors, giving rise to self-fulfilling misalignment. This paper provides the first controlled study of this hypothesis by pretraining 6.9B-parameter LLMs with varying amounts of (mis)alignment discourse. We find that discu</td>
      <td>http://arxiv.org/abs/2601.10160v1</td>
    </tr>
    <tr>
      <td>AWED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages for 6.6 Billion Speakers</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We introduce AWED-FiNER, an open-source ecosystem designed to bridge the gap in Fine-grained Named Entity Recognition (FgNER) for 36 global languages spoken by more than 6.6 billion people. While Large Language Models (LLMs) dominate general Natural Language Processing (NLP) tasks, they often struggle with low-resource languages and fine-grained NLP tasks. AWED-FiNER provides a collection of agentic toolkits, web applications, and several state-of-the-art expert models that provides FgNER soluti</td>
      <td>http://arxiv.org/abs/2601.10161v1</td>
    </tr>
    <tr>
      <td>CtD: Composition through Decomposition in Emergent Communication</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Compositionality is a cognitive mechanism that allows humans to systematically combine known concepts in novel ways. This study demonstrates how artificial neural agents acquire and utilize compositional generalization to describe previously unseen images. Our method, termed "Composition through Decomposition", involves two sequential training steps. In the 'Decompose' step, the agents learn to decompose an image into basic concepts using a codebook acquired during interaction in a multi-target</td>
      <td>http://arxiv.org/abs/2601.10169v1</td>
    </tr>
    <tr>
      <td>ReasAlign: Reasoning Enhanced Safety Alignment against Prompt Injection Attack</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) have enabled the development of powerful agentic systems capable of automating complex workflows across various fields. However, these systems are highly vulnerable to indirect prompt injection attacks, where malicious instructions embedded in external data can hijack agent behavior. In this work, we present ReasAlign, a model-level solution to improve safety alignment against indirect prompt injection attacks. The core idea of ReasAlign is to incorporate structured</td>
      <td>http://arxiv.org/abs/2601.10173v1</td>
    </tr>
    <tr>
      <td>Reinforcement Learning to Discover a NorthEast Monsoon Index for Monthly Rainfall Prediction in Thailand</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Climate prediction is a challenge due to the intricate spatiotemporal patterns within Earth systems. Global climate indices, such as the El Niño Southern Oscillation, are standard input features for long-term rainfall prediction. However, a significant gap persists regarding local-scale indices capable of improving predictive accuracy in specific regions of Thailand. This paper introduces a novel NorthEast monsoon climate index calculated from sea surface temperature to reflect the climatology o</td>
      <td>http://arxiv.org/abs/2601.10181v1</td>
    </tr>
    <tr>
      <td>Autonomous Quantum Simulation through Large Language Model Agents</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks. Tensor network methods are powerful tools for quantum simulation, but their effective use requires expertise typically acquired through years of graduate training. By combining in-context learning with curated documentation and multi-agent decomposition, we create autonomous AI agent</td>
      <td>http://arxiv.org/abs/2601.10194v1</td>
    </tr>
    <tr>
      <td>On the average-case complexity of learning states from the circular and Gaussian ensembles</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Studying the complexity of states sampled from various ensembles is a central component of quantum information theory. In this work we establish the average-case hardness of learning, in the statistical query model, the Born distributions of states sampled uniformly from the circular and (fermionic) Gaussian ensembles. These ensembles of states are induced variously by the uniform measures on the compact symmetric spaces of type AI, AII, and DIII. This finding complements analogous recent result</td>
      <td>http://arxiv.org/abs/2601.10197v1</td>
    </tr>
    <tr>
      <td>HUMANLLM: Benchmarking and Reinforcing LLM Anthropomorphism via Human Cognitive Patterns</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) have demonstrated remarkable capabilities in reasoning and generation, serving as the foundation for advanced persona simulation and Role-Playing Language Agents (RPLAs). However, achieving authentic alignment with human cognitive and behavioral patterns remains a critical challenge for these agents. We present HUMANLLM, a framework treating psychological patterns as interacting causal forces. We construct 244 patterns from ~12,000 academic papers and synthesize 11,3</td>
      <td>http://arxiv.org/abs/2601.10198v1</td>
    </tr>
    <tr>
      <td>Terrain-Adaptive Mobile 3D Printing with Hierarchical Control</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Mobile 3D printing on unstructured terrain remains challenging due to the conflict between platform mobility and deposition precision. Existing gantry-based systems achieve high accuracy but lack mobility, while mobile platforms struggle to maintain print quality on uneven ground. We present a framework that tightly integrates AI-driven disturbance prediction with multi-modal sensor fusion and hierarchical hardware control, forming a closed-loop perception-learning-actuation system. The AI modul</td>
      <td>http://arxiv.org/abs/2601.10208v1</td>
    </tr>
    <tr>
      <td>Agentic Pipelines in Embedded Software Engineering: Emerging Practices and Challenges</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>A new transformation is underway in software engineering, driven by the rapid adoption of generative AI in development workflows. Similar to how version control systems once automated manual coordination, AI tools are now beginning to automate many aspects of programming. For embedded software engineering organizations, however, this marks their first experience integrating AI into safety-critical and resource-constrained environments. The strict demands for determinism, reliability, and traceab</td>
      <td>http://arxiv.org/abs/2601.10220v1</td>
    </tr>
    <tr>
      <td>STEAMROLLER: A Multi-Agent System for Inclusive Automatic Speech Recognition for People who Stutter</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>People who stutter (PWS) face systemic exclusion in today's voice-driven society, where access to voice assistants, authentication systems, and remote work tools increasingly depends on fluent speech. Current automatic speech recognition (ASR) systems, trained predominantly on fluent speech, fail to serve millions of PWS worldwide. We present STEAMROLLER, a real time system that transforms stuttered speech into fluent output through a novel multi-stage, multi-agent AI pipeline. Our approach addr</td>
      <td>http://arxiv.org/abs/2601.10223v1</td>
    </tr>
    <tr>
      <td>Who Owns the Text? Design Patterns for Preserving Authorship in AI-Assisted Writing</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>AI writing assistants can reduce effort and improve fluency, but they may also weaken writers' sense of authorship. We study this tension with an ownership-aware co-writing editor that offers on-demand, sentence-level suggestions and tests two common design choices: persona-based coaching and style personalization. In an online study (N=176), participants completed three professional writing tasks: an email without AI help, a proposal with generic AI suggestions, and a cover letter with persona-</td>
      <td>http://arxiv.org/abs/2601.10236v1</td>
    </tr>
    <tr>
      <td>coTherapist: A Behavior-Aligned Small Language Model to Support Mental Healthcare Experts</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Access to mental healthcare is increasingly strained by workforce shortages and rising demand, motivating the development of intelligent systems that can support mental healthcare experts. We introduce coTherapist, a unified framework utilizing a small language model to emulate core therapeutic competencies through domain-specific fine-tuning, retrieval augmentation, and agentic reasoning. Evaluation on clinical queries demonstrates that coTherapist generates more relevant and clinically grounde</td>
      <td>http://arxiv.org/abs/2601.10246v1</td>
    </tr>
    <tr>
      <td>Developer Interaction Patterns with Proactive AI: A Five-Day Field Study</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Current in-IDE AI coding tools typically rely on time-consuming manual prompting and context management, whereas proactive alternatives that anticipate developer needs without explicit invocation remain underexplored. Understanding when humans are receptive to such proactive AI assistance during their daily work remains an open question in human-AI interaction research. We address this gap through a field study of proactive AI assistance in professional developer workflows. We present a five-day</td>
      <td>http://arxiv.org/abs/2601.10253v1</td>
    </tr>
    <tr>
      <td>Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent Tree-Query and Adversarial Confidence Estimation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Causal discovery aims to recover ``what causes what'', but classical constraint-based methods (e.g., PC, FCI) suffer from error propagation, and recent LLM-based causal oracles often behave as opaque, confidence-free black boxes. This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework that reduces pairwise causal discovery to a short sequence of queries about backdoor paths, (in)dependence, latent confounding, and causal direction, yielding interpretable judgments with ro</td>
      <td>http://arxiv.org/abs/2601.10137v1</td>
    </tr>
    <tr>
      <td>M^4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Generating molecules that satisfy precise numeric constraints over multiple physicochemical properties is critical and challenging. Although large language models (LLMs) are expressive, they struggle with precise multi-objective control and numeric reasoning without external structure and feedback. We introduce \textbf{M olGen}, a fragment-level, retrieval-augmented, two-stage framework for molecule generation under multi-property constraints. Stage I : Prototype generation: a multi-agent reason</td>
      <td>http://arxiv.org/abs/2601.10131v1</td>
    </tr>
    <tr>
      <td>LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Current multimodal latent reasoning often relies on external supervision (e.g., auxiliary images), ignoring intrinsic visual attention dynamics. In this work, we identify a critical Perception Gap in distillation: student models frequently mimic a teacher's textual output while attending to fundamentally divergent visual regions, effectively relying on language priors rather than grounded perception. To bridge this, we propose LaViT, a framework that aligns latent visual thoughts rather than sta</td>
      <td>http://arxiv.org/abs/2601.10129v1</td>
    </tr>
    <tr>
      <td>CALM-IT: Generating Realistic Long-Form Motivational Interviewing Dialogues with Dual-Actor Conversational Dynamics Tracking</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) are increasingly used in mental health-related settings, yet they struggle to sustain realistic, goal-directed dialogue over extended interactions. While LLMs generate fluent responses, they optimize locally for the next turn rather than maintaining a coherent model of therapeutic progress, leading to brittleness and long-horizon drift. We introduce CALM-IT, a framework for generating and evaluating long-form Motivational Interviewing (MI) dialogues that explicitly m</td>
      <td>http://arxiv.org/abs/2601.10085v1</td>
    </tr>
    <tr>
      <td>EHRNavigator: A Multi-Agent System for Patient-Level Clinical Question Answering over Heterogeneous Electronic Health Records</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Clinical decision-making increasingly relies on timely and context-aware access to patient information within Electronic Health Records (EHRs), yet most existing natural language question-answering (QA) systems are evaluated solely on benchmark datasets, limiting their practical relevance. To overcome this limitation, we introduce EHRNavigator, a multi-agent framework that harnesses AI agents to perform patient-level question answering across heterogeneous and multimodal EHR data. We assessed it</td>
      <td>http://arxiv.org/abs/2601.10020v1</td>
    </tr>
    <tr>
      <td>Structured Personality Control and Adaptation for LLM Agents</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) are increasingly shaping human-computer interaction (HCI), from personalized assistants to social simulations. Beyond language competence, researchers are exploring whether LLMs can exhibit human-like characteristics that influence engagement, decision-making, and perceived realism. Personality, in particular, is critical, yet existing approaches often struggle to achieve both nuanced and adaptable expression. We present a framework that models LLM personality via Ju</td>
      <td>http://arxiv.org/abs/2601.10025v1</td>
    </tr>
    <tr>
      <td>PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Academic paper search is a fundamental task in scientific research, yet most existing approaches rely on rigid, predefined workflows that struggle with complex, conditional queries. To address this limitation, we propose PaperScout, an autonomous agent that reformulates paper search as a sequential decision-making process. Unlike static workflows, PaperScout dynamically decides whether, when, and how to invoke search and expand tools based on accumulated retrieval context. However, training such</td>
      <td>http://arxiv.org/abs/2601.10029v1</td>
    </tr>
    <tr>
      <td>What Understanding Means in AI-Laden Astronomy</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Artificial intelligence is rapidly transforming astronomical research, yet the scientific community has largely treated this transformation as an engineering challenge rather than an epistemological one. This perspective article argues that philosophy of science offers essential tools for navigating AI's integration into astronomy--conceptual clarity about what "understanding" means, critical examination of assumptions about data and discovery, and frameworks for evaluating AI's roles across dif</td>
      <td>http://arxiv.org/abs/2601.10038v1</td>
    </tr>
    <tr>
      <td>Collective behavior based on agent-environment interactions</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We present a model of active particles interacting through a dynamic, heterogeneous environment, leading to emergent collective behaviors without direct agent-to-agent communication. Expanding the resource-dependent framework introduced in Briozzo et al., 2025, arXiv:2512.08762, agents perform a persistent random walk combined with chemotaxis, directing toward nutrient-rich patches, whose resources are generated by logistic regrowth. We identify distinct phases of collective organization, rangin</td>
      <td>http://arxiv.org/abs/2601.10046v1</td>
    </tr>
    <tr>
      <td>UEOF: A Benchmark Dataset for Underwater Event-Based Optical Flow</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Underwater imaging is fundamentally challenging due to wavelength-dependent light attenuation, strong scattering from suspended particles, turbidity-induced blur, and non-uniform illumination. These effects impair standard cameras and make ground-truth motion nearly impossible to obtain. On the other hand, event cameras offer microsecond resolution and high dynamic range. Nonetheless, progress on investigating event cameras for underwater environments has been limited due to the lack of datasets</td>
      <td>http://arxiv.org/abs/2601.10054v1</td>
    </tr>
    <tr>
      <td>Deriving Character Logic from Storyline as Codified Decision Trees</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Role-playing (RP) agents rely on behavioral profiles to act consistently across diverse narrative contexts, yet existing profiles are largely unstructured, non-executable, and weakly validated, leading to brittle agent behavior. We propose Codified Decision Trees (CDT), a data-driven framework that induces an executable and interpretable decision structure from large-scale narrative data. CDT represents behavioral profiles as a tree of conditional rules, where internal nodes correspond to valida</td>
      <td>http://arxiv.org/abs/2601.10080v1</td>
    </tr>
    <tr>
      <td>State of AI: An Empirical 100 Trillion Token Study with OpenRouter</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The past year has marked a turning point in the evolution and real-world use of large language models (LLMs). With the release of the first widely adopted reasoning model, o1, on December 5th, 2024, the field shifted from single-pass pattern generation to multi-step deliberation inference, accelerating deployment, experimentation, and new classes of applications. As this shift unfolded at a rapid pace, our empirical understanding of how these models have actually been used in practice has lagged</td>
      <td>http://arxiv.org/abs/2601.10088v1</td>
    </tr>
    <tr>
      <td>Fairness Driven Multi-Agent Path Finding Problem</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The Multi-Agent Path Finding (MAPF) problem aims at finding non-conflicting paths for multiple agents from their respective sources to destinations. This problem arises in multiple real-life situations, including robot motion planning and airspace assignment for unmanned aerial vehicle movement. The problem is computationally expensive, and adding to it, the agents are rational and can misreport their private information. In this paper, we study both variants of the problem under the realm of fa</td>
      <td>http://arxiv.org/abs/2601.10123v1</td>
    </tr>
    <tr>
      <td>Mark My Works Autograder for Programming Courses</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large programming courses struggle to provide timely, detailed feedback on student code. We developed Mark My Works, a local autograding system that combines traditional unit testing with LLM-generated explanations. The system uses role-based prompts to analyze submissions, critique code quality, and generate pedagogical feedback while maintaining transparency in its reasoning process. We piloted the system in a 191-student engineering course, comparing AI-generated assessments with human gradin</td>
      <td>http://arxiv.org/abs/2601.10093v1</td>
    </tr>
    <tr>
      <td>When Personas Override Payoffs: Role Identity Bias in Multi-Agent LLM Decision-Making</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large language models are increasingly deployed in multi-agent systems for strategic tasks, yet how design choices such as role-based personas and payoff visibility affect reasoning remains poorly understood. We investigate whether multi-agent systems function as strategic reasoners capable of payoff optimization or as identity-driven actors that prioritize role alignment over explicit incentives. Using Nash equilibrium achievement as a diagnostic for strategic reasoning, we conduct systematic e</td>
      <td>http://arxiv.org/abs/2601.10102v1</td>
    </tr>
    <tr>
      <td>FlowAct-R1: Towards Interactive Humanoid Video Generation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Interactive humanoid video generation aims to synthesize lifelike visual agents that can engage with humans through continuous and responsive video. Despite recent advances in video synthesis, existing methods often grapple with the trade-off between high-fidelity synthesis and real-time interaction requirements. In this paper, we propose FlowAct-R1, a framework specifically designed for real-time interactive humanoid video generation. Built upon a MMDiT architecture, FlowAct-R1 enables the stre</td>
      <td>http://arxiv.org/abs/2601.10103v1</td>
    </tr>
    <tr>
      <td>Multi-Constrained Evolutionary Molecular Design Framework: An Interpretable Drug Design Method Combining Rule-Based Evolution and Molecular Crossover</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This study proposes MCEMOL (Multi-Constrained Evolutionary Molecular Design Framework), a molecular optimization approach integrating rule-based evolution with molecular crossover. MCEMOL employs dual-layer evolution: optimizing transformation rules at rule level while applying crossover and mutation to molecular structures. Unlike deep learning methods requiring large datasets and extensive training, our algorithm evolves efficiently from minimal starting molecules with low computational overhe</td>
      <td>http://arxiv.org/abs/2601.10110v1</td>
    </tr>
    <tr>
      <td>Repository Intelligence Graph: Deterministic Architectural Map for LLM Code Assistants</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Repository aware coding agents often struggle to recover build and test structure, especially in multilingual projects where cross language dependencies are encoded across heterogeneous build systems and tooling. We introduce the Repository Intelligence Graph (RIG), a deterministic, evidence backed architectural map that represents buildable components, aggregators, runners, tests, external packages, and package managers, connected by explicit dependency and coverage edges that trace back to con</td>
      <td>http://arxiv.org/abs/2601.10112v1</td>
    </tr>
    <tr>
      <td>TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Optimizing communication topology in LLM-based multi-agent system is critical for enabling collective intelligence. Existing methods mainly rely on spatio-temporal interaction paradigms, where the sequential execution of multi-round dialogues incurs high latency and computation. Motivated by the recent insights that evaluation and debate mechanisms can improve problem-solving in multi-agent systems, we propose TopoDIM, a framework for one-shot Topology generation with Diverse Interaction Modes.</td>
      <td>http://arxiv.org/abs/2601.10120v1</td>
    </tr>
    <tr>
      <td>Role-Playing Agents Driven by Large Language Models: Current Status, Challenges, and Future Trends</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In recent years, with the rapid advancement of large language models (LLMs), role-playing language agents (RPLAs) have emerged as a prominent research focus at the intersection of natural language processing (NLP) and human-computer interaction. This paper systematically reviews the current development and key technologies of RPLAs, delineating the technological evolution from early rule-based template paradigms, through the language style imitation stage, to the cognitive simulation stage cente</td>
      <td>http://arxiv.org/abs/2601.10122v1</td>
    </tr>
    <tr>
      <td>Evolving with AI: A Longitudinal Analysis of Developer Logs</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>AI-powered coding assistants are rapidly becoming fixtures in professional IDEs, yet their sustained influence on everyday development remains poorly understood. Prior research has focused on short-term use or self-reported perceptions, leaving open questions about how sustained AI use reshapes actual daily coding practices in the long term. We address this gap with a mixed-method study of AI adoption in IDEs, combining longitudinal two-year fine-grained telemetry from 800 developers with a surv</td>
      <td>http://arxiv.org/abs/2601.10258v1</td>
    </tr>
    <tr>
      <td>MoST: Mixing Speech and Text with Modality-Aware Mixture of Experts</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We present MoST (Mixture of Speech and Text), a novel multimodal large language model that seamlessly integrates speech and text processing through our proposed Modality-Aware Mixture of Experts (MAMoE) architecture. While current multimodal models typically process diverse modality representations with identical parameters, disregarding their inherent representational differences, we introduce specialized routing pathways that direct tokens to modality-appropriate experts based on input type. M</td>
      <td>http://arxiv.org/abs/2601.10272v1</td>
    </tr>
    <tr>
      <td>Multipath Routing for Multi-Hop UAV Networks</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Multi-hop uncrewed aerial vehicle (UAV) networks are promising to extend the terrestrial network coverage. Existing multi-hop UAV networks employ a single routing path by selecting the next-hop forwarding node in a hop-by-hop manner, which leads to local congestion and increases traffic delays. In this paper, a novel traffic-adaptive multipath routing method is proposed for multi-hop UAV networks, which enables each UAV to dynamically split and forward traffic flows across multiple next-hop neig</td>
      <td>http://arxiv.org/abs/2601.10299v1</td>
    </tr>
    <tr>
      <td>Mitigating GIL Bottlenecks in Edge AI Systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Deploying Python based AI agents on resource-constrained edge devices presents a runtime optimization challenge: high thread counts are needed to mask I/O latency, yet Python's Global Interpreter Lock (GIL) serializes execution. We demonstrate that naive thread-pool scaling causes a "saturation cliff": &gt;= 20% throughput degradation at overprovisioned thread counts (N &gt;= 512) on edge-representative configurations. We present a lightweight profiling tool and adaptive runtime system using a Blockin</td>
      <td>http://arxiv.org/abs/2601.10582v1</td>
    </tr>
    <tr>
      <td>On the suboptimality of linear codes for binary distributed hypothesis testing</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We study a binary distributed hypothesis testing problem where two agents observe correlated binary vectors and communicate compressed information at the same rate to a central decision maker. In particular, we study linear compression schemes and show that simple truncation is the best linear scheme in two cases: (1) testing opposite signs of the same magnitude of correlation, and (2) testing for or against independence. We conjecture, supported by numerical evidence, that truncation is the bes</td>
      <td>http://arxiv.org/abs/2601.10526v1</td>
    </tr>
    <tr>
      <td>SVII-3D: Advancing Roadside Infrastructure Inventory with Decimeter-level 3D Localization and Comprehension from Sparse Street Imagery</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The automated creation of digital twins and precise asset inventories is a critical task in smart city construction and facility lifecycle management. However, utilizing cost-effective sparse imagery remains challenging due to limited robustness, inaccurate localization, and a lack of fine-grained state understanding. To address these limitations, SVII-3D, a unified framework for holistic asset digitization, is proposed. First, LoRA fine-tuned open-set detection is fused with a spatial-attention</td>
      <td>http://arxiv.org/abs/2601.10535v1</td>
    </tr>
    <tr>
      <td>Unleashing the Capabilities of Large Vision-Language Models for Intelligent Perception of Roadside Infrastructure</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Automated perception of urban roadside infrastructure is crucial for smart city management, yet general-purpose models often struggle to capture the necessary fine-grained attributes and domain rules. While Large Vision Language Models (VLMs) excel at open-world recognition, they often struggle to accurately interpret complex facility states in compliance with engineering standards, leading to unreliable performance in real-world applications. To address this, we propose a domain-adapted framewo</td>
      <td>http://arxiv.org/abs/2601.10551v1</td>
    </tr>
    <tr>
      <td>Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Multi-agent systems (MAS) enable complex reasoning by coordinating multiple agents, but often incur high inference latency due to multi-step execution and repeated model invocations, severely limiting their scalability and usability in time-sensitive scenarios. Most existing approaches primarily optimize task performance and inference cost, and explicitly or implicitly assume sequential execution, making them less optimal for controlling latency under parallel execution. In this work, we investi</td>
      <td>http://arxiv.org/abs/2601.10560v1</td>
    </tr>
    <tr>
      <td>Process-Guided Concept Bottleneck Model</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this, we propose the Process-Guided Concept Bottleneck Model (PG-CBM), an extension of CBMs which constrains</td>
      <td>http://arxiv.org/abs/2601.10562v1</td>
    </tr>
    <tr>
      <td>Generative AI collective behavior needs an interactionist paradigm</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning--motivates the need for an interact</td>
      <td>http://arxiv.org/abs/2601.10567v1</td>
    </tr>
    <tr>
      <td>From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate Gen</td>
      <td>http://arxiv.org/abs/2601.10581v1</td>
    </tr>
    <tr>
      <td>ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of uncertainty, or lack principled calibration mechanisms. While recent TSFMs employ sophisticated tech</td>
      <td>http://arxiv.org/abs/2601.10591v1</td>
    </tr>
    <tr>
      <td>Breaking Up with Normatively Monolithic Agency with GRACE: A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>As AI agents become increasingly autonomous, widely deployed in consequential contexts, and efficacious in bringing about real-world impacts, ensuring that their decisions are not only instrumentally effective but also normatively aligned has become critical. We introduce a neuro-symbolic reason-based containment architecture, Governor for Reason-Aligned ContainmEnt (GRACE), that decouples normative reasoning from instrumental decision-making and can contain AI agents of virtually any design. GR</td>
      <td>http://arxiv.org/abs/2601.10520v1</td>
    </tr>
    <tr>
      <td>Search for sub-GeV dark particles in $η\toπ^0+\rm{invisible}$ decay</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Using (10087$\pm$44)$\times$10$^{6}$ $J/ψ$ events collected with the BESIII detector at the BEPCII collider at the center-of-mass energy of $\sqrt{s}=3.097~\rm{GeV}$, we report the first search for $η\toπ^0S\toπ^0χ\barχ$ with $S$ denotes an on-shell dark scalar boson and $χ$ an invisible dark matter particle. No significant signals are observed with $S$ mass ranging from 0 to 400 $\rm{MeV}/c^2$. The upper limits on the branching fractions and the new physics coupling strengths between $S$ and qu</td>
      <td>http://arxiv.org/abs/2601.10597v1</td>
    </tr>
    <tr>
      <td>Institutional AI: A Governance Framework for Distributional AGI Safety</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>As LLM-based systems increasingly operate as agents embedded within human social and technical systems, alignment can no longer be treated as a property of an isolated model, but must be understood in relation to the environments in which these agents act. Even the most sophisticated methods of alignment, such as Reinforcement Learning through Human Feedback (RHLF) or through AI Feedback (RLAIF) cannot ensure control once internal goal structures diverge from developer intent. We identify three</td>
      <td>http://arxiv.org/abs/2601.10599v1</td>
    </tr>
    <tr>
      <td>Procedural Fairness in Multi-Agent Bandits</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides equal decision-making power for all agents, lies in the core, and provides for proportionality in outcom</td>
      <td>http://arxiv.org/abs/2601.10600v1</td>
    </tr>
    <tr>
      <td>RoutIR: Fast Serving of Retrieval Pipelines for Retrieval-Augmented Generation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Retrieval models are key components of Retrieval-Augmented Generation (RAG) systems, which generate search queries, process the documents returned, and generate a response. RAG systems are often dynamic and may involve multiple rounds of retrieval. While many state-of-the-art retrieval methods are available through academic IR platforms, these platforms are typically designed for the Cranfield paradigm in which all queries are known up front and can be batch processed offline. This simplificatio</td>
      <td>http://arxiv.org/abs/2601.10644v1</td>
    </tr>
    <tr>
      <td>PACEvolve: Enabling Long-Horizon Progress-Aware Consistent Evolution</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) have emerged as powerful operators for evolutionary search, yet the design of efficient search scaffolds remains ad hoc. While promising, current LLM-in-the-loop systems lack a systematic approach to managing the evolutionary process. We identify three distinct failure modes: Context Pollution, where experiment history biases future candidate generation; Mode Collapse, where agents stagnate in local minima due to poor exploration-exploitation balance; and Weak Collab</td>
      <td>http://arxiv.org/abs/2601.10657v1</td>
    </tr>
    <tr>
      <td>On the origin of neural scaling laws: from random graphs to natural language</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this paper we study scaling laws for transformers trained to predict random walks (bigrams) on graphs with</td>
      <td>http://arxiv.org/abs/2601.10684v1</td>
    </tr>
    <tr>
      <td>The Conversational Exam: A Scalable Assessment Design for the AI Era</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Traditional assessment methods collapse when students use generative AI to complete work without genuine engagement, creating an illusion of competence where they believe they're learning but aren't. This paper presents the conversational exam -- a scalable oral examination format that restores assessment validity by having students code live while explaining their reasoning. Drawing on human-computer interaction principles, we examined 58 students in small groups across just two days, demonstra</td>
      <td>http://arxiv.org/abs/2601.10691v1</td>
    </tr>
    <tr>
      <td>Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The practice of fine-tuning Large Language Models (LLMs) has achieved state-of-the-art performance on specialized tasks, yet diagnosing why these models become brittle and fail to generalize remains a critical open problem. To address this, we introduce and apply a multi-layered diagnostic framework to a cross-architectural study. We fine-tune Llama 3.1 8B, Gemma 2 9B, and Mistral models on a high-stakes phishing detection task and use SHAP analysis and mechanistic interpretability to uncover th</td>
      <td>http://arxiv.org/abs/2601.10524v1</td>
    </tr>
    <tr>
      <td>DR-Arena: an Automated Evaluation Framework for Deep Research Agents</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>As Large Language Models (LLMs) increasingly operate as Deep Research (DR) Agents capable of autonomous investigation and information synthesis, reliable evaluation of their task performance has become a critical bottleneck. Current benchmarks predominantly rely on static datasets, which suffer from several limitations: limited task generality, temporal misalignment, and data contamination. To address these, we introduce DR-Arena, a fully automated evaluation framework that pushes DR agents to t</td>
      <td>http://arxiv.org/abs/2601.10504v1</td>
    </tr>
    <tr>
      <td>The Straight and Narrow: Do LLMs Possess an Internal Moral Path?</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Enhancing the moral alignment of Large Language Models (LLMs) is a critical challenge in AI safety. Current alignment techniques often act as superficial guardrails, leaving the intrinsic moral representations of LLMs largely untouched. In this paper, we bridge this gap by leveraging Moral Foundations Theory (MFT) to map and manipulate the fine-grained moral landscape of LLMs. Through cross-lingual linear probing, we validate the shared nature of moral representations in middle layers and uncove</td>
      <td>http://arxiv.org/abs/2601.10307v1</td>
    </tr>
    <tr>
      <td>Advanced Manufacturing with Renewable and Bio-based Materials: AI/ML workflows and Process Optimization</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Advanced manufacturing with new bio-derived materials can be achieved faster and more economically with first-principle-based artificial intelligence and machine learning (AI/ML)-derived models and process optimization. Not only is this motivated by increased industry profitability, but it can also be optimized to reduce waste generation, energy consumption, and gas emissions through additive manufacturing (AM) and AI/ML-directed self-driving laboratory (SDL) process optimization. From this pers</td>
      <td>http://arxiv.org/abs/2601.10382v1</td>
    </tr>
    <tr>
      <td>Multimessenger Prospects for Low-Luminosity Gamma-Ray Bursts: Joint Neutrino and X-Ray Observations</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Low--luminosity gamma-ray bursts (LLGRBs) are promising candidates for high-energy neutrinos, yet no coincident neutrino events have been detected so far. Recent advances in X-ray time-domain astronomy, together with the development of next-generation neutrino telescopes, open new opportunities for joint X-ray and neutrino observations of these transients. We calculate the jet dynamical evolution and the associated neutrino production for both non-magnetized and magnetized outflows. For individu</td>
      <td>http://arxiv.org/abs/2601.10317v1</td>
    </tr>
    <tr>
      <td>Agent Skills in the Wild: An Empirical Study of Security Vulnerabilities at Scale</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The rise of AI agent frameworks has introduced agent skills, modular packages containing instructions and executable code that dynamically extend agent capabilities. While this architecture enables powerful customization, skills execute with implicit trust and minimal vetting, creating a significant yet uncharacterized attack surface. We conduct the first large-scale empirical security analysis of this emerging ecosystem, collecting 42,447 skills from two major marketplaces and systematically an</td>
      <td>http://arxiv.org/abs/2601.10338v1</td>
    </tr>
    <tr>
      <td>C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Heart rate variability (HRV) is a pivotal noninvasive marker for autonomic monitoring; however, applying Large Language Models (LLMs) to HRV interpretation is hindered by physiological hallucinations. These include respiratory sinus arrhythmia (RSA) contamination, short-data instability in nonlinear metrics, and the neglect of individualized baselines in favor of population norms. We propose C-GRASP (Clinically-Grounded Reasoning for Affective Signal Processing), a guardrailed RAG-enhanced pipel</td>
      <td>http://arxiv.org/abs/2601.10342v1</td>
    </tr>
    <tr>
      <td>OctoBench: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Modern coding scaffolds turn LLMs into capable software agents, but their ability to follow scaffold-specified instructions remains under-examined, especially when constraints are heterogeneous and persist across interactions. To fill this gap, we introduce OctoBench, which benchmarks scaffold-aware instruction following in repository-grounded agentic coding. OctoBench includes 34 environments and 217 tasks instantiated under three scaffold types, and is paired with 7,098 objective checklist ite</td>
      <td>http://arxiv.org/abs/2601.10343v1</td>
    </tr>
    <tr>
      <td>SuS: Strategy-aware Surprise for Intrinsic Exploration</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning. Unlike traditional curiosity-driven methods that rely solely on state prediction error, SuS introduces two complementary components: Strategy Stability (SS) and Strategy Surprise (SuS). SS measures consistency in behavioral strategy across temporal steps, while SuS captures unexpected outcomes relative to the agent'</td>
      <td>http://arxiv.org/abs/2601.10349v1</td>
    </tr>
    <tr>
      <td>Unlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Enabling Large Language Models (LLMs) to effectively utilize tools in multi-turn interactions is essential for building capable autonomous agents. However, acquiring diverse and realistic multi-turn tool-use data remains a significant challenge. In this work, we propose a novel text-based paradigm. We observe that textual corpora naturally contain rich, multi-step problem-solving experiences, which can serve as an untapped, scalable, and authentic data source for multi-turn tool-use tasks. Based</td>
      <td>http://arxiv.org/abs/2601.10355v1</td>
    </tr>
    <tr>
      <td>Inverse Learning in $2\times2$ Games: From Synthetic Interactions to Traffic Simulation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Understanding how agents coordinate or compete from limited behavioral data is central to modeling strategic interactions in traffic, robotics, and other multi-agent systems. In this work, we investigate the following complementary formulations of inverse game-theoretic learning: (i) a Closed-form Correlated Equilibrium Maximum-Likelihood estimator (CE-ML) specialized for $2\times2$ games; and (ii) a Logit Best Response Maximum-Likelihood estimator (LBR-ML) that captures long-run adaptation dyna</td>
      <td>http://arxiv.org/abs/2601.10367v1</td>
    </tr>
    <tr>
      <td>INDIC DIALECT: A Multi Task Benchmark to Evaluate and Translate in Indian Language Dialects</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Recent NLP advances focus primarily on standardized languages, leaving most low-resource dialects under-served especially in Indian scenarios. In India, the issue is particularly important: despite Hindi being the third most spoken language globally (over 600 million speakers), its numerous dialects remain underrepresented. The situation is similar for Odia, which has around 45 million speakers. While some datasets exist which contain standard Hindi and Odia languages, their regional dialects ha</td>
      <td>http://arxiv.org/abs/2601.10388v1</td>
    </tr>
    <tr>
      <td>Job Anxiety in Post-Secondary Computer Science Students Caused by Artificial Intelligence</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The emerging widespread usage of AI has led to industry adoption to improve efficiency and increase earnings. However, a major consequence of this is AI displacing employees from their jobs, leading to feelings of job insecurity and uncertainty. This is especially true for computer science students preparing to enter the workforce. To investigate this, we performed semi-structured interviews with (n = 25) students across computer science undergraduate and graduate programs at the University of T</td>
      <td>http://arxiv.org/abs/2601.10468v1</td>
    </tr>
    <tr>
      <td>Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The advancement of artificial intelligence toward agentic science is currently bottlenecked by the challenge of ultra-long-horizon autonomy, the ability to sustain strategic coherence and iterative correction over experimental cycles spanning days or weeks. While Large Language Models (LLMs) have demonstrated prowess in short-horizon reasoning, they are easily overwhelmed by execution details in the high-dimensional, delayed-feedback environments of real-world research, failing to consolidate sp</td>
      <td>http://arxiv.org/abs/2601.10402v1</td>
    </tr>
    <tr>
      <td>CS-GBA: A Critical Sample-based Gradient-guided Backdoor Attack for Offline Reinforcement Learning</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to backdoor attacks. Existing attack strategies typically struggle against safety-constrained algorithms (e.g., CQL) due to inefficient random poisoning and the use of easily detectable Out-of-Distribution (OOD) triggers. In this paper, we propose CS-GBA (Critical Sample-based Gradient-guided Backdoor Attack), a novel framework designed to achieve high stealthiness and destructivenes</td>
      <td>http://arxiv.org/abs/2601.10407v1</td>
    </tr>
    <tr>
      <td>Reinforcement Learning with Multi-Step Lookahead Information Via Adaptive Batching</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We study tabular reinforcement learning problems with multiple steps of lookahead information. Before acting, the learner observes $\ell$ steps of future transition and reward realizations: the exact state the agent would reach and the rewards it would collect under any possible course of action. While it has been shown that such information can drastically boost the value, finding the optimal policy is NP-hard, and it is common to apply one of two tractable heuristics: processing the lookahead</td>
      <td>http://arxiv.org/abs/2601.10418v1</td>
    </tr>
    <tr>
      <td>Development of Ontological Knowledge Bases by Leveraging Large Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Ontological Knowledge Bases (OKBs) play a vital role in structuring domain-specific knowledge and serve as a foundation for effective knowledge management systems. However, their traditional manual development poses significant challenges related to scalability, consistency, and adaptability. Recent advancements in Generative AI, particularly Large Language Models (LLMs), offer promising solutions for automating and enhancing OKB development. This paper introduces a structured, iterative methodo</td>
      <td>http://arxiv.org/abs/2601.10436v1</td>
    </tr>
    <tr>
      <td>AgentGuardian: Learning Access Control Policies to Govern AI Agent Behavior</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Artificial intelligence (AI) agents are increasingly used in a variety of domains to automate tasks, interact with users, and make decisions based on data inputs. Ensuring that AI agents perform only authorized actions and handle inputs appropriately is essential for maintaining system integrity and preventing misuse. In this study, we introduce the AgentGuardian, a novel security framework that governs and protects AI agent operations by enforcing context-aware access-control policies. During a</td>
      <td>http://arxiv.org/abs/2601.10440v1</td>
    </tr>
    <tr>
      <td>ChartComplete: A Taxonomy-based Inclusive Chart Dataset</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>With advancements in deep learning (DL) and computer vision techniques, the field of chart understanding is evolving rapidly. In particular, multimodal large language models (MLLMs) are proving to be efficient and accurate in understanding charts. To accurately measure the performance of MLLMs, the research community has developed multiple datasets to serve as benchmarks. By examining these datasets, we found that they are all limited to a small set of chart types. To bridge this gap, we propose</td>
      <td>http://arxiv.org/abs/2601.10462v1</td>
    </tr>
    <tr>
      <td>AI Sycophancy: How Users Flag and Respond</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>While concerns about LLM sycophancy have grown among researchers and developers, how users themselves experience this behavior remains largely unexplored. We analyze Reddit discussions to investigate how users detect, mitigate, and perceive sycophantic AI. We develop the ODR Framework that maps user experiences across three stages: observing sycophantic behaviors, detecting sycophancy, and responding to these behaviors. Our findings reveal that users employ various detection techniques, includin</td>
      <td>http://arxiv.org/abs/2601.10467v1</td>
    </tr>
    <tr>
      <td>Empowering Older Adults in Digital Technology Use with Foundation Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>While high-quality technology support can assist older adults in using digital applications, many struggle to articulate their issues due to unfamiliarity with technical terminology and age-related cognitive changes. This study examines these communication challenges and explores AI-based approaches to mitigate them. We conducted a diary study with English-speaking, community-dwelling older adults to collect asynchronous, technology-related queries and used reflexive thematic analysis to identif</td>
      <td>http://arxiv.org/abs/2601.10018v1</td>
    </tr>
    <tr>
      <td>PID-Guided Partial Alignment for Multimodal Decentralized Federated Learning</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Multimodal decentralized federated learning (DFL) is challenging because agents differ in available modalities and model architectures, yet must collaborate over peer-to-peer (P2P) networks without a central coordinator. Standard multimodal pipelines learn a single shared embedding across all modalities. In DFL, such a monolithic representation induces gradient misalignment between uni- and multimodal agents; as a result, it suppresses heterogeneous sharing and cross-modal interaction. We presen</td>
      <td>http://arxiv.org/abs/2601.10012v1</td>
    </tr>
    <tr>
      <td>SoK: Privacy-aware LLM in Healthcare: Threat Model, Privacy Techniques, Challenges and Recommendations</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) are increasingly adopted in healthcare to support clinical decision-making, summarize electronic health records (EHRs), and enhance patient care. However, this integration introduces significant privacy and security challenges, driven by the sensitivity of clinical data and the high-stakes nature of medical workflows. These risks become even more pronounced across heterogeneous deployment environments, ranging from small on-premise hospital systems to regional health</td>
      <td>http://arxiv.org/abs/2601.10004v1</td>
    </tr>
    <tr>
      <td>Action100M: A Large-scale Video Action Dataset</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Inferring physical actions from visual observations is a fundamental capability for advancing machine intelligence in the physical world. Achieving this requires large-scale, open-vocabulary video action datasets that span broad domains. We introduce Action100M, a large-scale dataset constructed from 1.2M Internet instructional videos (14.6 years of duration), yielding O(100 million) temporally localized segments with open-vocabulary action supervision and rich captions. Action100M is generated</td>
      <td>http://arxiv.org/abs/2601.10592v1</td>
    </tr>
    <tr>
      <td>Synchronization and Hopf Bifurcation in Stuart--Landau Networks</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The Kuramoto model has shaped our understanding of synchronization in complex systems, yet its phase-only formulation neglects amplitude dynamics that are intrinsic to many oscillatory networks. In this work, we revisit Kuramoto-type synchronization through networks of Stuart--Landau oscillators, which arise as the universal normal form near a Hopf bifurcation. For identical natural frequencies, we analyze synchronization in two complementary regimes. Away from criticality, we establish topology</td>
      <td>http://arxiv.org/abs/2601.10234v1</td>
    </tr>
    <tr>
      <td>Tables or Sankey Diagrams? Investigating User Interaction with Different Representations of Simulation Parameters</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Understanding complex parameter dependencies is critical for effective configuration and maintenance of software systems across diverse domains - from Computer-Aided Engineering (CAE) to cloud infrastructure and database management. However, legacy tabular interfaces create a major bottleneck: engineers cannot easily comprehend how parameters relate across the system, leading to inefficient workflows, costly configuration errors, and reduced system trust - a fundamental program comprehension cha</td>
      <td>http://arxiv.org/abs/2601.10232v1</td>
    </tr>
    <tr>
      <td>Integral Variable Range Hopping for Modeling Electrical Transport in Disordered Systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The variable range hopping (VRH) model has been widely applied to describe electrical transport in disordered systems, providing theoretical formulas to fit temperature-dependent electric conductivity. These models rely on oversimplified assumptions that restrict their applicability and result in problematic fitting behaviors, yet their overusing situation is becoming increasingly serious. In this work we formulate an integral variable range hopping (IVRH) model, which replaces the empirical tem</td>
      <td>http://arxiv.org/abs/2601.10226v1</td>
    </tr>
    <tr>
      <td>UFO Trees: Practical and Provably-Efficient Parallel Batch-Dynamic Trees</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The dynamic trees problem is to maintain a tree under edge updates while supporting queries like connectivity queries or path queries. Despite the first data structure for this fundamental problem -- the link-cut tree -- being invented 40 years ago, our experiments reveal that they are still the fastest sequential data structure for the problem. However, link-cut trees cannot support parallel batch-dynamic updates and have limitations on the kinds of queries they support. In this paper, we desig</td>
      <td>http://arxiv.org/abs/2601.10706v1</td>
    </tr>
    <tr>
      <td>Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only one unknown cell. We attribute this failure to the violation of the fixed point property, a fundamen</td>
      <td>http://arxiv.org/abs/2601.10679v1</td>
    </tr>
    <tr>
      <td>Adjusted Similarity Measures and a Violation of Expectations</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Adjusted similarity measures, such as Cohen's kappa for inter-rater reliability and the adjusted Rand index used to compare clustering algorithms, are a vital tool for comparing discrete labellings. These measures are intended to have the property of 0 expectation under a null distribution and maximum value 1 under maximal similarity to aid in interpretation. Measures are frequently adjusted with respect to the permutation distribution for historic and analytic reasons. There is currently renewe</td>
      <td>http://arxiv.org/abs/2601.10641v1</td>
    </tr>
    <tr>
      <td>STEM: Scaling Transformers with Embedding Modules</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Fine-grained sparsity promises higher parametric capacity without proportional per-token compute, but often suffers from training instability, load balancing, and communication overhead. We introduce STEM (Scaling Transformers with Embedding Modules), a static, token-indexed approach that replaces the FFN up-projection with a layer-local embedding lookup while keeping the gate and down-projection dense. This removes runtime routing, enables CPU offload with asynchronous prefetch, and decouples c</td>
      <td>http://arxiv.org/abs/2601.10639v1</td>
    </tr>
    <tr>
      <td>Urban Socio-Semantic Segmentation with Vision-Language Reasoning</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>As hubs of human activity, urban surfaces consist of a wealth of semantic entities. Segmenting these various entities from satellite imagery is crucial for a range of downstream applications. Current advanced segmentation models can reliably segment entities defined by physical attributes (e.g., buildings, water bodies) but still struggle with socially defined categories (e.g., schools, parks). In this work, we achieve socio-semantic segmentation by vision-language model reasoning. To facilitate</td>
      <td>http://arxiv.org/abs/2601.10477v1</td>
    </tr>
    <tr>
      <td>Cell Behavior Video Classification Challenge, a benchmark for computer vision methods in time-lapse microscopy</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The classification of microscopy videos capturing complex cellular behaviors is crucial for understanding and quantifying the dynamics of biological processes over time. However, it remains a frontier in computer vision, requiring approaches that effectively model the shape and motion of objects without rigid boundaries, extract hierarchical spatiotemporal features from entire image sequences rather than static frames, and account for multiple objects within the field of view. To this end, we or</td>
      <td>http://arxiv.org/abs/2601.10250v1</td>
    </tr>
    <tr>
      <td>RSA-Bench: Benchmarking Audio Large Models in Real-World Acoustic Scenarios</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>While Audio Large Models (ALMs) have achieved remarkable proficiency, their robustness remains brittle in real-world deployment. Existing evaluations largely rely on synthetic Gaussian noise or simplistic single-source interference, failing to capture the intricate, multi-layered acoustic dynamics -- or ``Acoustic Ecology'' -- that characterize authentic physical environments. To bridge this ecological gap, we introduce \textbf{RSA-Bench}, a comprehensive robustness benchmark designed to stress-</td>
      <td>http://arxiv.org/abs/2601.10384v1</td>
    </tr>
    <tr>
      <td>EvoMorph: Counterfactual Explanations for Continuous Time-Series Extrinsic Regression Applied to Photoplethysmography</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Wearable devices enable continuous, population-scale monitoring of physiological signals, such as photoplethysmography (PPG), creating new opportunities for data-driven clinical assessment. Time-series extrinsic regression (TSER) models increasingly leverage PPG signals to estimate clinically relevant outcomes, including heart rate, respiratory rate, and oxygen saturation. For clinical reasoning and trust, however, single point estimates alone are insufficient: clinicians must also understand wh</td>
      <td>http://arxiv.org/abs/2601.10356v1</td>
    </tr>
    <tr>
      <td>Training-Trajectory-Aware Token Selection</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Efficient distillation is a key pathway for converting expensive reasoning capability into deployable efficiency, yet in the frontier regime where the student already has strong reasoning ability, naive continual distillation often yields limited gains or even degradation. We observe a characteristic training phenomenon: even as loss decreases monotonically, all performance metrics can drop sharply at almost the same bottleneck, before gradually recovering. We further uncover a token-level mecha</td>
      <td>http://arxiv.org/abs/2601.10348v1</td>
    </tr>
    <tr>
      <td>Boundary-Aware NL2SQL: Integrating Reliability through Hybrid Reward and Data Synthesis</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In this paper, we present BAR-SQL (Boundary-Aware Reliable NL2SQL), a unified training framework that embeds reliability and boundary awareness directly into the generation process. We introduce a Seed Mutation data synthesis paradigm that constructs a representative enterprise corpus, explicitly encompassing multi-step analytical queries alongside boundary cases including ambiguity and schema limitations. To ensure interpretability, we employ Knowledge-Grounded Reasoning Synthesis, which produc</td>
      <td>http://arxiv.org/abs/2601.10318v1</td>
    </tr>
    <tr>
      <td>Cycle dependence of helioseismic oscillations above the acoustic cut-off frequency</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Helioseismic and recent asteroseismic observations reveal fine structure in the power spectrum with alternating peaks and troughs above the acoustic cut-off frequency. This structure is interpreted as the interference patterns of high-frequency acoustic waves excited in the solar interior and propagating into the atmosphere, known as pseudomodes. Pseudomodes exhibit clear solar-cycle variability, with frequency shifts that occur predominantly in anti-phase with the activity cycle, although the u</td>
      <td>http://arxiv.org/abs/2601.10283v1</td>
    </tr>
    <tr>
      <td>Credit C-GPT: A Domain-Specialized Large Language Model for Conversational Understanding in Vietnamese Debt Collection</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Debt collection is a critical function within the banking, financial services, and insurance (BFSI) sector, relying heavily on large-scale human-to-human conversational interactions conducted primarily in Vietnamese contact centers. These conversations involve informal spoken language, emotional variability, and complex domain-specific reasoning, which pose significant challenges for traditional natural language processing systems. This paper introduces Credit C-GPT, a domain-specialized large l</td>
      <td>http://arxiv.org/abs/2601.10167v1</td>
    </tr>
    <tr>
      <td>Advancing Adaptive Multi-Stage Video Anomaly Reasoning: A Benchmark Dataset and Method</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Recent progress in reasoning capabilities of Multimodal Large Language Models(MLLMs) has highlighted their potential for performing complex video understanding tasks. However, in the domain of Video Anomaly Detection and Understanding (VAD&amp;U), existing MLLM-based methods are largely limited to anomaly localization or post-hoc description, lacking explicit reasoning processes, risk awareness, and decision-oriented interpretation. To address this gap, we define a new task termed Video Anomaly Reas</td>
      <td>http://arxiv.org/abs/2601.10165v1</td>
    </tr>
    <tr>
      <td>A flower theorem in $\mathbb{C}^n$</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We prove an analog of the flower theorem for non-degenerate reduced tangent to the identity germs that fix the coordinate hyperspaces in any dimension.</td>
      <td>http://arxiv.org/abs/2601.10235v1</td>
    </tr>
    <tr>
      <td>Controllability score for linear time-invariant systems on an infinite time horizon</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We introduce a scaled controllability Gramian that can be computed reliably even for unstable systems. Using this scaled Gramian, we reformulate the controllability scoring problems into equivalent but numerically stable optimization problems. Their optimal solutions define dynamics-aware network centrality measures, referred to as the volumetric controllability score (VCS) and the average energy controllability score (AECS). We then formulate controllability scoring problems on an infinite time</td>
      <td>http://arxiv.org/abs/2601.10260v1</td>
    </tr>
    <tr>
      <td>Skill-Aware Data Selection and Fine-Tuning for Data-Efficient Reasoning Distillation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large reasoning models such as DeepSeek-R1 and their distilled variants achieve strong performance on complex reasoning tasks. Yet, distilling these models often demands large-scale data for supervised fine-tuning (SFT), motivating the pursuit of data-efficient training methods. To address this, we propose a skill-centric distillation framework that efficiently transfers reasoning ability to weaker models with two components: (1) Skill-based data selection, which prioritizes examples targeting t</td>
      <td>http://arxiv.org/abs/2601.10109v1</td>
    </tr>
    <tr>
      <td>CURVE: A Benchmark for Cultural and Multilingual Long Video Reasoning</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Recent advancements in video models have shown tremendous progress, particularly in long video understanding. However, current benchmarks predominantly feature western-centric data and English as the dominant language, introducing significant biases in evaluation. To address this, we introduce CURVE (Cultural Understanding and Reasoning in Video Evaluation), a challenging benchmark for multicultural and multilingual video reasoning. CURVE comprises high-quality, entirely human-generated annotati</td>
      <td>http://arxiv.org/abs/2601.10649v1</td>
    </tr>
    <tr>
      <td>Flat-band Ferromagnetism of SU$(N)$ Hubbard Model on the Kagome Lattices</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The kagome lattice, a well known example of the geometrically frustrated system, hosts a dispersionless flat band that offers a unique platform for studying correlation-driven quantum phenomena. At appropriate particle concentrations, the existence of a flat band allows a representation of percolation with nontrivial weights. In this work, we investigate the paramagnetic-ferromagnetic transition in the repulsive SU($N$) Hubbard model on the kagome lattice within this percolation framework. In th</td>
      <td>http://arxiv.org/abs/2601.10549v1</td>
    </tr>
    <tr>
      <td>Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large language models (LLMs) have achieved impressive performance across natural language tasks and are increasingly deployed in real-world applications. Despite extensive safety alignment efforts, recent studies show that such alignment is often shallow and remains vulnerable to jailbreak attacks. Existing defense mechanisms, including decoding-based constraints and post-hoc content detectors, struggle against sophisticated jailbreaks, often intervening robust detection or excessively degrading</td>
      <td>http://arxiv.org/abs/2601.10543v1</td>
    </tr>
    <tr>
      <td>HeartMuLa: A Family of Open Sourced Music Foundation Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We present a family of open-source Music Foundation Models designed to advance large-scale music understanding and generation across diverse tasks and modalities. Our framework consists of four major components: (1) HeartCLAP, an audio-text alignment model; (2) HeartTranscriptor, a robust lyric recognition model optimized for real-world music scenarios; and (3) HeartCodec, a low-frame-rate (12.5 Hz) yet high-fidelity music codec tokenizer that captures long-range musical structure while preservi</td>
      <td>http://arxiv.org/abs/2601.10547v1</td>
    </tr>
    <tr>
      <td>Representation-Aware Unlearning via Activation Signatures: From Suppression to Knowledge-Signature Erasure</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Selective knowledge erasure from LLMs is critical for GDPR compliance and model safety, yet current unlearning methods conflate behavioral suppression with true knowledge removal, allowing latent capabilities to persist beneath surface-level refusals. In this work, we address this challenge by introducing Knowledge Immunization Framework (KIF), a representation-aware architecture that distinguishes genuine erasure from obfuscation by targeting internal activation signatures rather than surface o</td>
      <td>http://arxiv.org/abs/2601.10566v1</td>
    </tr>
    <tr>
      <td>Be Your Own Red Teamer: Safety Alignment via Self-Play and Reflective Experience Replay</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large Language Models (LLMs) have achieved remarkable capabilities but remain vulnerable to adversarial ``jailbreak'' attacks designed to bypass safety guardrails. Current safety alignment methods depend heavily on static external red teaming, utilizing fixed defense prompts or pre-collected adversarial datasets. This leads to a rigid defense that overfits known patterns and fails to generalize to novel, sophisticated threats. To address this critical limitation, we propose empowering the model</td>
      <td>http://arxiv.org/abs/2601.10589v1</td>
    </tr>
    <tr>
      <td>iTIMO: An LLM-empowered Synthesis Dataset for Travel Itinerary Modification</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Addressing itinerary modification is crucial for enhancing the travel experience as it is a frequent requirement during traveling. However, existing research mainly focuses on fixed itinerary planning, leaving modification underexplored. To bridge this gap, we formally define the itinerary modification task and introduce iTIMO, a dataset specifically tailored for this purpose. We identify the lack of {\itshape need-to-modify} itinerary data as the critical bottleneck hindering research on this t</td>
      <td>http://arxiv.org/abs/2601.10609v1</td>
    </tr>
    <tr>
      <td>Influential Training Data Retrieval for Explaining Verbalized Confidence of LLMs</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large language models (LLMs) can increase users' perceived trust by verbalizing confidence in their outputs. However, prior work has shown that LLMs are often overconfident, making their stated confidence unreliable since it does not consistently align with factual accuracy. To better understand the sources of this verbalized confidence, we introduce TracVC (\textbf{Trac}ing \textbf{V}erbalized \textbf{C}onfidence), a method that builds on information retrieval and influence estimation to trace</td>
      <td>http://arxiv.org/abs/2601.10645v1</td>
    </tr>
    <tr>
      <td>Detecting Winning Arguments with Large Language Models and Persuasion Strategies</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Detecting persuasion in argumentative text is a challenging task with important implications for understanding human communication. This work investigates the role of persuasion strategies - such as Attack on reputation, Distraction, and Manipulative wording - in determining the persuasiveness of a text. We conduct experiments on three annotated argument datasets: Winning Arguments (built from the Change My View subreddit), Anthropic/Persuasion, and Persuasion for Good. Our approach leverages la</td>
      <td>http://arxiv.org/abs/2601.10660v1</td>
    </tr>
    <tr>
      <td>XuanJia: A Comprehensive Virtualization-Based Code Obfuscator for Binary Protection</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Virtualization-based binary obfuscation is widely adopted to protect software intellectual property, yet existing approaches leave exception-handling (EH) metadata unprotected to preserve ABI compatibility. This exposed metadata leaks rich structural information, such as stack layouts, control-flow boundaries, and object lifetimes, which can be exploited to facilitate reverse engineering. In this paper, we present XuanJia, a comprehensive VM-based binary obfuscation framework that provides end-t</td>
      <td>http://arxiv.org/abs/2601.10261v1</td>
    </tr>
    <tr>
      <td>Single-Stage Huffman Encoder for ML Compression</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Training and serving Large Language Models (LLMs) require partitioning data across multiple accelerators, where collective operations are frequently bottlenecked by network bandwidth. Lossless compression using Huffman codes is an effective way to alleviate the issue, however, its three-stage design requiring on-the-fly frequency analysis, codebook generation and transmission of codebook along with data introduces computational, latency and data overheads which are prohibitive for latency-sensit</td>
      <td>http://arxiv.org/abs/2601.10673v1</td>
    </tr>
    <tr>
      <td>Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insufficient query context, including 2nd and 3rd order facets. In this paper, a structure-informed and diversity-constrained context bubble construction framework is proposed that assembles coherent, cit</td>
      <td>http://arxiv.org/abs/2601.10681v1</td>
    </tr>
    <tr>
      <td>LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influence model behavior, which is crucial for decision-makers in high-stakes domains. Recent work evaluates the faithfulness of such explanations by comparing them to reference causal effects estimated from counterfactuals. In practice, existing benchmarks rely on costly human-written counterfactuals that serve as an imperfect proxy. To address this, we introduce a framework for constructing datasets contai</td>
      <td>http://arxiv.org/abs/2601.10700v1</td>
    </tr>
    <tr>
      <td>From One-to-One to Many-to-Many: Dynamic Cross-Layer Injection for Deep Vision-Language Fusion</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Vision-Language Models (VLMs) create a severe visual feature bottleneck by using a crude, asymmetric connection that links only the output of the vision encoder to the input of the large language model (LLM). This static architecture fundamentally limits the ability of LLMs to achieve comprehensive alignment with hierarchical visual knowledge, compromising their capacity to accurately integrate local details with global semantics into coherent reasoning. To resolve this, we introduce Cross-Layer</td>
      <td>http://arxiv.org/abs/2601.10710v1</td>
    </tr>
    <tr>
      <td>MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool calls from redundant or erroneous ones, particularly in long-horizon multi-turn scenarios. To addre</td>
      <td>http://arxiv.org/abs/2601.10712v1</td>
    </tr>
    <tr>
      <td>The impact of tactile sensor configurations on grasp learning efficiency -- a comparative evaluation in simulation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Tactile sensors are breaking into the field of robotics to provide direct information related to contact surfaces, including contact events, slip events and even texture identification. These events are especially important for robotic hand designs, including prosthetics, as they can greatly improve grasp stability. Most presently published robotic hand designs, however, implement them in vastly different densities and layouts on the hand surface, often reserving the majority of the available sp</td>
      <td>http://arxiv.org/abs/2601.10268v1</td>
    </tr>
    <tr>
      <td>Sim2Real Deep Transfer for Per-Device CFO Calibration</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Carrier Frequency Offset (CFO) estimation in Orthogonal Frequency Division Multiplexing (OFDM) systems faces significant performance degradation across heterogeneous software-defined radio (SDR) platforms due to uncalibrated hardware impairments. Existing deep neural network (DNN)-based approaches lack device-level adaptation, limiting their practical deployment. This paper proposes a Sim2Real transfer learning framework for per-device CFO calibration, combining simulation-driven pretraining wit</td>
      <td>http://arxiv.org/abs/2601.10264v1</td>
    </tr>
    <tr>
      <td>Density of States of Ru3 and Pt3 Clusters Supported on Sputter-Deposited TiO2</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In this work, 3-atom clusters, Ru3 and Pt3, were deposited onto radio frequency RF-sputter deposited TiO2, treated with Ar+ ion sputtering. Ru3 was deposited by both solution submersion and chemical vapor deposition of Ru3(CO)12, while Pt3 was deposited under ultra-high vacuum using a laser vaporisation cluster source. The valence electronic density of states (DOS) of the deposited clusters were analysed after heat treatment using ultraviolet photoelectron spectroscopy (UPS) and metastable impac</td>
      <td>http://arxiv.org/abs/2601.10140v1</td>
    </tr>
    <tr>
      <td>SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal Scientific Interleaved Literature</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Evaluating whether multimodal large language models truly understand long-form scientific papers remains challenging: answer-only metrics and synthetic "Needle-In-A-Haystack" tests often reward answer matching without requiring a causal, evidence-linked reasoning trace in the document. We propose the "Fish-in-the-Ocean" (FITO) paradigm, which requires models to construct explicit cross-modal evidence chains within native scientific documents. To operationalize FITO, we build SIN-Data, a scientif</td>
      <td>http://arxiv.org/abs/2601.10108v1</td>
    </tr>
    <tr>
      <td>Brief but Impactful: How Human Tutoring Interactions Shape Engagement in Online Learning</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Learning analytics can guide human tutors to efficiently address motivational barriers to learning that AI systems struggle to support. Students become more engaged when they receive human attention. However, what occurs during short interventions, and when are they most effective? We align student-tutor dialogue transcripts with MATHia tutoring system log data to study brief human-tutor interactions on Zoom drawn from 2,075 hours of 191 middle school students' classroom math practice. Mixed-eff</td>
      <td>http://arxiv.org/abs/2601.09994v1</td>
    </tr>
    <tr>
      <td>Modeling conflicting incentives in engineering senior capstone projects: A multi-player game theory approach</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>University engineering capstone projects involve sustained interaction among students, faculty, and industry sponsors whose objectives are only partially aligned. While capstones are widely used in engineering education, existing analyses typically treat stakeholder behavior informally or descriptively, leaving incentive conflicts, information asymmetries, and strategic dependencies underexplored. This paper develops a formal game-theoretic framework that models capstone projects as a sequential</td>
      <td>http://arxiv.org/abs/2601.09944v1</td>
    </tr>
    <tr>
      <td>Performance of AI agents based on reasoning language models on ALD process optimization tasks</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>In this work we explore the performance and behavior of reasoning large language models to autonomously optimize atomic layer deposition (ALD) processes. In the ALD process optimization task, an agent built on top of a reasoning LLM has to find optimal dose times for an ALD precursor and a coreactant without any prior knowledge on the process, including whether it is actually self-limited. The agent is meant to interact iteratively with an ALD reactor in a fully unsupervised way. We evaluate thi</td>
      <td>http://arxiv.org/abs/2601.09980v1</td>
    </tr>
    <tr>
      <td>Chinese Labor Law Large Language Model Benchmark</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Recent advances in large language models (LLMs) have led to substantial progress in domain-specific applications, particularly within the legal domain. However, general-purpose models such as GPT-4 often struggle with specialized subdomains that require precise legal knowledge, complex reasoning, and contextual sensitivity. To address these limitations, we present LabourLawLLM, a legal large language model tailored to Chinese labor law. We also introduce LabourLawBench, a comprehensive benchmark</td>
      <td>http://arxiv.org/abs/2601.09972v1</td>
    </tr>
    <tr>
      <td>A Sustainable AI Economy Needs Data Deals That Work for Generators</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We argue that the machine learning value chain is structurally unsustainable due to an economic data processing inequality: each state in the data cycle from inputs to model weights to synthetic outputs refines technical signal but strips economic equity from data generators. We show, by analyzing seventy-three public data deals, that the majority of value accrues to aggregators, with documented creator royalties rounding to zero and widespread opacity of deal terms. This is not just an economic</td>
      <td>http://arxiv.org/abs/2601.09966v1</td>
    </tr>
    <tr>
      <td>aiPlato: A Novel AI Tutoring and Step-wise Feedback System for Physics Homework</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This exploratory study examines the classroom deployment of aiPlato, an AI-enabled homework platform, in a large introductory physics course at the University of Texas at Arlington. Designed to support open-ended problem solving, aiPlato provides step-wise feedback and iterative guidance through tools such as "Evaluate My Work" and "AI Tutor Chat", while preserving opportunities for productive struggle. Over four optional extra-credit assignments, the platform captured detailed student interacti</td>
      <td>http://arxiv.org/abs/2601.09965v1</td>
    </tr>
    <tr>
      <td>A Control Theoretic Approach to Decentralized AI Economy Stabilization via Dynamic Buyback-and-Burn Mechanisms</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>The democratization of artificial intelligence through decentralized networks represents a paradigm shift in computational provisioning, yet the long-term viability of these ecosystems is critically endangered by the extreme volatility of their native economic layers. Current tokenomic models, which predominantly rely on static or threshold-based buyback heuristics, are ill-equipped to handle complex system dynamics and often function pro-cyclically, exacerbating instability during market downtu</td>
      <td>http://arxiv.org/abs/2601.09961v1</td>
    </tr>
    <tr>
      <td>The Spatial Blindspot of Vision-Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Vision-language models (VLMs) have advanced rapidly, but their ability to capture spatial relationships remains a blindspot. Current VLMs are typically built with contrastive language-image pretraining (CLIP) style image encoders. The training recipe often flattens images into 1D patch sequences, discarding the 2D structure necessary for spatial reasoning. We argue that this lack of spatial awareness is a missing dimension in VLM design and a bottleneck for applications requiring spatial groundi</td>
      <td>http://arxiv.org/abs/2601.09954v1</td>
    </tr>
    <tr>
      <td>The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, wh</td>
      <td>http://arxiv.org/abs/2601.10696v1</td>
    </tr>
    <tr>
      <td>Enhancing Visual In-Context Learning by Multi-Faceted Fusion</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Visual In-Context Learning (VICL) has emerged as a powerful paradigm, enabling models to perform novel visual tasks by learning from in-context examples. The dominant "retrieve-then-prompt" approach typically relies on selecting the single best visual prompt, a practice that often discards valuable contextual information from other suitable candidates. While recent work has explored fusing the top-K prompts into a single, enhanced representation, this still simply collapses multiple rich signals</td>
      <td>http://arxiv.org/abs/2601.10107v1</td>
    </tr>
    <tr>
      <td>Chebyshev Accelerated Subspsace Eigensolver for Pseudo-hermitian Hamiltonians</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Studying the optoelectronic structure of materials can require the computation of up to several thousands of the smallest eigenpairs of a pseudo-hermitian Hamiltonian. Iterative eigensolvers may be preferred over direct methods for this task since their complexity is a function of the desired fraction of the spectrum. In addition, they generally rely on highly optimized and scalable kernels such as matrix-vector multiplications that leverage the massive parallelism and the computational power of</td>
      <td>http://arxiv.org/abs/2601.10557v1</td>
    </tr>
    <tr>
      <td>V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Recent advances in multimodal learning have significantly enhanced the reasoning capabilities of vision-language models (VLMs). However, state-of-the-art approaches rely heavily on large-scale human-annotated datasets, which are costly and time-consuming to acquire. To overcome this limitation, we introduce V-Zero, a general post-training framework that facilitates self-improvement using exclusively unlabeled images. V-Zero establishes a co-evolutionary loop by instantiating two distinct roles:</td>
      <td>http://arxiv.org/abs/2601.10094v1</td>
    </tr>
    <tr>
      <td>Is MT Ready for the Next Crisis or Pandemic?</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Communication in times of crisis is essential. However, there is often a mismatch between the language of governments, aid providers, doctors, and those to whom they are providing aid. Commercial MT systems are reasonable tools to turn to in these scenarios. But how effective are these tools for translating to and from low resource languages, particularly in the crisis or medical domain? In this study, we evaluate four commercial MT systems using the TICO-19 dataset, which is composed of pandemi</td>
      <td>http://arxiv.org/abs/2601.10082v1</td>
    </tr>
    <tr>
      <td>ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for Whole-Slide Histopathology</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>We introduce ReaMIL (Reasoning- and Evidence-Aware MIL), a multiple instance learning approach for whole-slide histopathology that adds a light selection head to a strong MIL backbone. The head produces soft per-tile gates and is trained with a budgeted-sufficiency objective: a hinge loss that enforces the true-class probability to be $\geq τ$ using only the kept evidence, under a sparsity budget on the number of selected tiles. The budgeted-sufficiency objective yields small, spatially compact</td>
      <td>http://arxiv.org/abs/2601.10073v1</td>
    </tr>
    <tr>
      <td>CoF-T2I: Video Models as Pure Visual Reasoners for Text-to-Image Generation</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Recent video generation models have revealed the emergence of Chain-of-Frame (CoF) reasoning, enabling frame-by-frame visual inference. With this capability, video models have been successfully applied to various visual tasks (e.g., maze solving, visual puzzles). However, their potential to enhance text-to-image (T2I) generation remains largely unexplored due to the absence of a clearly defined visual reasoning starting point and interpretable intermediate states in the T2I generation process. T</td>
      <td>http://arxiv.org/abs/2601.10061v1</td>
    </tr>
    <tr>
      <td>Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Existing NL2SQL systems face two critical limitations: (1) they rely on in-context learning with only correct examples, overlooking the rich signal in historical error-fix pairs that could guide more robust self-correction; and (2) test-time scaling approaches often decompose questions arbitrarily, producing near-identical SQL candidates across runs and diminishing ensemble gains. Moreover, these methods suffer from a stark accuracy-efficiency trade-off: high performance demands excessive comput</td>
      <td>http://arxiv.org/abs/2601.10011v1</td>
    </tr>
    <tr>
      <td>VERHallu: Evaluating and Mitigating Event Relation Hallucination in Video Large Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Video Large Language Models (VideoLLMs) exhibit various types of hallucinations. Existing research has primarily focused on hallucinations involving the presence of events, objects, and scenes in videos, while largely neglecting event relation hallucination. In this paper, we introduce a novel benchmark for evaluating the Video Event Relation Hallucination, named VERHallu. This benchmark focuses on causal, temporal, and subevent relations between events, encompassing three types of tasks: relati</td>
      <td>http://arxiv.org/abs/2601.10010v1</td>
    </tr>
    <tr>
      <td>DR$^2$Seg: Decomposed Two-Stage Rollouts for Efficient Reasoning Segmentation in Multimodal Large Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>Reasoning segmentation is an emerging vision-language task that requires reasoning over intricate text queries to precisely segment objects. However, existing methods typically suffer from overthinking, generating verbose reasoning chains that interfere with object localization in multimodal large language models (MLLMs). To address this issue, we propose DR$^2$Seg, a self-rewarding framework that improves both reasoning efficiency and segmentation accuracy without requiring extra thinking super</td>
      <td>http://arxiv.org/abs/2601.09981v1</td>
    </tr>
    <tr>
      <td>Average pairing correlation properties and effective pairing residual interactions</td>
      <td>ArXiv</td>
      <td>2026-01-15</td>
      <td>This paper describes a method to determine the intensities of effective pairing residual interactions, extending what has been done for the seniority force model [Phys. Rev. C 110, 024311 (2024)]. It has been tested in Hartree-Fock plus BCS calculations using residual pairing zero-range interactions. The average pair condensation energy is the key quantity connecting the determination of constant pairing matrix elements to the estimation of delta interaction intensities. From individually fitted</td>
      <td>http://arxiv.org/abs/2601.09993v1</td>
    </tr>
    <tr>
      <td>Clozing the Gap: Exploring Why Language Model Surprisal Outperforms Cloze Surprisal</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>How predictable a word is can be quantified in two ways: using human responses to the cloze task or using probabilities from language models (LMs).When used as predictors of processing effort, LM probabilities outperform probabilities derived from cloze data. However, it is important to establish that LM probabilities do so for the right reasons, since different predictors can lead to different scientific conclusions about the role of prediction in language comprehension. We present evidence for</td>
      <td>http://arxiv.org/abs/2601.09886v1</td>
    </tr>
    <tr>
      <td>Show HN: OSS AI agent that indexes and searches the Epstein files</td>
      <td>HackerNews</td>
      <td>2026-01-14</td>
      <td>Hi HN,&lt;p&gt;I built an open-source AI agent that has already indexed and can search the entire Epstein files, roughly 100M words of publicly released documents.&lt;p&gt;The goal was simple: make a large, messy corpus of PDFs and text files immediately searchable in a precise way, without relying on keyword search or bloated prompts.&lt;p&gt;What it does:&lt;p&gt;- The full dataset is already indexed\n- You can ask natural language questions\n- Answers are grounded and include direct references to source documents\n- Su</td>
      <td>https://epstein.trynia.ai/</td>
    </tr>
    <tr>
      <td>Software Engineer C++ (Senior) at Apexver</td>
      <td>RemoteJob</td>
      <td>2026-01-14</td>
      <td>Role Overview\nAs a Senior Software Engineer, you will take leadership in designing, building, and scaling high-performance trading systems. You will be driving architectural decisions, mentoring others, and ensuring the reliability, latency, and correctness of our production systems.Your role will bridge between quant research, trading operations, and engineering excellence.\n \nKey Responsibilities\n\n\nLead design, development, and ownership of large, complex C++ systems: engines for order executio</td>
      <td>https://remotive.com/remote-jobs/software-development/software-engineer-c-senior-2069728</td>
    </tr>
    <tr>
      <td>Tech Lead Databricks Data Engineer at Mitre Media</td>
      <td>RemoteJob</td>
      <td>2026-01-14</td>
      <td>About Mitre Media\nMitre Media is redefining FinTech with AI-driven tools that empower millions of investors. Our portfolio, including Dividend.com and MutualFunds.com, leverages LLMs to deliver novel data insights and visually rich user experiences. For over a decade, we’ve served individual investors, financial advisors, and top asset managers like BlackRock and Vanguard through our premium data, tools, and advertising solutions. If you’re excited by the intersection of big data, AI, and invest</td>
      <td>https://remotive.com/remote-jobs/software-development/tech-lead-databricks-data-engineer-2069747</td>
    </tr>
    <tr>
      <td>Tech Lead Full-Stack Rails Engineer at Mitre Media</td>
      <td>RemoteJob</td>
      <td>2026-01-14</td>
      <td>About Mitre Media\nMitre Media is redefining FinTech with AI-driven tools that empower millions of investors. Our portfolio, including Dividend.com and MutualFunds.com, leverages LLMs to deliver novel data insights and visually rich user experiences. For over a decade, we’ve served individual investors, financial advisors, and top asset managers like BlackRock and Vanguard through our premium data, tools, and advertising solutions. Join our lean, entrepreneurial team to shape the future of AI-pow</td>
      <td>https://remotive.com/remote-jobs/software-development/tech-lead-full-stack-rails-engineer-2069746</td>
    </tr>
    <tr>
      <td>Show HN: Tabstack – Browser infrastructure for AI agents (by Mozilla)</td>
      <td>HackerNews</td>
      <td>2026-01-14</td>
      <td>Hi HN,&lt;p&gt;My team and I are building Tabstack to handle the &amp;quot;web layer&amp;quot; for AI agents. Launch Post: &lt;a href="https:&amp;#x2F;&amp;#x2F;tabstack.ai&amp;#x2F;blog&amp;#x2F;intro-browsing-infrastructure-ai-agents" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;tabstack.ai&amp;#x2F;blog&amp;#x2F;intro-browsing-infrastructure-ai-ag...&lt;/a&gt;&lt;p&gt;Maintaining a complex infrastructure stack for web browsing is one of the biggest bottlenecks in building reliable agents. You start with a simple fetch, but quickly end up managing a complex</td>
      <td>https://news.ycombinator.com/item?id=46620358</td>
    </tr>
    <tr>
      <td>Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning. More recent studies have incorporated multimodal information into the reasoning steps; however, they often follow a single task-specific reasoning pattern, which limits their generalizability across various multimodal tasks. In fact, there are numerous multimodal tasks requiring diverse reasoning skills, such as zooming in on a specific region or</td>
      <td>http://arxiv.org/abs/2601.09536v1</td>
    </tr>
    <tr>
      <td>MedVL-SAM2: A unified 3D medical vision-language model for multimodal reasoning and prompt-driven segmentation</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Recent progress in medical vision-language models (VLMs) has achieved strong performance on image-level text-centric tasks such as report generation and visual question answering (VQA). However, achieving fine-grained visual grounding and volumetric spatial reasoning in 3D medical VLMs remains challenging, particularly when aiming to unify these capabilities within a single, generalizable framework. To address this challenge, we proposed MedVL-SAM2, a unified 3D medical multimodal model that con</td>
      <td>http://arxiv.org/abs/2601.09879v1</td>
    </tr>
    <tr>
      <td>MM-BRIGHT: A Multi-Task Multimodal Benchmark for Reasoning-Intensive Retrieval</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Existing retrieval benchmarks primarily consist of text-based queries where keyword or semantic matching is usually sufficient. Many real-world queries contain multimodal elements, particularly, images such as diagrams, charts, and screenshots that require intensive reasoning to identify relevant documents. To address this gap, we introduce MM-BRIGHT, the first multimodal benchmark for reasoning-intensive retrieval. Our dataset consists of 2,803 real-world queries spanning 29 diverse technical d</td>
      <td>http://arxiv.org/abs/2601.09562v2</td>
    </tr>
    <tr>
      <td>Energy-Entropy Regularization: The True Power of Minimal Looped Transformers</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Recent research suggests that looped Transformers have superior reasoning capabilities compared to standard deep architectures. Current approaches to training single-head looped architectures on benchmark tasks frequently fail or yield suboptimal performance due to a highly non-convex and irregular loss landscape. In these settings, optimization often stagnates in poor local minima and saddle points of the loss landscape, preventing the model from discovering the global minimum point. The intern</td>
      <td>http://arxiv.org/abs/2601.09588v1</td>
    </tr>
    <tr>
      <td>CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Accurate and early perception of potential intrusion targets is essential for ensuring the safety of railway transportation systems. However, most existing systems focus narrowly on object classification within fixed visual scopes and apply rule-based heuristics to determine intrusion status, often overlooking targets that pose latent intrusion risks. Anticipating such risks requires the cognition of spatial context and temporal dynamics for the object of interest (OOI), which presents challenge</td>
      <td>http://arxiv.org/abs/2601.09613v1</td>
    </tr>
    <tr>
      <td>Comparison of plasma response models for RMP effects on the divertor and scrape-off layer in KSTAR</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Resonant magnetic perturbations (RMPs) are beneficial for control of edge localized modes (ELMs) in tokamaks. Nevertheless, a side effect is the appearance of a helical striations in the particle and heat loads onto divertor targets. The extent and field line connection of these striations is significantly altered by the plasma response to external perturbations. For an ELM suppressed H-mode plasma at KSTAR, magnetic footprints are computed by FLARE based on plasma response from GPEC, MARS-F, M3</td>
      <td>http://arxiv.org/abs/2601.09617v1</td>
    </tr>
    <tr>
      <td>TaxoBell: Gaussian Box Embeddings for Self-Supervised Taxonomy Expansion</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Taxonomies form the backbone of structured knowledge representation across diverse domains, enabling applications such as e-commerce catalogs, semantic search, and biomedical discovery. Yet, manual taxonomy expansion is labor-intensive and cannot keep pace with the emergence of new concepts. Existing automated methods rely on point-based vector embeddings, which model symmetric similarity and thus struggle with the asymmetric "is-a" relationships that are fundamental to taxonomies. Box embedding</td>
      <td>http://arxiv.org/abs/2601.09633v1</td>
    </tr>
    <tr>
      <td>STEP3-VL-10B Technical Report</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>We present STEP3-VL-10B, a lightweight open-source foundation model designed to redefine the trade-off between compact efficiency and frontier-level multimodal intelligence. STEP3-VL-10B is realized through two strategic shifts: first, a unified, fully unfrozen pre-training strategy on 1.2T multimodal tokens that integrates a language-aligned Perception Encoder with a Qwen3-8B decoder to establish intrinsic vision-language synergy; and second, a scaled post-training pipeline featuring over 1k it</td>
      <td>http://arxiv.org/abs/2601.09668v2</td>
    </tr>
    <tr>
      <td>The Geometry of Thought: Disclosing the Transformer as a Tropical Polynomial Circuit</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>We prove that the Transformer self-attention mechanism in the high-confidence regime ($β\to \infty$, where $β$ is an inverse temperature) operates in the tropical semiring (max-plus algebra). In particular, we show that taking the tropical limit of the softmax attention converts it into a tropical matrix product. This reveals that the Transformer's forward pass is effectively executing a dynamic programming recurrence (specifically, a Bellman-Ford path-finding update) on a latent graph defined b</td>
      <td>http://arxiv.org/abs/2601.09775v1</td>
    </tr>
    <tr>
      <td>Value-Aware Numerical Representations for Transformer Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Transformer-based language models often achieve strong results on mathematical reasoning benchmarks while remaining fragile on basic numerical understanding and arithmetic operations. A central limitation is that numbers are processed as symbolic tokens whose embeddings do not explicitly encode numerical value, leading to systematic errors. We introduce a value-aware numerical representation that augments standard tokenized inputs with a dedicated prefix token whose embedding is explicitly condi</td>
      <td>http://arxiv.org/abs/2601.09706v1</td>
    </tr>
    <tr>
      <td>Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficie</td>
      <td>http://arxiv.org/abs/2601.09708v1</td>
    </tr>
    <tr>
      <td>Thinking Long, but Short: Stable Sequential Test-Time Scaling for Large Reasoning Models</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Sequential test-time scaling is a promising training-free method to improve large reasoning model accuracy, but as currently implemented, significant limitations have been observed. Inducing models to think for longer can increase their accuracy, but as the length of reasoning is further extended, it has also been shown to result in accuracy degradation and model instability. This work presents a novel sequential test-time scaling method, Min-Seek, which improves model accuracy significantly ove</td>
      <td>http://arxiv.org/abs/2601.09855v1</td>
    </tr>
    <tr>
      <td>Patient-Similarity Cohort Reasoning in Clinical Text-to-SQL</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Real-world clinical text-to-SQL requires reasoning over heterogeneous EHR tables, temporal windows, and patient-similarity cohorts to produce executable queries. We introduce CLINSQL, a benchmark of 633 expert-annotated tasks on MIMIC-IV v3.1 that demands multi-table joins, clinically meaningful filters, and executable SQL. Solving CLINSQL entails navigating schema metadata and clinical coding systems, handling long contexts, and composing multi-step queries beyond traditional text-to-SQL. We ev</td>
      <td>http://arxiv.org/abs/2601.09876v1</td>
    </tr>
    <tr>
      <td>Constitutive parameter inference using physics-based data-driven modeling in full volume datasets of intact and torn rotator cuff tendons</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>In this work, we characterized the material properties of an animal model of the rotator cuff tendon using full volume datasets of both its intact and injured states by capturing internal strain behavior throughout the tendon. Our experimental setup, involving tension along the fiber direction, activated volumetric, tensile, and shear mechanisms due to the tendon's complex geometry. We implemented an approach to model inference that we refer to as variational system identification (VSI) to solve</td>
      <td>http://arxiv.org/abs/2601.09660v1</td>
    </tr>
    <tr>
      <td>Ask HN: How are you doing RAG locally?</td>
      <td>HackerNews</td>
      <td>2026-01-14</td>
      <td>I am curious how people are doing RAG locally with minimal dependencies for internal code or complex documents?&lt;p&gt;Are you using a vector database, some type of semantic search, a knowledge graph, a hypergraph?</td>
      <td>https://news.ycombinator.com/item?id=46616529</td>
    </tr>
    <tr>
      <td>How Diplomacy Reshapes Online Discourse:Asymmetric Persistence in Online Framing of North Korea</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Public opinion toward foreign adversaries shapes and constrains diplomatic options. Prior research has largely relied on sentiment analysis and survey based measures, providing limited insight into how sustained narrative changes (beyond transient emotional reactions) might follow diplomatic engagement. This study examines the extent to which high stakes diplomatic summits shape how adversaries are framed in online discourse. We analyze U.S.-North Korea summit diplomacy (2018-2019) using a Diffe</td>
      <td>http://arxiv.org/abs/2601.09942v1</td>
    </tr>
    <tr>
      <td>Information Access of the Oppressed: A Problem-Posing Framework for Envisioning Emancipatory Information Access Platforms</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Online information access (IA) platforms are targets of authoritarian capture. These concerns are particularly serious and urgent today in light of the rising levels of democratic erosion worldwide, the emerging capabilities of generative AI technologies such as AI persuasion, and the increasing concentration of economic and political power in the hands of Big Tech. This raises the question of what alternative IA infrastructure we must reimagine and build to mitigate the risks of authoritarian c</td>
      <td>http://arxiv.org/abs/2601.09600v1</td>
    </tr>
    <tr>
      <td>PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Modern LLM-based recommenders can generate compelling ranked lists, but they struggle to reliably satisfy governance constraints such as minimum long-tail exposure or diversity requirements. We present PCN-Rec, a proof-carrying negotiation pipeline that separates natural-language reasoning from deterministic enforcement. A base recommender (MF/CF) produces a candidate window of size W, which is negotiated by two agents: a User Advocate optimizing relevance and a Policy Agent enforcing constraint</td>
      <td>http://arxiv.org/abs/2601.09771v1</td>
    </tr>
    <tr>
      <td>Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>SMEs increasingly seek alternatives to cloud LLM APIs, which raise data privacy concerns. Dedicated cloud GPU instances offer improved privacy but with limited guarantees and ongoing costs, while professional on-premise hardware (A100, H100) remains prohibitively expensive. We present a systematic evaluation of NVIDIA's Blackwell consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) for production LLM inference, benchmarking four open-weight models (Qwen3-8B, Gemma3-12B, Gemma3-27B, GPT-OSS-20B) across 79</td>
      <td>http://arxiv.org/abs/2601.09527v1</td>
    </tr>
    <tr>
      <td>SERM: Self-Evolving Relevance Model with Agent-Driven Learning from Massive Query Streams</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Due to the dynamically evolving nature of real-world query streams, relevance models struggle to generalize to practical search scenarios. A sophisticated solution is self-evolution techniques. However, in large-scale industrial settings with massive query streams, this technique faces two challenges: (1) informative samples are often sparse and difficult to identify, and (2) pseudo-labels generated by the current model could be unreliable. To address these challenges, in this work, we propose a</td>
      <td>http://arxiv.org/abs/2601.09515v1</td>
    </tr>
    <tr>
      <td>GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Recent advances in vision-language models (VLMs) and reinforcement learning (RL) have driven progress in GUI automation. However, most existing methods rely on static, one-shot visual inputs and passive perception, lacking the ability to adaptively determine when, whether, and how to observe the interface. We present GUI-Eyes, a reinforcement learning framework for active visual perception in GUI tasks. To acquire more informative observations, the agent learns to make strategic decisions on bot</td>
      <td>http://arxiv.org/abs/2601.09770v1</td>
    </tr>
    <tr>
      <td>What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large language model (LLM) agents have demonstrated remarkable capabilities in complex decision-making and tool-use tasks, yet their ability to generalize across varying environments remains a under-examined concern. Current evaluation paradigms predominantly rely on trajectory-based metrics that measure task success, while failing to assess whether agents possess a grounded, transferable model of the environment. To address this gap, we propose Task-to-Quiz (T2Q), a deterministic and automated</td>
      <td>http://arxiv.org/abs/2601.09503v1</td>
    </tr>
    <tr>
      <td>On lower bounds for hypergeometric tails</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Let $n,k$ be positive integers such that $n\geq k$, and let $H$ be a hypergeometric random variable counting the number of black marbles in a sample without replacement of size $k$ from an urn that contains $i\in \{1,\ldots, n\}$ black and $n - i$ white marbles. It is shown that \[ \mathbb{P}(H \ge \mathbb{E}(H)) \ge k/n\, , \, \text{when} \,\, n\ge 8k \, . \] Furthermore, provided that $1\le \mathbb{E}(H)\le \min\{i,k\}-2$ as well as that $\frac{(n-i)(n-k)}{n}&gt;1$, it is shown that \[ \mathbb{P}</td>
      <td>http://arxiv.org/abs/2601.09485v1</td>
    </tr>
    <tr>
      <td>Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Accurate global medium-range weather forecasting is fundamental to Earth system science. Most existing Transformer-based forecasting models adopt vision-centric architectures that neglect the Earth's spherical geometry and zonal periodicity. In addition, conventional autoregressive training is computationally expensive and limits forecast horizons due to error accumulation. To address these challenges, we propose the Shifted Earth Transformer (Searth Transformer), a physics-informed architecture</td>
      <td>http://arxiv.org/abs/2601.09467v1</td>
    </tr>
    <tr>
      <td>EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>While LLM-based agents have shown promise for deep research, most existing approaches rely on fixed workflows that struggle to adapt to real-world, open-ended queries. Recent work therefore explores self-evolution by allowing agents to rewrite their own code or prompts to improve problem-solving ability, but unconstrained optimization often triggers instability, hallucinations, and instruction drift. We propose EvoFSM, a structured self-evolving framework that achieves both adaptability and cont</td>
      <td>http://arxiv.org/abs/2601.09465v1</td>
    </tr>
    <tr>
      <td>Dissecting Judicial Reasoning in U.S. Copyright Damage Awards</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Judicial reasoning in copyright damage awards poses a core challenge for computational legal analysis. Although federal courts follow the 1976 Copyright Act, their interpretations and factor weightings vary widely across jurisdictions. This inconsistency creates unpredictability for litigants and obscures the empirical basis of legal decisions. This research introduces a novel discourse-based Large Language Model (LLM) methodology that integrates Rhetorical Structure Theory (RST) with an agentic</td>
      <td>http://arxiv.org/abs/2601.09459v1</td>
    </tr>
    <tr>
      <td>On the Hardness of Computing Counterfactual and Semifactual Explanations in XAI</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Providing clear explanations to the choices of machine learning models is essential for these models to be deployed in crucial applications. Counterfactual and semi-factual explanations have emerged as two mechanisms for providing users with insights into the outputs of their models. We provide an overview of the computational complexity results in the literature for generating these explanations, finding that in many cases, generating explanations is computationally hard. We strengthen the argu</td>
      <td>http://arxiv.org/abs/2601.09455v1</td>
    </tr>
    <tr>
      <td>MAD: Motion Appearance Decoupling for efficient Driving World Models</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Recent video diffusion models generate photorealistic, temporally coherent videos, yet they fall short as reliable world models for autonomous driving, where structured motion and physically consistent interactions are essential. Adapting these generalist video models to driving domains has shown promise but typically requires massive domain-specific data and costly fine-tuning. We propose an efficient adaptation framework that converts generalist video diffusion models into controllable driving</td>
      <td>http://arxiv.org/abs/2601.09452v1</td>
    </tr>
    <tr>
      <td>DepRadar: Agentic Coordination for Context Aware Defect Impact Analysis in Deep Learning Libraries</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Deep learning libraries like Transformers and Megatron are now widely adopted in modern AI programs. However, when these libraries introduce defects, ranging from silent computation errors to subtle performance regressions, it is often challenging for downstream users to assess whether their own programs are affected. Such impact analysis requires not only understanding the defect semantics but also checking whether the client code satisfies complex triggering conditions involving configuration</td>
      <td>http://arxiv.org/abs/2601.09440v1</td>
    </tr>
    <tr>
      <td>SC-MAS: Constructing Cost-Efficient Multi-Agent Systems with Edge-Level Heterogeneous Collaboration</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large Language Model (LLM)-based Multi-Agent Systems (MAS) enhance complex problem solving through multi-agent collaboration, but often incur substantially higher costs than single-agent systems. Recent MAS routing methods aim to balance performance and overhead by dynamically selecting agent roles and language models. However, these approaches typically rely on a homogeneous collaboration mode, where all agents follow the same interaction pattern, limiting collaboration flexibility across diffe</td>
      <td>http://arxiv.org/abs/2601.09434v1</td>
    </tr>
    <tr>
      <td>Speech-Hands: A Self-Reflection Voice Agentic Approach to Speech Recognition and Audio Reasoning with Omni Perception</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>We introduce a voice-agentic framework that learns one critical omni-understanding skill: knowing when to trust itself versus when to consult external audio perception. Our work is motivated by a crucial yet counterintuitive finding: naively fine-tuning an omni-model on both speech recognition and external sound understanding tasks often degrades performance, as the model can be easily misled by noisy hypotheses. To address this, our framework, Speech-Hands, recasts the problem as an explicit se</td>
      <td>http://arxiv.org/abs/2601.09413v1</td>
    </tr>
    <tr>
      <td>Preliminary Tests of the Anticipatory Classifier System with Hindsight Experience Replay</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>This paper introduces ACS2HER, a novel integration of the Anticipatory Classifier System (ACS2) with the Hindsight Experience Replay (HER) mechanism. While ACS2 is highly effective at building cognitive maps through latent learning, its performance often stagnates in environments characterized by sparse rewards. We propose a specific architectural variant that triggers hindsight learning when the agent fails to reach its primary goal, re-labeling visited states as virtual goals to densify the le</td>
      <td>http://arxiv.org/abs/2601.09400v1</td>
    </tr>
    <tr>
      <td>AI-NativeBench: An Open-Source White-Box Agentic Benchmark Suite for AI-Native Systems</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The transition from Cloud-Native to AI-Native architectures is fundamentally reshaping software engineering, replacing deterministic microservices with probabilistic agentic services. However, this shift renders traditional black-box evaluation paradigms insufficient: existing benchmarks measure raw model capabilities while remaining blind to system-level execution dynamics. To bridge this gap, we introduce AI-NativeBench, the first application-centric and white-box AI-Native benchmark suite gro</td>
      <td>http://arxiv.org/abs/2601.09393v1</td>
    </tr>
    <tr>
      <td>New Estimate for the Cosmic Ray-Induced $\rm H_2$ Photodissociation Rate in the Interstellar Medium</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>In the interstellar medium, cosmic rays (CRs) generate a field of ultraviolet (UV) photons via the excitation and subsequent radiative decay of $\rm H_2$ molecules. This UV field is a major agent of ionization and dissociation in the inner regions of molecular clouds that are shielded from the effects of the interstellar radiation field. In particular, the dissociation of $\rm H_2$, by far the most abundant molecule in interstellar clouds, leads to the production of atomic hydrogen which then ta</td>
      <td>http://arxiv.org/abs/2601.09387v1</td>
    </tr>
    <tr>
      <td>Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user's intents and dynamically adapt to evolving external environments. In this paper, we propose a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user's needs and a dynamic environment. We formalize proactivity thro</td>
      <td>http://arxiv.org/abs/2601.09382v1</td>
    </tr>
    <tr>
      <td>Batch-Fabricated PDMS Templates for the Robotic Transfer of 2D Materials</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Robotic stacking of van der Waals heterostructures has been at the verge thanks to the convergence between artificial intelligence (AI) and two-dimensional (2D) materials research. Key ingredients to fulfill this pursuit often include algorithms to identify layer compounds on chips, hard-wares to realize sophisticated operations of motion and/or rotation in a microscale, and, as importantly, highly-standardized and uniform transfer stamps that are often used in picking up layered materials under</td>
      <td>http://arxiv.org/abs/2601.09378v1</td>
    </tr>
    <tr>
      <td>Measuring the benefits of lying in MARA under egalitarian social welfare</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>When some resources are to be distributed among a set of agents following egalitarian social welfare, the goal is to maximize the utility of the agent whose utility turns out to be minimal. In this context, agents can have an incentive to lie about their actual preferences, so that more valuable resources are assigned to them. In this paper we analyze this situation, and we present a practical study where genetic algorithms are used to assess the benefits of lying under different situations.</td>
      <td>http://arxiv.org/abs/2601.09354v1</td>
    </tr>
    <tr>
      <td>Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Lane-free traffic environments allow vehicles to better harness the lateral capacity of the road without being restricted to lane-keeping, thereby increasing the traffic flow rates. As such, we have a distinct and more challenging setting for autonomous driving. In this work, we consider a Monte-Carlo Tree Search (MCTS) planning approach for single-agent autonomous driving in lane-free traffic, where the associated Markov Decision Process we formulate is influenced from existing approaches tied</td>
      <td>http://arxiv.org/abs/2601.09353v1</td>
    </tr>
    <tr>
      <td>Navigating Ethical AI Challenges in the Industrial Sector: Balancing Innovation and Responsibility</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The integration of artificial intelligence (AI) into the industrial sector has not only driven innovation but also expanded the ethical landscape, necessitating a reevaluation of principles governing technology and its applications and awareness in research and development of industrial AI solutions. This chapter explores how AI-empowered industrial innovation inherently intersects with ethics, as advancements in AI introduce new challenges related to transparency, accountability, and fairness.</td>
      <td>http://arxiv.org/abs/2601.09351v1</td>
    </tr>
    <tr>
      <td>Improving Implicit Hate Speech Detection via a Community-Driven Multi-Agent Framework</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>This work proposes a contextualised detection framework for implicitly hateful speech, implemented as a multi-agent system comprising a central Moderator Agent and dynamically constructed Community Agents representing specific demographic groups. Our approach explicitly integrates socio-cultural context from publicly available knowledge sources, enabling identity-aware moderation that surpasses state-of-the-art prompting methods (zero-shot prompting, few-shot prompting, chain-of-thought promptin</td>
      <td>http://arxiv.org/abs/2601.09342v1</td>
    </tr>
    <tr>
      <td>High-Performance Serverless Computing: A Systematic Literature Review on Serverless for HPC, AI, and Big Data</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The widespread deployment of large-scale, compute-intensive applications such as high-performance computing, artificial intelligence, and big data is leading to convergence between cloud and high-performance computing infrastructures. Cloud providers are increasingly integrating high-performance computing capabilities in their infrastructures, such as hardware accelerators and high-speed interconnects, while researchers in the high-performance computing community are starting to explore cloud-na</td>
      <td>http://arxiv.org/abs/2601.09334v1</td>
    </tr>
    <tr>
      <td>Single-Round Clustered Federated Learning via Data Collaboration Analysis for Non-IID Data</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Federated Learning (FL) enables distributed learning across multiple clients without sharing raw data. When statistical heterogeneity across clients is severe, Clustered Federated Learning (CFL) can improve performance by grouping similar clients and training cluster-wise models. However, most CFL approaches rely on multiple communication rounds for cluster estimation and model updates, which limits their practicality under tight constraints on communication rounds. We propose Data Collaboration</td>
      <td>http://arxiv.org/abs/2601.09304v1</td>
    </tr>
    <tr>
      <td>AI Survival Stories: a Taxonomic Analysis of AI Existential Risk</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Since the release of ChatGPT, there has been a lot of debate about whether AI systems pose an existential risk to humanity. This paper develops a general framework for thinking about the existential risk of AI systems. We analyze a two premise argument that AI systems pose a threat to humanity. Premise one: AI systems will become extremely powerful. Premise two: if AI systems become extremely powerful, they will destroy humanity. We use these two premises to construct a taxonomy of survival stor</td>
      <td>http://arxiv.org/abs/2601.09765v1</td>
    </tr>
    <tr>
      <td>Learning and Equilibrium under Model Misspecification</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>This chapter develops a unified framework for studying misspecified learning situations in which agents optimize and update beliefs within an incorrect model of their environment. We review the statistical foundations of learning from misspecified models and extend these insights to environments with endogenous, action-dependent data, including both single agent and strategic settings.</td>
      <td>http://arxiv.org/abs/2601.09891v1</td>
    </tr>
    <tr>
      <td>Self-reflection in Automated Qualitative Coding: Improving Text Annotation through Secondary LLM Critique</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large language models (LLMs) allow for sophisticated qualitative coding of large datasets, but zero- and few-shot classifiers can produce an intolerable number of errors, even with careful, validated prompting. We present a simple, generalizable two-stage workflow: an LLM applies a human-designed, LLM-adapted codebook; a secondary LLM critic performs self-reflection on each positive label by re-reading the source text alongside the first model's rationale and issuing a final decision. We evaluat</td>
      <td>http://arxiv.org/abs/2601.09905v1</td>
    </tr>
    <tr>
      <td>Beyond Strict Rules: Assessing the Effectiveness of Large Language Models for Code Smell Detection</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Code smells are symptoms of potential code quality problems that may affect software maintainability, thus increasing development costs and impacting software reliability. Large language models (LLMs) have shown remarkable capabilities for supporting various software engineering activities, but their use for detecting code smells remains underexplored. However, unlike the rigid rules of static analysis tools, LLMs can support flexible and adaptable detection strategies tailored to the unique pro</td>
      <td>http://arxiv.org/abs/2601.09873v1</td>
    </tr>
    <tr>
      <td>Antisocial behavior towards large language model users: experimental evidence</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The rapid spread of large language models (LLMs) has raised concerns about the social reactions they provoke. Prior research documents negative attitudes toward AI users, but it remains unclear whether such disapproval translates into costly action. We address this question in a two-phase online experiment (N = 491 Phase II participants; Phase I provided targets) where participants could spend part of their own endowment to reduce the earnings of peers who had previously completed a real-effort</td>
      <td>http://arxiv.org/abs/2601.09772v1</td>
    </tr>
    <tr>
      <td>Full Disclosure, Less Trust? How the Level of Detail about AI Use in News Writing Affects Readers' Trust</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>As artificial intelligence (AI) is increasingly integrated into news production, calls for transparency about the use of AI have gained considerable traction. Recent studies suggest that AI disclosures can lead to a ``transparency dilemma'', where disclosure reduces readers' trust. However, little is known about how the \textit{level of detail} in AI disclosures influences trust and contributes to this dilemma within the news context. In this 3$\times$2$\times$2 mixed factorial study with 40 par</td>
      <td>http://arxiv.org/abs/2601.09620v1</td>
    </tr>
    <tr>
      <td>OUTLINEFORGE: Hierarchical Reinforcement Learning with Explicit States for Scientific Writing</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Scientific paper generation requires document-level planning and factual grounding, but current large language models, despite their strong local fluency, often fail in global structure, input coverage, and citation consistency. We present a reinforcement learning framework that casts scientific outline construction as a long-horizon planning problem over hierarchical document structures. Our approach models edit evolving outlines through structured actions, enabling the system to incrementally</td>
      <td>http://arxiv.org/abs/2601.09858v1</td>
    </tr>
    <tr>
      <td>The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The rapid adoption of large language model (LLM)-based systems -- from chatbots to autonomous agents capable of executing code and financial transactions -- has created a new attack surface that existing security frameworks inadequately address. The dominant framing of these threats as "prompt injection" -- a catch-all phrase for security failures in LLM-based systems -- obscures a more complex reality: Attacks on LLM-based systems increasingly involve multi-step sequences that mirror traditiona</td>
      <td>http://arxiv.org/abs/2601.09625v1</td>
    </tr>
    <tr>
      <td>Cooking Up Politeness in Human-AI Information Seeking Dialogue</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Politeness is a core dimension of human communication, yet its role in human-AI information seeking remains underexplored. We investigate how user politeness behaviour shapes conversational outcomes in a cooking-assistance setting. First, we annotated 30 dialogues, identifying four distinct user clusters ranging from Hyperpolite to Hyperefficient. We then scaled up to 18,000 simulated conversations across five politeness profiles (including impolite) and three open-weight models. Results show th</td>
      <td>http://arxiv.org/abs/2601.09898v1</td>
    </tr>
    <tr>
      <td>Continuum Memory Architectures for Long-Horizon LLM Agents</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Retrieval-augmented generation (RAG) has become the default strategy for providing large language model (LLM) agents with contextual knowledge. Yet RAG treats memory as a stateless lookup table: information persists indefinitely, retrieval is read-only, and temporal continuity is absent. We define the \textit{Continuum Memory Architecture} (CMA), a class of systems that maintain and update internal state across interactions through persistent storage, selective retention, associative routing, te</td>
      <td>http://arxiv.org/abs/2601.09913v1</td>
    </tr>
    <tr>
      <td>Learning-Augmented Perfectly Secure Collaborative Matrix Multiplication</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>This paper presents a perfectly secure matrix multiplication (PSMM) protocol for multiparty computation (MPC) of $\mathrm{A}^{\top}\mathrm{B}$ over finite fields. The proposed scheme guarantees correctness and information-theoretic privacy against threshold-bounded, semi-honest colluding agents, under explicit local storage constraints. Our scheme encodes submatrices as evaluations of sparse masking polynomials and combines coefficient alignment with Beaver-style randomness to ensure perfect sec</td>
      <td>http://arxiv.org/abs/2601.09916v1</td>
    </tr>
    <tr>
      <td>CaMeLs Can Use Computers Too: System-level Security for Computer Use Agents</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>AI agents are vulnerable to prompt injection attacks, where malicious content hijacks agent behavior to steal credentials or cause financial loss. The only known robust defense is architectural isolation that strictly separates trusted task planning from untrusted environment observations. However, applying this design to Computer Use Agents (CUAs) -- systems that automate tasks by viewing screens and executing actions -- presents a fundamental challenge: current agents require continuous observ</td>
      <td>http://arxiv.org/abs/2601.09923v1</td>
    </tr>
    <tr>
      <td>The PROPER Approach to Proactivity: Benchmarking and Advancing Knowledge Gap Navigation</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Most language-based assistants follow a reactive ask-and-respond paradigm, requiring users to explicitly state their needs. As a result, relevant but unexpressed needs often go unmet. Existing proactive agents attempt to address this gap either by eliciting further clarification, preserving this burden, or by extrapolating future needs from context, often leading to unnecessary or mistimed interventions. We introduce ProPer, Proactivity-driven Personalized agents, a novel two-agent architecture</td>
      <td>http://arxiv.org/abs/2601.09926v1</td>
    </tr>
    <tr>
      <td>In-Browser Agents for Search Assistance</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>A fundamental tension exists between the demand for sophisticated AI assistance in web search and the need for user data privacy. Current centralized models require users to transmit sensitive browsing data to external services, which limits user control. In this paper, we present a browser extension that provides a viable in-browser alternative. We introduce a hybrid architecture that functions entirely on the client side, combining two components: (1) an adaptive probabilistic model that learn</td>
      <td>http://arxiv.org/abs/2601.09928v1</td>
    </tr>
    <tr>
      <td>Hallucination Detection and Mitigation in Large Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large Language Models (LLMs) and Large Reasoning Models (LRMs) offer transformative potential for high-stakes domains like finance and law, but their tendency to hallucinate, generating factually incorrect or unsupported content, poses a critical reliability risk. This paper introduces a comprehensive operational framework for hallucination management, built on a continuous improvement cycle driven by root cause awareness. We categorize hallucination sources into model, data, and context-related</td>
      <td>http://arxiv.org/abs/2601.09929v1</td>
    </tr>
    <tr>
      <td>From SERPs to Agents: A Platform for Comparative Studies of Information Interaction</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The diversification of information access systems, from RAG to autonomous agents, creates a critical need for comparative user studies. However, the technical overhead to deploy and manage these distinct systems is a major barrier. We present UXLab, an open-source system for web-based user studies that addresses this challenge. Its core is a web-based dashboard enabling the complete, no-code configuration of complex experimental designs. Researchers can visually manage the full study, from recru</td>
      <td>http://arxiv.org/abs/2601.09937v1</td>
    </tr>
    <tr>
      <td>Beyond Optimization: Harnessing Quantum Annealer Dynamics for Machine Learning</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Quantum annealing is typically regarded as a tool for combinatorial optimization, but its coherent dynamics also offer potential for machine learning. We present a model that encodes classical data into an Ising Hamiltonian, evolves it on a quantum annealer, and uses the resulting probability distributions as feature maps for classification. Experiments on the quantum annealer machine with the Digits dataset, together with simulations on MNIST, demonstrate that short annealing times yield higher</td>
      <td>http://arxiv.org/abs/2601.09938v1</td>
    </tr>
    <tr>
      <td>Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Most existing Large Language Model (LLM)-based Multi-Agent Systems (MAS) rely on predefined workflows, where human engineers enumerate task states in advance and specify routing rules and contextual injections accordingly. Such workflow-driven designs are essentially rule-based decision trees, which suffer from two fundamental limitations: they require substantial manual effort to anticipate and encode possible task states, and they cannot exhaustively cover the state space of complex real-world</td>
      <td>http://arxiv.org/abs/2601.09883v1</td>
    </tr>
    <tr>
      <td>Who Owns My AI Twin? Data Ownership in a New World of Simulated Identities</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The emergence of AI twins, digital replicas that encapsulate an individual's knowledge, memories, psychological traits, and behavioral patterns, raises novel legal and ethical challenges for data governance and personal identity. Built from personal data, these systems require a rethinking of what it means to exercise dominion over one's data and to maintain personal autonomy in an AI-mediated environment. This article argues that natural persons should be recognized as the moral and legal owner</td>
      <td>http://arxiv.org/abs/2601.09877v1</td>
    </tr>
    <tr>
      <td>Epistemology gives a Future to Complementarity in Human-AI Interactions</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Human-AI complementarity is the claim that a human supported by an AI system can outperform either alone in a decision-making process. Since its introduction in the human-AI interaction literature, it has gained traction by generalizing the reliance paradigm and by offering a more practical alternative to the contested construct of 'trust in AI.' Yet complementarity faces key theoretical challenges: it lacks precise theoretical anchoring, it is formalized just as a post hoc indicator of relative</td>
      <td>http://arxiv.org/abs/2601.09871v1</td>
    </tr>
    <tr>
      <td>A Scoping Review of the Ethical Perspectives on Anthropomorphising Large Language Model-Based Conversational Agents</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Anthropomorphisation -- the phenomenon whereby non-human entities are ascribed human-like qualities -- has become increasingly salient with the rise of large language model (LLM)-based conversational agents (CAs). Unlike earlier chatbots, LLM-based CAs routinely generate interactional and linguistic cues, such as first-person self-reference, epistemic and affective expressions that empirical work shows can increase engagement. On the other hand, anthropomorphisation raises ethical concerns, incl</td>
      <td>http://arxiv.org/abs/2601.09869v1</td>
    </tr>
    <tr>
      <td>MedRedFlag: Investigating how LLMs Redirect Misconceptions in Real-World Health Communication</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Real-world health questions from patients often unintentionally embed false assumptions or premises. In such cases, safe medical communication typically involves redirection: addressing the implicit misconception and then responding to the underlying patient context, rather than the original question. While large language models (LLMs) are increasingly being used by lay users for medical advice, they have not yet been tested for this crucial competency. Therefore, in this work, we investigate ho</td>
      <td>http://arxiv.org/abs/2601.09853v1</td>
    </tr>
    <tr>
      <td>ViSIL: Unified Evaluation of Information Loss in Multimodal Video Captioning</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Multimodal video captioning condenses dense footage into a structured format of keyframes and natural language. By creating a cohesive multimodal summary, this approach anchors generative AI in rich semantic evidence and serves as a lightweight proxy for high-efficiency retrieval. However, traditional metrics like BLEU or ROUGE fail to quantify information coverage across disparate modalities, such as comparing a paragraph of text to a sequence of keyframes. To address this, we propose the Video</td>
      <td>http://arxiv.org/abs/2601.09851v1</td>
    </tr>
    <tr>
      <td>LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Despite recent advancements in Large Language Models (LLMs), complex Software Engineering (SE) tasks require more collaborative and specialized approaches. This concept paper systematically reviews the emerging paradigm of LLM-based multi-agent systems, examining their applications across the Software Development Life Cycle (SDLC), from requirements engineering and code generation to static code checking, testing, and debugging. We delve into a wide range of topics such as language model selecti</td>
      <td>http://arxiv.org/abs/2601.09822v1</td>
    </tr>
    <tr>
      <td>Explainable Deep Learning for Pediatric Pneumonia Detection in Chest X-Ray Images</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Background: Pneumonia remains a leading cause of morbidity and mortality among children worldwide, emphasizing the need for accurate and efficient diagnostic support tools. Deep learning has shown strong potential in medical image analysis, particularly for chest X-ray interpretation. This study compares two state-of-the-art convolutional neural network (CNN) architectures for automated pediatric pneumonia detection. Methods: A publicly available dataset of 5,863 pediatric chest X-ray images was</td>
      <td>http://arxiv.org/abs/2601.09814v1</td>
    </tr>
    <tr>
      <td>An agent-based modelling approach to investigate the impact of gender on tuberculosis transmission in Uganda</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Tuberculosis (TB) is an airborne disease caused by the pathogen Mycobacterium tuberculosis. In 2023, it returned to being the leading cause of death from an infectious agent globally, replacing COVID-19; in the nineteenth century, one in seven of all humans died of tuberculosis. More than 10 million people are diagnosed with TB every year. The majority of cases in adults occur in males (62.5% of all global adult cases in 2023, compared to 37.5% in females). The main reasons for males suffering f</td>
      <td>http://arxiv.org/abs/2601.09813v1</td>
    </tr>
    <tr>
      <td>Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Modern video generative models based on diffusion models can produce very realistic clips, but they are computationally inefficient, often requiring minutes of GPU time for just a few seconds of video. This inefficiency poses a critical barrier to deploying generative video in applications that require real-time interactions, such as embodied AI and VR/AR. This paper explores a new strategy for camera-conditioned video generation of static scenes: using diffusion-based generative models to gener</td>
      <td>http://arxiv.org/abs/2601.09697v1</td>
    </tr>
    <tr>
      <td>LLMs can Compress LLMs: Adaptive Pruning by Agents</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>As Large Language Models (LLMs) continue to scale, post-training pruning has emerged as a promising approach to reduce computational costs while preserving performance. Existing methods such as SparseGPT and Wanda achieve high sparsity through layer-wise weight reconstruction or activation-aware magnitude pruning, but rely on uniform or hand-crafted heuristics to determine per-layer sparsity ratios. Moreover, recent work has shown that pruned LLMs suffer from severe factual knowledge degradation</td>
      <td>http://arxiv.org/abs/2601.09694v1</td>
    </tr>
    <tr>
      <td>A continental-scale dataset of ground beetles with high-resolution images and validated morphological trait measurements</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Despite the ecological significance of invertebrates, global trait databases remain heavily biased toward vertebrates and plants, limiting comprehensive ecological analyses of high-diversity groups like ground beetles. Ground beetles (Coleoptera: Carabidae) serve as critical bioindicators of ecosystem health, providing valuable insights into biodiversity shifts driven by environmental changes. While the National Ecological Observatory Network (NEON) maintains an extensive collection of carabid s</td>
      <td>http://arxiv.org/abs/2601.10687v1</td>
    </tr>
    <tr>
      <td>DeepResearchEval: An Automated Framework for Deep Research Task Construction and Agentic Evaluation</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Deep research systems are widely used for multi-step web research, analysis, and cross-source synthesis, yet their evaluation remains challenging. Existing benchmarks often require annotation-intensive task construction, rely on static evaluation dimensions, or fail to reliably verify facts when citations are missing. To bridge these gaps, we introduce DeepResearchEval, an automated framework for deep research task construction and agentic evaluation. For task construction, we propose a persona-</td>
      <td>http://arxiv.org/abs/2601.09688v1</td>
    </tr>
    <tr>
      <td>Automating Supply Chain Disruption Monitoring via an Agentic AI Approach</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework</td>
      <td>http://arxiv.org/abs/2601.09680v1</td>
    </tr>
    <tr>
      <td>Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inf</td>
      <td>http://arxiv.org/abs/2601.09667v2</td>
    </tr>
    <tr>
      <td>Identifying Models Behind Text-to-Image Leaderboards</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Text-to-image (T2I) models are increasingly popular, producing a large share of AI-generated images online. To compare model quality, voting-based leaderboards have become the standard, relying on anonymized model outputs for fairness. In this work, we show that such anonymity can be easily broken. We find that generations from each T2I model form distinctive clusters in the image embedding space, enabling accurate deanonymization without prompt control or training data. Using 22 models and 280</td>
      <td>http://arxiv.org/abs/2601.09647v1</td>
    </tr>
    <tr>
      <td>Long-Term Average Impulse and Singular Control of a Growth Model with Two Revenue Sources</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>This paper analyzes and explicitly solves a class of long-term average impulse control problems and a related class of singular control problems. The underlying process is a general one-dimensional diffusion with appropriate boundary behavior. The model is motivated by applications such as the optimal long-term management of renewable resources and financial portfolio management. A large class of admissible policies is identified over which the agent seeks to maximize her long-term average rewar</td>
      <td>http://arxiv.org/abs/2601.09646v1</td>
    </tr>
    <tr>
      <td>PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>While GUI agents have shown strong performance under explicit and completion instructions, real-world deployment requires aligning with users' more complex implicit intents. In this work, we highlight Hierarchical Implicit Intent Alignment for Personalized GUI Agent (PersonalAlign), a new agent task that requires agents to leverage long-term user records as persistent context to resolve omitted preferences in vague instructions and anticipate latent routines by user state for proactive assistanc</td>
      <td>http://arxiv.org/abs/2601.09636v1</td>
    </tr>
    <tr>
      <td>LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large-scale optimization is a key backbone of modern business decision-making. However, building these models is often labor-intensive and time-consuming. We address this by proposing LEAN-LLM-OPT, a LightwEight AgeNtic workflow construction framework for LLM-assisted large-scale OPTimization auto-formulation. LEAN-LLM-OPT takes as input a problem description together with associated datasets and orchestrates a team of LLM agents to produce an optimization formulation. Specifically, upon receivi</td>
      <td>http://arxiv.org/abs/2601.09635v1</td>
    </tr>
    <tr>
      <td>LLMs Got Rhythm? Hybrid Phonological Filtering for Greek Poetry Rhyme Detection and Generation</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large Language Models (LLMs), despite their remarkable capabilities across NLP tasks, struggle with phonologically-grounded phenomena like rhyme detection and generation. This is even more evident in lower-resource languages such as Modern Greek. In this paper, we present a hybrid system that combines LLMs with deterministic phonological algorithms to achieve accurate rhyme identification/analysis and generation. Our approach implements a comprehensive taxonomy of Greek rhyme types, including Pu</td>
      <td>http://arxiv.org/abs/2601.09631v1</td>
    </tr>
    <tr>
      <td>Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large Language Models (LLMs) enable advanced natural language processing but face deployment challenges on resource-constrained edge devices due to high computational, memory, and energy demands. Optimizing these models requires addressing three key challenges: acquiring task-specific data, fine-tuning for performance, and compressing models to accelerate inference while reducing resource demands. We propose an integrated framework combining GPTQ-based quantization, low-rank adaptation (LoRA), a</td>
      <td>http://arxiv.org/abs/2601.09865v1</td>
    </tr>
    <tr>
      <td>The Algorithmic Gaze: An Audit and Ethnography of the LAION-Aesthetics Predictor Model</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Visual generative AI models are trained using a one-size-fits-all measure of aesthetic appeal. However, what is deemed "aesthetic" is inextricably linked to personal taste and cultural values, raising the question of whose taste is represented in visual generative AI models. In this work, we study an aesthetic evaluation model--LAION Aesthetic Predictor (LAP)--that is widely used to curate datasets to train visual generative image models, like Stable Diffusion, and evaluate the quality of AI-gen</td>
      <td>http://arxiv.org/abs/2601.09896v1</td>
    </tr>
    <tr>
      <td>Strategies of cooperation and defection in five large language models</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large language models (LLMs) are increasingly deployed to support human decision-making. This use of LLMs has concerning implications, especially when their prescriptions affect the welfare of others. To gauge how LLMs make social decisions, we explore whether five leading models produce sensible strategies in the repeated prisoner's dilemma, which is the main metaphor of reciprocal cooperation. First, we measure the propensity of LLMs to cooperate in a neutral setting, without using language re</td>
      <td>http://arxiv.org/abs/2601.09849v1</td>
    </tr>
    <tr>
      <td>Hybrid guided variational autoencoder for visual place recognition</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Autonomous agents such as cars, robots and drones need to precisely localize themselves in diverse environments, including in GPS-denied indoor environments. One approach for precise localization is visual place recognition (VPR), which estimates the place of an image based on previously seen places. State-of-the-art VPR models require high amounts of memory, making them unwieldy for mobile deployment, while more compact models lack robustness and generalization capabilities. This work overcomes</td>
      <td>http://arxiv.org/abs/2601.09248v1</td>
    </tr>
    <tr>
      <td>ReflexDiffusion: Reflection-Enhanced Trajectory Planning for High-lateral-acceleration Scenarios in Autonomous Driving</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Generating safe and reliable trajectories for autonomous vehicles in long-tail scenarios remains a significant challenge, particularly for high-lateral-acceleration maneuvers such as sharp turns, which represent critical safety situations. Existing trajectory planners exhibit systematic failures in these scenarios due to data imbalance. This results in insufficient modelling of vehicle dynamics, road geometry, and environmental constraints in high-risk situations, leading to suboptimal or unsafe</td>
      <td>http://arxiv.org/abs/2601.09377v1</td>
    </tr>
    <tr>
      <td>Interplay of Micellar Architecture and Viscosity Governs Active Droplet Motility</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The autonomous motion of liquid crystal oil droplets in micellar media arises from spontaneous breaking of time reversal symmetry via nonlinear coupling between Marangoni stresses and surfactant transport. While this phenomenon has been widely studied, the influence of micellar solute structure remains unexplored. By modifying micellar architecture using a structure forming salt, we uncover a pronounced non monotonic dependence of droplet velocity on salt concentration. Increasing salt simultane</td>
      <td>http://arxiv.org/abs/2601.09376v1</td>
    </tr>
    <tr>
      <td>On the Fair Allocation to Asymmetric Agents with Binary XOS Valuations</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>We study the problem of allocating $m$ indivisible goods among $n$ agents, where each agent's valuation is fractionally subadditive (XOS). With respect to AnyPrice Share (APS) fairness, Kulkarni et al. (2024) showed that, when agents have binary marginal values, a $0.1222$-APS allocation can be found in polynomial time, and there exists an instance where no allocation is better than $0.5$-approximate APS. Very recently, Feige and Grinberg (2025) extended the problem to the asymmetric case, where</td>
      <td>http://arxiv.org/abs/2601.09299v1</td>
    </tr>
    <tr>
      <td>MACRO-LLM: LLM-Empowered Multi-Agent Collaborative Reasoning under Spatiotemporal Partial Observability</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large Language Model (LLM) agents deployed in complex real-world scenarios typically operate as spatially distributed entities. However, this physical dispersion constrains agents to limited local perception and finite temporal horizons. We characterize this bottleneck as spatiotemporal partial observability. Given such fragmented awareness, distributed agents struggle to coordinate efficiently. To bridge this gap, we introduce MACRO-LLM, LLM-empowered multi-agent collaborative reasoning under s</td>
      <td>http://arxiv.org/abs/2601.09295v1</td>
    </tr>
    <tr>
      <td>Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>We present a novel framework for solving Dynamic Job Shop Scheduling Problems under uncertainty, addressing the challenges introduced by stochastic job arrivals and unexpected machine breakdowns. Our approach follows a model-based paradigm, using Coloured Timed Petri Nets to represent the scheduling environment, and Maskable Proximal Policy Optimization to enable dynamic decision-making while restricting the agent to feasible actions at each decision point. To simulate realistic industrial condi</td>
      <td>http://arxiv.org/abs/2601.09293v1</td>
    </tr>
    <tr>
      <td>Blue Teaming Function-Calling Agents</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>We present an experimental evaluation that assesses the robustness of four open source LLMs claiming function-calling capabilities against three different attacks, and we measure the effectiveness of eight different defences. Our results show how these models are not safe by default, and how the defences are not yet employable in real-world scenarios.</td>
      <td>http://arxiv.org/abs/2601.09292v1</td>
    </tr>
    <tr>
      <td>M$^3$Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Recent advances in DeepResearch-style agents have demonstrated strong capabilities in autonomous information acquisition and synthesize from real-world web environments. However, existing approaches remain fundamentally limited to text modality. Extending autonomous information-seeking agents to multimodal settings introduces critical challenges: the specialization-generalization trade-off that emerges when training models for multimodal tool-use at scale, and the severe scarcity of training dat</td>
      <td>http://arxiv.org/abs/2601.09278v1</td>
    </tr>
    <tr>
      <td>Stable and Explainable Personality Trait Evaluation in Large Language Models with Internal Activations</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Evaluating personality traits in Large Language Models (LLMs) is key to model interpretation, comparison, and responsible deployment. However, existing questionnaire-based evaluation methods exhibit limited stability and offer little explainability, as their results are highly sensitive to minor variations in prompt phrasing or role-play configurations. To address these limitations, we propose an internal-activation-based approach, termed Persona-Vector Neutrality Interpolation (PVNI), for stabl</td>
      <td>http://arxiv.org/abs/2601.09833v1</td>
    </tr>
    <tr>
      <td>Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent. However, human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation. To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proact</td>
      <td>http://arxiv.org/abs/2601.09264v1</td>
    </tr>
    <tr>
      <td>Learning to Trust Experience: A Monitor-Trust-Regulator Framework for Learning under Unobservable Feedback Reliability</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Learning under unobservable feedback reliability poses a distinct challenge beyond optimization robustness: a system must decide whether to learn from an experience, not only how to learn stably. We study this setting as Epistemic Identifiability under Unobservable Reliability (EIUR), where each experience has a latent credibility, reliable and unreliable feedback can be locally indistinguishable, and data are generated in a closed loop by the learner's own evolving beliefs and actions. In EIUR,</td>
      <td>http://arxiv.org/abs/2601.09261v1</td>
    </tr>
    <tr>
      <td>MAXS: Meta-Adaptive Exploration with LLM Agents</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths. These issues make it difficult to balance global effectiveness and computational efficiency. To address these two issues, we propose meta-adaptive ex</td>
      <td>http://arxiv.org/abs/2601.09259v1</td>
    </tr>
    <tr>
      <td>Honesty-Aware Multi-Agent Framework for High-Fidelity Synthetic Data Generation in Digital Psychiatric Intake Doctor-Patient Interactions</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Data scarcity and unreliable self-reporting -- such as concealment or exaggeration -- pose fundamental challenges to psychiatric intake and assessment. We propose a multi-agent synthesis framework that explicitly models patient deception to generate high-fidelity, publicly releasable synthetic psychiatric intake records. Starting from DAIC-WOZ interviews, we construct enriched patient profiles and simulate a four-role workflow: a \emph{Patient} completes self-rated scales and participates in a s</td>
      <td>http://arxiv.org/abs/2601.09216v1</td>
    </tr>
    <tr>
      <td>Normal trace inequalities and decay of solutions to the nonlinear Maxwell system with absorbing boundary</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>We study the quasilinear Maxwell system with a strictly positive, state dependent boundary conductivity. For small data we show that the solution exists for all times and decays exponentially to $0$. As in related literature we assume a nontrapping condition. Our approach relies on a new trace estimate for the corresponding non-autonomous linear problem, an observability-type estimate, and a detailed regularity analysis. The results are improved in the linear autonomous case, using properties of</td>
      <td>http://arxiv.org/abs/2601.09490v1</td>
    </tr>
    <tr>
      <td>UserLM-R1: Modeling Human Reasoning in User Language Models with Multi-Reward Reinforcement Learning</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>User simulators serve as the critical interactive environment for agent post-training, and an ideal user simulator generalizes across domains and proactively engages in negotiation by challenging or bargaining. However, current methods exhibit two issues. They rely on static and context-unaware profiles, necessitating extensive manual redesign for new scenarios, thus limiting generalizability. Moreover, they neglect human strategic thinking, leading to vulnerability to agent manipulation. To add</td>
      <td>http://arxiv.org/abs/2601.09215v1</td>
    </tr>
    <tr>
      <td>Vision-Conditioned Variational Bayesian Last Layer Dynamics Models</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Agile control of robotic systems often requires anticipating how the environment affects system behavior. For example, a driver must perceive the road ahead to anticipate available friction and plan actions accordingly. Achieving such proactive adaptation within autonomous frameworks remains a challenge, particularly under rapidly changing conditions. Traditional modeling approaches often struggle to capture abrupt variations in system behavior, while adaptive methods are inherently reactive and</td>
      <td>http://arxiv.org/abs/2601.09178v1</td>
    </tr>
    <tr>
      <td>User-Centric Stream Sensing for Grant-Free Access: Deep Learning with Covariance Differencing</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Grant-free (GF) access is essential for massive connectivity but faces collision risks due to uncoordinated transmissions. While user-side sensing can mitigate these collisions by enabling autonomous transmission decisions, conventional methods become ineffective in overloaded scenarios where active streams exceed receive antennas. To address this problem, we propose a differential stream sensing framework that reframes the problem from estimating the total stream count to isolating newly activa</td>
      <td>http://arxiv.org/abs/2601.09168v1</td>
    </tr>
    <tr>
      <td>PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>This paper introduces PRA, an AI-agent design for simulating how individual users form privacy concerns in response to real-world news. Moving beyond population-level sentiment analysis, PRA integrates privacy and cognitive theories to simulate user-specific privacy reasoning grounded in personal comment histories and contextual cues. The agent reconstructs each user's "privacy mind", dynamically activates relevant privacy memory through a contextual filter that emulates bounded rationality, and</td>
      <td>http://arxiv.org/abs/2601.09152v1</td>
    </tr>
    <tr>
      <td>World Craft: Agentic Framework to Create Visualizable Worlds via Text</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large Language Models (LLMs) motivate generative agent simulation (e.g., AI Town) to create a ``dynamic world'', holding immense value across entertainment and research. However, for non-experts, especially those without programming skills, it isn't easy to customize a visualizable environment by themselves. In this paper, we introduce World Craft, an agentic world creation framework to create an executable and visualizable AI Town via user textual descriptions. It consists of two main modules,</td>
      <td>http://arxiv.org/abs/2601.09150v1</td>
    </tr>
    <tr>
      <td>KryptoPilot: An Open-World Knowledge-Augmented LLM Agent for Automated Cryptographic Exploitation</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Capture-the-Flag (CTF) competitions play a central role in modern cybersecurity as a platform for training practitioners and evaluating offensive and defensive techniques derived from real-world vulnerabilities. Despite recent advances in large language models (LLMs), existing LLM-based agents remain ineffective on high-difficulty cryptographic CTF challenges, which require precise cryptanalytic knowledge, stable long-horizon reasoning, and disciplined interaction with specialized toolchains. Th</td>
      <td>http://arxiv.org/abs/2601.09129v1</td>
    </tr>
    <tr>
      <td>A saturation-absorption rubidium magnetometer with multilevel optical Bloch-equation modeling for intermediate-to-high fields</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>We present SASHMAG (Saturated Absorption Spectroscopy High-field MAGnetometer), an atomic sensor designed for precision magnetic-field measurements in the intermediate-to-high field regime ($&gt;0.2\,\text{T}$) using Rubidium-87 ($^{87}Rb$). The sensor operates in the hyperfine Paschen-Back regime, where the hyperfine and Zeeman interactions decouple, and utilizes counter-propagating pump-probe configuration in Faraday geometry to resolve isolated, Doppler-free Zeeman transitions. To interpret the</td>
      <td>http://arxiv.org/abs/2601.09115v1</td>
    </tr>
    <tr>
      <td>The AI Hippocampus: How Far are We From Human Memory?</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Memory plays a foundational role in augmenting the reasoning, adaptability, and contextual fidelity of modern Large Language Models and Multi-Modal LLMs. As these models transition from static predictors to interactive systems capable of continual learning and personalized inference, the incorporation of memory mechanisms has emerged as a central theme in their architectural and functional evolution. This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organ</td>
      <td>http://arxiv.org/abs/2601.09113v1</td>
    </tr>
    <tr>
      <td>Towards Open Environments and Instructions: General Vision-Language Navigation via Fast-Slow Interactive Reasoning</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Vision-Language Navigation aims to enable agents to navigate to a target location based on language instructions. Traditional VLN often follows a close-set assumption, i.e., training and test data share the same style of the input images and instructions. However, the real world is open and filled with various unseen environments, posing enormous difficulties for close-set methods. To this end, we focus on the General Scene Adaptation (GSA-VLN) task, aiming to learn generalized navigation abilit</td>
      <td>http://arxiv.org/abs/2601.09111v1</td>
    </tr>
    <tr>
      <td>AviationLMM: A Large Multimodal Foundation Model for Civil Aviation</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency and customer satisfaction is paramount. Yet conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. They struggle to integrate heterogeneous data such as voice communications, radar tracks, sensor streams and textual reports, which limits situational awareness, adaptability, and real-time decision support. Th</td>
      <td>http://arxiv.org/abs/2601.09105v1</td>
    </tr>
    <tr>
      <td>Human-AI Co-design for Clinical Prediction Models</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Developing safe, effective, and practically useful clinical prediction models (CPMs) traditionally requires iterative collaboration between clinical experts, data scientists, and informaticists. This process refines the often small but critical details of the model building process, such as which features/patients to include and how clinical categories should be defined. However, this traditional collaboration process is extremely time- and resource-intensive, resulting in only a small fraction</td>
      <td>http://arxiv.org/abs/2601.09072v1</td>
    </tr>
    <tr>
      <td>Data Scaling for Navigation in Unknown Environments</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Generalization of imitation-learned navigation policies to environments unseen in training remains a major challenge. We address this by conducting the first large-scale study of how data quantity and data diversity affect real-world generalization in end-to-end, map-free visual navigation. Using a curated 4,565-hour crowd-sourced dataset collected across 161 locations in 35 countries, we train policies for point goal navigation and evaluate their closed-loop control performance on sidewalk robo</td>
      <td>http://arxiv.org/abs/2601.09444v1</td>
    </tr>
    <tr>
      <td>RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches that require parameter updates. While activation steering has emerged as a parameter efficient alternative, existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, we propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that</td>
      <td>http://arxiv.org/abs/2601.09269v1</td>
    </tr>
    <tr>
      <td>CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>To teach robots complex manipulation tasks, it is now a common practice to fine-tune a pre-trained vision-language-action model (VLA) on task-specific data. However, since this recipe updates existing representations, it is unsuitable for long-term operation in the real world, where robots must continually adapt to new tasks and environments while retaining the knowledge they have already acquired. Existing continual learning methods for robotics commonly require storing previous data (exemplars</td>
      <td>http://arxiv.org/abs/2601.09512v1</td>
    </tr>
    <tr>
      <td>Unifying Search and Recommendation in LLMs via Gradient Multi-Subspace Tuning</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Search and recommendation (S&amp;R) are core to online platforms, addressing explicit intent through queries and modeling implicit intent from behaviors, respectively. Their complementary roles motivate a unified modeling paradigm. Early studies to unify S&amp;R adopt shared encoders with task-specific heads, while recent efforts reframe item ranking in both S&amp;R as conditional generation. The latter holds particular promise, enabling end-to-end optimization and leveraging the semantic understanding of L</td>
      <td>http://arxiv.org/abs/2601.09496v1</td>
    </tr>
    <tr>
      <td>Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Modern logical reasoning with LLMs primarily relies on employing complex interactive frameworks that decompose the reasoning process into subtasks solved through carefully designed prompts or requiring external resources (e.g., symbolic solvers) to exploit their strong logical structures. While interactive approaches introduce additional overhead, hybrid approaches depend on external components, which limit their scalability. A non-interactive, end-to-end framework enables reasoning to emerge wi</td>
      <td>http://arxiv.org/abs/2601.09805v1</td>
    </tr>
    <tr>
      <td>ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and escal</td>
      <td>http://arxiv.org/abs/2601.09703v1</td>
    </tr>
    <tr>
      <td>Multimodal Signal Processing For Thermo-Visible-Lidar Fusion In Real-time 3D Semantic Mapping</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>In complex environments, autonomous robot navigation and environmental perception pose higher requirements for SLAM technology. This paper presents a novel method for semantically enhancing 3D point cloud maps with thermal information. By first performing pixel-level fusion of visible and infrared images, the system projects real-time LiDAR point clouds onto this fused image stream. It then segments heat source features in the thermal channel to instantly identify high temperature targets and ap</td>
      <td>http://arxiv.org/abs/2601.09578v1</td>
    </tr>
    <tr>
      <td>How well LLM-based test generation techniques perform with newer LLM versions?</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The rapid evolution of Large Language Models (LLMs) has strongly impacted software engineering, leading to a growing number of studies on automated unit test generation. However, the standalone use of LLMs without post-processing has proven insufficient, often producing tests that fail to compile or achieve high coverage. Several techniques have been proposed to address these issues, reporting improvements in test compilation and coverage. While important, LLM-based test generation techniques ha</td>
      <td>http://arxiv.org/abs/2601.09695v1</td>
    </tr>
    <tr>
      <td>Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large Language Model (LLM) routers dynamically select optimal models for given inputs. Existing approaches typically assume access to ground-truth labeled data, which is often unavailable in practice, especially when user request distributions are heterogeneous and unknown. We introduce Routing with Generated Data (RGD), a challenging setting in which routers are trained exclusively on generated queries and answers produced from high-level task descriptions by generator LLMs. We evaluate query-a</td>
      <td>http://arxiv.org/abs/2601.09692v1</td>
    </tr>
    <tr>
      <td>Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) has emerged as a promising direction for parameter-efficient deployment of Large Language Models (LLMs). By sharing a single adapter across multiple tasks, one can significantly reduce storage overhead. However, this approach suffers from negative transfer, where conflicting gradient updates from distinct tasks degrade the performance of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due</td>
      <td>http://arxiv.org/abs/2601.09684v1</td>
    </tr>
    <tr>
      <td>From Prompt to Protocol: Fast Charging Batteries with Large Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Efficiently optimizing battery charging protocols is challenging because each evaluation is slow, costly, and non-differentiable. Many existing approaches address this difficulty by heavily constraining the protocol search space, which limits the diversity of protocols that can be explored, preventing the discovery of higher-performing solutions. We introduce two gradient-free, LLM-driven closed-loop methods: Prompt-to-Optimizer (P2O), which uses an LLM to propose the code for small neural-netwo</td>
      <td>http://arxiv.org/abs/2601.09626v1</td>
    </tr>
    <tr>
      <td>DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Reinforcement learning (RL)-based enhancement of large language models (LLMs) often leads to reduced output diversity, undermining their utility in open-ended tasks like creative writing. Current methods lack explicit mechanisms for guiding diverse exploration and instead prioritize optimization efficiency and performance over diversity. This paper proposes an RL framework structured around a semi-structured long Chain-of-Thought (CoT), in which the generation process is decomposed into explicit</td>
      <td>http://arxiv.org/abs/2601.09609v1</td>
    </tr>
    <tr>
      <td>Dialogue Telemetry: Turn-Level Instrumentation for Autonomous Information Gathering</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Autonomous systems conducting schema-grounded information-gathering dialogues face an instrumentation gap, lacking turn-level observables for monitoring acquisition efficiency and detecting when questioning becomes unproductive. We introduce Dialogue Telemetry (DT), a measurement framework that produces two model-agnostic signals after each question-answer exchange: (i) a Progress Estimator (PE) quantifying residual information potential per category (with a bits-based variant), and (ii) a Stall</td>
      <td>http://arxiv.org/abs/2601.09570v1</td>
    </tr>
    <tr>
      <td>Benchmarking Post-Training Quantization of Large Language Models under Microscaling Floating Point Formats</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Microscaling Floating-Point (MXFP) has emerged as a promising low-precision format for large language models (LLMs). Despite various post-training quantization (PTQ) algorithms being proposed, they mostly focus on integer quantization, while their applicability and behavior under MXFP formats remain largely unexplored. To address this gap, this work conducts a systematic investigation of PTQ under MXFP formats, encompassing over 7 PTQ algorithms, 15 evaluation benchmarks, and 3 LLM families. The</td>
      <td>http://arxiv.org/abs/2601.09555v1</td>
    </tr>
    <tr>
      <td>Examining DOM Coordinate Effectiveness For Page Segmentation</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Web pages form a cornerstone of available data for daily human consumption and with the rise of LLM-based search and learning systems a treasure trove of valuable data. The scale of this data and its unstructured format still continue to grow requiring ever more robust automated extraction and retrieval mechanisms. Existing work, leveraging the web pages Document Object Model (DOM), often derives clustering vectors from coordinates informed by the DOM such as visual placement or tree structure.</td>
      <td>http://arxiv.org/abs/2601.09543v1</td>
    </tr>
    <tr>
      <td>Empathy Applicability Modeling for General Health Queries</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>LLMs are increasingly being integrated into clinical workflows, yet they often lack clinical empathy, an essential aspect of effective doctor-patient communication. Existing NLP frameworks focus on reactively labeling empathy in doctors' responses but offer limited support for anticipatory modeling of empathy needs, especially in general health queries. We introduce the Empathy Applicability Framework (EAF), a theory-driven approach that classifies patient queries in terms of the applicability o</td>
      <td>http://arxiv.org/abs/2601.09696v1</td>
    </tr>
    <tr>
      <td>SlidesGen-Bench: Evaluating Slides Generation via Computational and Quantitative Metrics</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The rapid evolution of Large Language Models (LLMs) has fostered diverse paradigms for automated slide generation, ranging from code-driven layouts to image-centric synthesis. However, evaluating these heterogeneous systems remains challenging, as existing protocols often struggle to provide comparable scores across architectures or rely on uncalibrated judgments. In this paper, we introduce SlidesGen-Bench, a benchmark designed to evaluate slide generation through a lens of three core principle</td>
      <td>http://arxiv.org/abs/2601.09487v1</td>
    </tr>
    <tr>
      <td>Ability Transfer and Recovery via Modularized Parameters Localization</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Large language models can be continually pre-trained or fine-tuned to improve performance in specific domains, languages, or skills, but this specialization often degrades other capabilities and may cause catastrophic forgetting. We investigate how abilities are distributed within LLM parameters by analyzing module activations under domain- and language-specific inputs for closely related models. Across layers and modules, we find that ability-related activations are highly concentrated in a sma</td>
      <td>http://arxiv.org/abs/2601.09398v1</td>
    </tr>
    <tr>
      <td>Bridging Semantic Understanding and Popularity Bias with LLMs</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Semantic understanding of popularity bias is a crucial yet underexplored challenge in recommender systems, where popular items are often favored at the expense of niche content. Most existing debiasing methods treat the semantic understanding of popularity bias as a matter of diversity enhancement or long-tail coverage, neglecting the deeper semantic layer that embodies the causal origins of the bias itself. Consequently, such shallow interpretations limit both their debiasing effectiveness and</td>
      <td>http://arxiv.org/abs/2601.09478v2</td>
    </tr>
    <tr>
      <td>SCE-SLAM: Scale-Consistent Monocular SLAM via Scene Coordinate Embeddings</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Monocular visual SLAM enables 3D reconstruction from internet video and autonomous navigation on resource-constrained platforms, yet suffers from scale drift, i.e., the gradual divergence of estimated scale over long sequences. Existing frame-to-frame methods achieve real-time performance through local optimization but accumulate scale drift due to the lack of global constraints among independent windows. To address this, we propose SCE-SLAM, an end-to-end SLAM system that maintains scale consis</td>
      <td>http://arxiv.org/abs/2601.09665v1</td>
    </tr>
    <tr>
      <td>The Imperfective Paradox in Large Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Do Large Language Models (LLMs) genuinely grasp the compositional semantics of events, or do they rely on surface-level probabilistic heuristics? We investigate the Imperfective Paradox, a logical phenomenon where the past progressive aspect entails event realization for activities (e.g., running $\to$ ran) but not for accomplishments (e.g., building $\nrightarrow$ built). We introduce ImperfectiveNLI, a diagnostic dataset designed to probe this distinction across diverse semantic classes. Evalu</td>
      <td>http://arxiv.org/abs/2601.09373v1</td>
    </tr>
    <tr>
      <td>SLAM-LLM: A Modular, Open-Source Multimodal Large Language Model Framework and Best Practice for Speech, Language, Audio and Music Processing</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The recent surge in open-source Multimodal Large Language Models (MLLM) frameworks, such as LLaVA, provides a convenient kickoff for artificial intelligence developers and researchers. However, most of the MLLM frameworks take vision as the main input modality, and provide limited in-depth support for the modality of speech, audio, and music. This situation hinders the development of audio-language models, and forces researchers to spend a lot of effort on code writing and hyperparameter tuning.</td>
      <td>http://arxiv.org/abs/2601.09385v1</td>
    </tr>
    <tr>
      <td>LCF3D: A Robust and Real-Time Late-Cascade Fusion Framework for 3D Object Detection in Autonomous Driving</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Accurately localizing 3D objects like pedestrians, cyclists, and other vehicles is essential in Autonomous Driving. To ensure high detection performance, Autonomous Vehicles complement RGB cameras with LiDAR sensors, but effectively combining these data sources for 3D object detection remains challenging. We propose LCF3D, a novel sensor fusion framework that combines a 2D object detector on RGB images with a 3D object detector on LiDAR point clouds. By leveraging multimodal fusion principles, w</td>
      <td>http://arxiv.org/abs/2601.09812v1</td>
    </tr>
    <tr>
      <td>Structured Knowledge Representation through Contextual Pages for Retrieval-Augmented Generation</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by incorporating external knowledge. Recently, some works have incorporated iterative knowledge accumulation processes into RAG models to progressively accumulate and refine query-related knowledge, thereby constructing more comprehensive knowledge representations. However, these iterative processes often lack a coherent organizational structure, which limits the construction of more comprehensive and cohesive knowledge r</td>
      <td>http://arxiv.org/abs/2601.09402v1</td>
    </tr>
    <tr>
      <td>TiInsight: A SQL-based Automated Exploratory Data Analysis System through Large Language Models</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>The SQL-based exploratory data analysis has garnered significant attention within the data analysis community. The emergence of large language models (LLMs) has facilitated the paradigm shift from manual to automated data exploration. However, existing methods generally lack the ability for cross-domain analysis, and the exploration of LLMs capabilities remains insufficient. This paper presents TiInsight, an SQL-based automated cross-domain exploratory data analysis system. First, TiInsight offe</td>
      <td>http://arxiv.org/abs/2601.09404v1</td>
    </tr>
    <tr>
      <td>Population-Aligned Audio Reproduction With LLM-Based Equalizers</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Conventional audio equalization is a static process that requires manual and cumbersome adjustments to adapt to changing listening contexts (e.g., mood, location, or social setting). In this paper, we introduce a Large Language Model (LLM)-based alternative that maps natural language text prompts to equalization settings. This enables a conversational approach to sound system control. By utilizing data collected from a controlled listening experiment, our models exploit in-context learning and p</td>
      <td>http://arxiv.org/abs/2601.09448v1</td>
    </tr>
    <tr>
      <td>SimMerge: Learning to Select Merge Operators from Similarity Signals</td>
      <td>ArXiv</td>
      <td>2026-01-14</td>
      <td>Model merging enables multiple large language models (LLMs) to be combined into a single model while preserving performance. This makes it a valuable tool in LLM development, offering a competitive alternative to multi-task training. However, merging can be difficult at scale, as successful merging requires choosing the right merge operator, selecting the right models, and merging them in the right order. This often leads researchers to run expensive merge-and-evaluate searches to select the bes</td>
      <td>http://arxiv.org/abs/2601.09473v1</td>
    </tr>
    <tr>
      <td>Imagine-then-Plan: Agent Learning from Adaptive Lookahead with World Models</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>Recent advances in world models have shown promise for modeling future dynamics of environmental states, enabling agents to reason and act without accessing real environments. Current methods mainly perform single-step or fixed-horizon rollouts, leaving their potential for complex task planning under-exploited. We propose Imagine-then-Plan (\texttt{ITP}), a unified framework for agent learning via lookahead imagination, where an agent's policy model interacts with the learned world model, yieldi</td>
      <td>http://arxiv.org/abs/2601.08955v1</td>
    </tr>
    <tr>
      <td>Agent Contracts: A Formal Framework for Resource-Bounded Autonomous AI Systems</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>The Contract Net Protocol (1980) introduced coordination through contracts in multi-agent systems. Modern agent protocols standardize connectivity and interoperability; yet, none provide formal, resource governance-normative mechanisms to bound how much agents may consume or how long they may operate. We introduce Agent Contracts, a formal framework that extends the contract metaphor from task allocation to resource-bounded execution. An Agent Contract unifies input/output specifications, multi-</td>
      <td>http://arxiv.org/abs/2601.08815v1</td>
    </tr>
    <tr>
      <td>MemRec: Collaborative Memory-Augmented Agentic Recommender System</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>The evolution of recommender systems has shifted preference storage from rating matrices and dense embeddings to semantic memory in the agentic era. Yet existing agents rely on isolated memory, overlooking crucial collaborative signals. Bridging this gap is hindered by the dual challenges of distilling vast graph contexts without overwhelming reasoning agents with cognitive load, and evolving the collaborative memory efficiently without incurring prohibitive computational costs. To address this,</td>
      <td>http://arxiv.org/abs/2601.08816v1</td>
    </tr>
    <tr>
      <td>Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>Researchers have proposed many text-to-SQL techniques to streamline data analytics and accelerate the development of database-driven applications. To compare these techniques and select the best one for deployment, the community depends on public benchmarks and their leaderboards. Since these benchmarks heavily rely on human annotations during question construction and answer evaluation, the validity of the annotations is crucial. In this paper, we conduct an empirical study that (i) benchmarks</td>
      <td>http://arxiv.org/abs/2601.08778v2</td>
    </tr>
    <tr>
      <td>Simulating hardware keyboard input on Windows</td>
      <td>HackerNews</td>
      <td>2026-01-13</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://autoptt.com/posts/simulating-a-real-keyboard-with-faker-input/</td>
    </tr>
    <tr>
      <td>Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions. Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair. We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory. Our simulation results showcase several interesting findings, including how incorporating Elo improves Area Chair decis</td>
      <td>http://arxiv.org/abs/2601.08829v1</td>
    </tr>
    <tr>
      <td>Towards a Self-Driving Trigger at the LHC: Adaptive Response in Real Time</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>Real-time data filtering and selection -- or trigger -- systems at high-throughput scientific facilities such as the experiments at the Large Hadron Collider (LHC) must process extremely high-rate data streams under stringent bandwidth, latency, and storage constraints. Yet these systems are typically designed as static, hand-tuned menus of selection criteria grounded in prior knowledge and simulation. In this work, we further explore the concept of a self-driving trigger, an autonomous data-fil</td>
      <td>http://arxiv.org/abs/2601.08910v1</td>
    </tr>
    <tr>
      <td>Fairness risk and its privacy-enabled solution in AI-driven robotic applications</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>Complex decision-making by autonomous machines and algorithms could underpin the foundations of future society. Generative AI is emerging as a powerful engine for such transitions. However, we show that Generative AI-driven developments pose a critical pitfall: fairness concerns. In robotic applications, although intuitions about fairness are common, a precise and implementable definition that captures user utility and inherent data randomness is missing. Here we provide a utility-aware fairness</td>
      <td>http://arxiv.org/abs/2601.08953v1</td>
    </tr>
    <tr>
      <td>Senior Front-End Developer- Analytics &amp; UX Focused (Remote) at Actionable.co</td>
      <td>RemoteJob</td>
      <td>2026-01-13</td>
      <td>At Actionable.co, we’re transforming how Learning &amp;amp; Development initiatives create lasting, measurable behavior change. Our platform empowers Consultants and Professionals in the Training, Leadership Development, Learning and Culture Change space to demonstrate measurable impact through our tech-enabled change methodology.We’re looking for a UX-obsessed front-end engineer who can turn complex analytics and participant workflows into intuitive, high-impact user experiences. This role starts w</td>
      <td>https://remotive.com/remote-jobs/software-development/senior-front-end-developer-analytics-ux-focused-remote-2088537</td>
    </tr>
    <tr>
      <td>ART: Action-based Reasoning Task Benchmarking for Medical AI Agents</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>Reliable clinical decision support requires medical AI agents capable of safe, multi-step reasoning over structured electronic health records (EHRs). While large language models (LLMs) show promise in healthcare, existing benchmarks inadequately assess performance on action-based tasks involving threshold evaluation, temporal aggregation, and conditional logic. We introduce ART, an Action-based Reasoning clinical Task benchmark for medical AI agents, which mines real-world EHR data to create cha</td>
      <td>http://arxiv.org/abs/2601.08988v1</td>
    </tr>
    <tr>
      <td>Multicultural Spyfall: Assessing LLMs through Dynamic Multilingual Social Deduction Game</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>The rapid advancement of Large Language Models (LLMs) has necessitated more robust evaluation methods that go beyond static benchmarks, which are increasingly prone to data saturation and leakage. In this paper, we propose a dynamic benchmarking framework for evaluating multilingual and multicultural capabilities through the social deduction game Spyfall. In our setup, models must engage in strategic dialogue to either identify a secret agent or avoid detection, utilizing culturally relevant loc</td>
      <td>http://arxiv.org/abs/2601.09017v1</td>
    </tr>
    <tr>
      <td>Agentic AI and Machine Learning for Accelerated Materials Discovery and Applications</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>Artificial Intelligence (AI), especially AI agents, is increasingly being applied to chemistry, healthcare, and manufacturing to enhance productivity. In this review, we discuss the progress of AI and agentic AI in areas related to, and beyond polymer materials and discovery chemistry. More specifically, the focus is on the need for efficient discovery, core concepts, and large language models. Consequently, applications are showcased in scenarios such as (1) flow chemistry, (2) biosensors, and</td>
      <td>http://arxiv.org/abs/2601.09027v2</td>
    </tr>
    <tr>
      <td>🇫🇷 Senior Site Reliability Engineer (SRE) - Cloud at Scalingo</td>
      <td>RemoteJob</td>
      <td>2026-01-13</td>
      <td>🇫🇷 This job ad is written in French. 🇫🇷\n🌍 À propos de Scalingo\nScalingo est une startup technologique en forte croissance. Notre plateforme cloud européenne, robuste et souveraine, libère les équipes techniques des contraintes d’infrastructure, pour leur permettre de se concentrer sur ce qui compte vraiment : créer, innover et délivrer.\nNotre PaaS permet de déployer et d’héberger facilement des applications web et des bases de données, sans avoir à gérer l’administration système ou l’infrastruct</td>
      <td>https://remotive.com/remote-jobs/devops/senior-site-reliability-engineer-sre-cloud-2088536</td>
    </tr>
    <tr>
      <td>Senior Software Engineer, Global Contractor at Jump</td>
      <td>RemoteJob</td>
      <td>2026-01-13</td>
      <td>Who are we?\nHey there! We are Jumpapp.com, AI for Financial Advisors. Jump’s mission is to empower financial advisors, firms, and clients to thrive in the age of AI with smarter workflows, deeper insights, and enterprise-grade security and compliance.\nJump leads its category in market share, customer satisfaction, and analyst rankings, and is rapidly growing Jump was launched in 2023 by repeat entrepreneurs and is led by a team with backgrounds from Harvard, Stanford, Google, Snowflake, Bill.com</td>
      <td>https://remotive.com/remote-jobs/software-development/senior-software-engineer-global-contractor-2088534</td>
    </tr>
    <tr>
      <td>The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. We present an empirical study evaluating frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. Our analysis reveals an empirically-derived \emph{hierarchy of agentic capabilities} that models must master for real-world deployment: (1) tool use, (2) planning and goal formati</td>
      <td>http://arxiv.org/abs/2601.09032v1</td>
    </tr>
    <tr>
      <td>To Retrieve or To Think? An Agentic Approach for Context Evolution</td>
      <td>ArXiv</td>
      <td>2026-01-13</td>
      <td>Current context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks. However, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step. This indiscriminate approach not only incurs unnecessary computational costs but also degrades performance by saturating the context with irrelevant noise. To address these limitations, we introduce Agentic Context Evolution (ACE), a framework inspired by</td>
      <td>http://arxiv.org/abs/2601.08747v2</td>
    </tr>
    <tr>
      <td>Implementing FakerInput</td>
      <td>HackerNews</td>
      <td>2026-01-12</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://autoptt.com/posts/implementing-faker-input/</td>
    </tr>
    <tr>
      <td>AI Trainer at Anuttacon</td>
      <td>RemoteJob</td>
      <td>2026-01-12</td>
      <td>🎮 Our Culture:\n \nOur culture thrives on creativity, communication, and collaboration. Around here, the work is the game. You’ll have fun, make real connections, and actually see the impact of what you do.\n \n\n \n \n🎮 About Us:\n \nAnuttacon’s mission is to create immersive and personalized virtual worlds where players can form unique connections and deeper experiences in digital spaces. We are dedicated to leveraging different perspectives, voices, and backgrounds to promote a thoughtful and humanist</td>
      <td>https://remotive.com/remote-jobs/ai-ml/ai-trainer-2087694</td>
    </tr>
    <tr>
      <td>Show HN: Yolobox – Run AI coding agents with full sudo without nuking home dir</td>
      <td>HackerNews</td>
      <td>2026-01-12</td>
      <td>Points: 121, Comments: 99</td>
      <td>https://github.com/finbarr/yolobox</td>
    </tr>
    <tr>
      <td>Quantitative Research Team Lead (Completed) at Apexver</td>
      <td>RemoteJob</td>
      <td>2026-01-12</td>
      <td>Role Overview\nAs the Quantitative Research Team Lead, you will head a team of quants and researchers dedicated to developing trading strategies, improving alpha models, and optimizing execution. This role is both hands-on research and strategic leadership: you will drive model development, oversee research pipelines, and mentor team members while shaping Apexver’s research roadmap.\nYou will partner with traders, engineers, and data scientists to push the boundaries of what’s possible in high-fre</td>
      <td>https://remotive.com/remote-jobs/software-development/quantitative-research-team-lead-completed-2088533</td>
    </tr>
    <tr>
      <td>Office Assistant at Coalition Technologies</td>
      <td>RemoteJob</td>
      <td>2026-01-11</td>
      <td>WHY YOU SHOULD APPLY:\n \nCoalition Technologies is devoted to delivering clients the highest quality work while providing our team a fun, thriving, and innovative environment. Along with the opportunity for tremendous career growth and rapid advancement, CT offers:\n\nThe most competitive profit-sharing bonus plan in the industry, paying up to 50% of company profits to full-time employees each month!\nA highly competitive Paid Time Off plan, promoting quality work-life balance.\nSubsidized gym member</td>
      <td>https://remotive.com/remote-jobs/marketing/office-assistant-1680495</td>
    </tr>
    <tr>
      <td>Show HN: ContextGraph Cloud – Governance infrastructure for AI agents</td>
      <td>HackerNews</td>
      <td>2026-01-10</td>
      <td>We built this because enterprise customers kept asking: &amp;quot;How do we prove our AI agents are compliant?&amp;quot;&lt;p&gt;The problem:\n• AI agents make autonomous decisions (trading, medical, customer service)\n• No standard audit trail format\n• Policy enforcement is ad-hoc (if it exists)\n• Compliance teams can&amp;#x27;t verify anything\n• When something goes wrong, you can&amp;#x27;t trace what happened&lt;p&gt;What we built:\n• Decision trace logging with full provenance chains\n• Policy-as-code enforcement (evaluate</td>
      <td>https://github.com/akz4ol/contextgraph-cloud</td>
    </tr>
    <tr>
      <td>Show HN: ContextGraph Cloud – Governance infrastructure for AI agents</td>
      <td>HackerNews</td>
      <td>2026-01-10</td>
      <td>We built this because enterprise customers kept asking: &amp;quot;How do we prove our AI agents are compliant?&amp;quot;&lt;p&gt;The problem:\n• AI agents make autonomous decisions (trading, medical, customer service)\n• No standard audit trail format\n• Policy enforcement is ad-hoc (if it exists)\n• Compliance teams can&amp;#x27;t verify anything\n• When something goes wrong, you can&amp;#x27;t trace what happened&lt;p&gt;What we built:\n• Decision trace logging with full provenance chains\n• Policy-as-code enforcement (evaluate</td>
      <td>https://github.com/akz4ol/contextgraph-integrations</td>
    </tr>
    <tr>
      <td>Executive Assistant &amp; Accountability Partner (Full‑Time, Remote, ET Hours) at N/A</td>
      <td>RemoteJob</td>
      <td>2026-01-10</td>
      <td>About the role\nWe are seeking a college‑educated, high‑judgment Executive Assistant to partner with a CEO and spouse across work and family operations. This is a 40 hrs/week, long‑term role in Eastern Time (ET). You will run complex calendars and travel, keep our “family operating system” tight, act as a gentle accountability coach for both principals, and prepare bill payments within a clear approvals workflow. We’re looking for someone who leads up—proactive, thoughtful, and comfortable prompt</td>
      <td>https://remotive.com/remote-jobs/all-others/executive-assistant-accountability-partner-fulltime-remote-et-hours-2087132</td>
    </tr>
    <tr>
      <td>iOS Developer at nooro</td>
      <td>RemoteJob</td>
      <td>2026-01-09</td>
      <td>WHO ARE WE?\n \nAt nooro, we're revolutionizing pain management for seniors. Our platform is transforming how older adults engage with pain management at home. We're on a mission to make wellness more accessible and effective through technology.\n \nCheck our website here: https://nooro-us.com/\n \nWe're a fast-moving startup that works on quick iteration and bold decisions. Our team is lean, agile, and empowered to make meaningful impacts daily. If you enjoy a dynamic environment where ideas become a</td>
      <td>https://remotive.com/remote-jobs/software-development/ios-developer-1956455</td>
    </tr>
    <tr>
      <td>Senior Frontend Engineer at Vialma</td>
      <td>RemoteJob</td>
      <td>2026-01-08</td>
      <td>About UsVialma is a streaming service dedicated to music and the arts, creating unforgettable digital and multimedia experiences for our B2B clients and end users. We work in close partnership with museums, concert halls, and cultural organisations (e.g., Paris Opera, Orsay Museum, London Symphony Orchestra), as well as corporate brands and financial institutions across Europe, to help them connect with their audiences, increase revenue, and raise funds.We build white-label streaming services an</td>
      <td>https://remotive.com/remote-jobs/software-development/senior-frontend-engineer-2088531</td>
    </tr>
    <tr>
      <td>AI Marketing Automation SaaS with Autonomous Agents</td>
      <td>HackerNews</td>
      <td>2026-01-08</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://flippa.com/12205760-vect-ai-is-an-autonomous-marketing-command-center-where-ai-agents-plan-campaigns-create-visuals-and-run-10-growth-tools-from-one-unified-system</td>
    </tr>
    <tr>
      <td>Inside Sales Contractor at Credit Wellness, LLC</td>
      <td>RemoteJob</td>
      <td>2026-01-08</td>
      <td>About Us\nWe are a financial services start up focusing on helping to improve consumer credit profiles. We are currently seeking KPI driven sales representatives looking to earn up to 45K in their first year while working remotely. We offer comprehensive training and continuous sales coaching to help you meet your financial goals.\nDuring our training period we offer a guaranteed training stipend while our trainees are acclimating to the position (*see weekly pay below). If you are a seasoned sale</td>
      <td>https://remotive.com/remote-jobs/sales-business/inside-sales-contractor-2086540</td>
    </tr>
    <tr>
      <td>Context Graphs: The Next Data Platform for Enterprise AI Automation</td>
      <td>HackerNews</td>
      <td>2026-01-08</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://twitter.com/jainarvind/status/2008965852381483258</td>
    </tr>
    <tr>
      <td>AI automation paradox: More work, not less</td>
      <td>HackerNews</td>
      <td>2026-01-07</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://www.theregister.com/2026/01/06/ai_could_damage_your_health/</td>
    </tr>
    <tr>
      <td>Comparing AI agents to cybersecurity professionals in real-world pen testing</td>
      <td>HackerNews</td>
      <td>2026-01-06</td>
      <td>WSJ writeup (&amp;quot;AI Hackers Are Coming Dangerously Close to Beating Humans&amp;quot;): &lt;a href="https:&amp;#x2F;&amp;#x2F;www.wsj.com&amp;#x2F;tech&amp;#x2F;ai&amp;#x2F;ai-hackers-are-coming-dangerously-close-to-beating-humans-4afc3ad6" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.wsj.com&amp;#x2F;tech&amp;#x2F;ai&amp;#x2F;ai-hackers-are-coming-dangerousl...&lt;/a&gt;, &lt;a href="https:&amp;#x2F;&amp;#x2F;archive.ph&amp;#x2F;L4gh3" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;archive.ph&amp;#x2F;L4gh3&lt;/a&gt;</td>
      <td>https://arxiv.org/abs/2512.09882</td>
    </tr>
    <tr>
      <td>Opus 4.5 is not the normal AI agent experience that I have had thus far</td>
      <td>HackerNews</td>
      <td>2026-01-06</td>
      <td>Points: 878, Comments: 1353</td>
      <td>https://burkeholland.github.io/posts/opus-4-5-change-everything/</td>
    </tr>
    <tr>
      <td>🇩🇪 EU Freelance Customer Advisor – Inbound Mobile / Prepaid at hey contact heroes GmbH</td>
      <td>RemoteJob</td>
      <td>2026-01-06</td>
      <td>🇩🇪 This job ad is written in German. 🇩🇪\n100% Remote innerhalb der EU (außer Deutschland)\nProjektstart: Februar – wir suchen 150 neue Partner!\nDie hey contact heroes starten ein neues, großes Mobilfunk-Projekt im Bereich Prepaid Kundenservice – und dafür suchen wir zuverlässige, motivierte Freelancer, die uns langfristig unterstützen.\nWenn Du innerhalb der EU (aber nicht in Deutschland) lebst und Lust hast, als professioneller Customer-Service-Partner mit uns durchzustarten, bist Du bei uns genau</td>
      <td>https://remotive.com/remote-jobs/customer-service/eu-freelance-customer-advisor-inbound-mobile-prepaid-2088527</td>
    </tr>
    <tr>
      <td>Agentic Frameworks in 2026: Less Hype, More Autonomy</td>
      <td>HackerNews</td>
      <td>2026-01-06</td>
      <td>Over the last two years we have gone from “LLMs with tools” to genuinely agentic systems that plan, reflect, delegate, retry, and sometimes surprise us in ways that feel uncomfortably close to junior engineers. The ecosystem has matured fast enough that framework choice now meaningfully shapes what your agents can and cannot become.&lt;p&gt;Here is a ground level comparison from someone who has built, broken, and rebuilt agents across several stacks, focusing less on benchmarks and more on lived behav</td>
      <td>https://news.ycombinator.com/item?id=46509130</td>
    </tr>
    <tr>
      <td>Show HN: Mantic.sh – A structural code search engine for AI agents</td>
      <td>HackerNews</td>
      <td>2026-01-06</td>
      <td>Author here! Some context: I published this 48 hours ago and it was auto-listed on MCPMarket (the MCP tools directory). Got 700+ organic downloads with zero marketing—developers were actively searching for exactly this solution.&lt;p&gt;The &amp;quot;Git Accelerator&amp;quot; optimization story:&lt;p&gt;Initially used a file walker that took 6.6s on Chromium. Profiling showed 90% was filesystem I&amp;#x2F;O. The fix: git ls-files returns 480k paths in ~200ms. Added smart heuristics for untracked files (only scan dirs &amp;</td>
      <td>https://github.com/marcoaapfortes/Mantic.sh</td>
    </tr>
    <tr>
      <td>Show HN: AI compliance automation for startups and lean teams</td>
      <td>HackerNews</td>
      <td>2026-01-04</td>
      <td>Regulance is an AI-powered compliance automation platform for startups and SaaS companies. It helps teams achieve GDPR, SOC 2, ISO 27001, PCI DSS, and HIPAA compliance faster by automating evidence collection, policies, risk management, and audit readiness.&lt;p&gt;Background: While working on PCI-DSS compliance for IntaSend (my other company), we struggled to first collect evidence, which is very fragmented, keep track of things we need to do periodically, etc. We found some good solutions, but they</td>
      <td>https://regulance.io/</td>
    </tr>
    <tr>
      <td>Show HN: I built a tool to create AI agents that live in iMessage</td>
      <td>HackerNews</td>
      <td>2026-01-04</td>
      <td>Hey everyone, I made this thing:\n&lt;a href="https:&amp;#x2F;&amp;#x2F;tryflux.ai&amp;#x2F;" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;tryflux.ai&amp;#x2F;&lt;/a&gt;. Here&amp;#x27;s a demo video: &lt;a href="https:&amp;#x2F;&amp;#x2F;screen.studio&amp;#x2F;share&amp;#x2F;1y2EnC26" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;screen.studio&amp;#x2F;share&amp;#x2F;1y2EnC26&lt;/a&gt;&lt;p&gt;Context: I&amp;#x27;ve tried probably 15 different AI apps over the past year. ChatGPT, note-taking apps, productivity apps, all of it. But most of them are just clutter on my iphone.&lt;p&gt;They live in s</td>
      <td>https://tryflux.ai/</td>
    </tr>
    <tr>
      <td>Copywriter at Coalition Technologies</td>
      <td>RemoteJob</td>
      <td>2026-01-02</td>
      <td>\nWHO WE'RE LOOKING FOR\nThe ideal copywriter has excellent English writing skills and is excited to write high-quality, SEO-driven content that aligns with detailed, client-specific guidelines. Projects most commonly include writing web pages for eCommerce and lead generation business sites such as category pages, product descriptions, and blog posts. Our clientele is constantly evolving. We produce content for these and many other industry verticals:\n \nFashion (both mass-market and luxury)\nSkin</td>
      <td>https://remotive.com/remote-jobs/writing/copywriter-1749306</td>
    </tr>
    <tr>
      <td>AI Automation</td>
      <td>HackerNews</td>
      <td>2025-12-31</td>
      <td>HN PHONE DEMO - AI BUSINESS FACTORY\n======================================\nRunning on: Linux localhost 5.10.226-android12-9-g018b9fdb2168 #1 SMP PREEMPT Thu May 8 03:53:46 UTC 2025 aarch64 Android        Storage: 0 free\nMemory: 2.8Gi&amp;#x2F;5.3Gi used                   \n Starting AI Business Factory Demo...\nThis is what&amp;#x27;s running on my actual phone right now.&lt;p&gt;Demo output: &amp;#x2F;data&amp;#x2F;data&amp;#x2F;com.termux&amp;#x2F;files&amp;#x2F;home&amp;#x2F;HN_DEMO_1767188899&lt;p&gt;Generating AI business concepts...</td>
      <td>https://news.ycombinator.com/item?id=46444061</td>
    </tr>
    <tr>
      <td>Building an AI agent inside a 7-year-old Rails monolith</td>
      <td>HackerNews</td>
      <td>2025-12-26</td>
      <td>Points: 109, Comments: 53</td>
      <td>https://catalinionescu.dev/ai-agent/building-ai-agent-part-1/</td>
    </tr>
    <tr>
      <td>Senior Amazon Brand Manager at GNO Partners</td>
      <td>RemoteJob</td>
      <td>2025-12-26</td>
      <td>Why Join Us?\n\nFully remote Amazon consulting agency.\nHigh-performance culture: hard work, speed, over-delivery, and trust.\nCompetitive Compensation: Total OTE of $220,000-$300,000+.\n\nBase Salary: $120,000\nPerformance-Based Earnings: Realistically getting an extra $180,000 per year based on performance, and more (no cap).\n\n\n\n\nWork with a team that lives and breathes Amazon while having fun doing it.\n\n \nWho We’re Looking For:\nWe are seeking a Senior Amazon Brand Manager who deeply understands Amaz</td>
      <td>https://remotive.com/remote-jobs/marketing/senior-amazon-brand-manager-2082736</td>
    </tr>
    <tr>
      <td>Critical vulnerability in LangChain – CVE-2025-68664</td>
      <td>HackerNews</td>
      <td>2025-12-25</td>
      <td>Points: 131, Comments: 91</td>
      <td>https://cyata.ai/blog/langgrinch-langchain-core-cve-2025-68664/</td>
    </tr>
    <tr>
      <td>Asterisk AI Voice Agent</td>
      <td>HackerNews</td>
      <td>2025-12-24</td>
      <td>Points: 198, Comments: 119</td>
      <td>https://github.com/hkjarral/Asterisk-AI-Voice-Agent</td>
    </tr>
    <tr>
      <td>Senior Performance Marketer (Full Remote - Worldwide) at EverAI</td>
      <td>RemoteJob</td>
      <td>2025-12-21</td>
      <td>Our Vision &amp;amp; Products🚀 EverAI — Building the Future of AI CompanionshipOne of the Top 15 Largest &amp;amp; Fastest-Growing AI Companies in the World30+ Million Users in under 2 years — Help Us Reach 100M first, 500M nextAt EverAI, we’re shaping what it means to connect with AI. With 30+ million users and counting, we're not just building products — we're creating entirely new categories.Our flagship product is the world’s largest AI girlfriend/boyfriend platform, redefining relationships for mil</td>
      <td>https://remotive.com/remote-jobs/marketing/senior-performance-marketer-full-remote-worldwide-2080462</td>
    </tr>
    <tr>
      <td>Language teachers at AE Virtual Class S.A</td>
      <td>RemoteJob</td>
      <td>2025-12-21</td>
      <td>Description:\nAE Virtual Class, member of Academia Europea Group, leader in language teaching, with 56 years of experience and the largest teaching staff in the Americas! We are looking for language enthusiasts who want to be part of our great family! Experience is NOT a requirement! We teach you how to teach!\n \nJob Requirements:\nLaptop (with webcam).\nStable internet connection (15 Mbps).\nAttitude.\nDynamism.\nAfternoon and/or evening shifts (Central America time zone).\nExcellent Mandarin, German,</td>
      <td>https://remotive.com/remote-jobs/education/language-teachers-1987878</td>
    </tr>
    <tr>
      <td>Marionette: Local-first, private, voice-controlled AI browser automation agent</td>
      <td>HackerNews</td>
      <td>2025-12-20</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://github.com/youneslaaroussi/Marionette</td>
    </tr>
    <tr>
      <td>Chief Operating Officer at Shah &amp; Associates CPAs PA</td>
      <td>RemoteJob</td>
      <td>2025-12-19</td>
      <td>WANTED: One of the BEST Chief Operating Officer (A Player only)\n \nAt Shah &amp;amp; Associates CPAs PA, we don’t just prepare tax returns—we partner with clients year-round to deliver proactive tax planning strategies that create measurable savings and long-term wealth. Our mission is to elevate our clients’ financial position through collaborative advisory services designed to increase revenues, profits, and overall net worth.\nThis role exists because the firm is growing rapidly, and we need a seni</td>
      <td>https://remotive.com/remote-jobs/sales-business/chief-operating-officer-2088514</td>
    </tr>
    <tr>
      <td>The SafetyWing Digital Nomad Residency at SafetyWing</td>
      <td>RemoteJob</td>
      <td>2025-12-18</td>
      <td>The SafetyWing Digital Nomad ResidencyCalling all current and aspiring digital nomads: your dream opportunity is waiting! \nSafetyWing is funding one persons next global adventure with up to $4,000 in reimbursements to help you on your journey as a digital nomad.\nWhether you are a seasoned world explorer or someone who has always dreamt of far-off places, this could be your moment! The only requirement to apply is a deep desire to travel widely and live freely.Who is SafetyWing?\nSafetyWing envisi</td>
      <td>https://remotive.com/remote-jobs/all-others/the-safetywing-digital-nomad-residency-2088511</td>
    </tr>
    <tr>
      <td>Senior DevOps Engineer at Marketerx</td>
      <td>RemoteJob</td>
      <td>2025-12-18</td>
      <td>The Role: Architect of a Resilient Future\nWe are seeking a highly experienced and motivated Senior DevOps/Security Engineer to join our founding engineering team. This isn't just another DevOps role. You will be the architect of the resilient, scalable, and secure foundation upon which our entire autonomous marketing platform is built. As the first dedicated DevOps/Security hire, you will have a unique opportunity to shape our infrastructure from the ground up, ensuring our platform can deliver</td>
      <td>https://remotive.com/remote-jobs/devops/senior-devops-engineer-2070150</td>
    </tr>
    <tr>
      <td>Show HN: TheAuditor v2.0 – A “Flight Computer” for AI Coding Agents</td>
      <td>HackerNews</td>
      <td>2025-12-16</td>
      <td>I’m a former Systems Architect (Cisco&amp;#x2F;VMware) turned builder in Thailand. TheAuditor v2.0 is a complete architectural rewrite (800+ commits) of the prototype I posted three months ago.&lt;p&gt;The &amp;quot;A-ha&amp;quot; moment for me didn&amp;#x27;t come from a success; it came from a massive failure. I was trying to use AI to refactor a complex schema change (a foundation change from &amp;quot;Products&amp;quot; to &amp;quot;ProductsVariants&amp;quot;), and due to the scope of it, it failed spectacularly. I realized two</td>
      <td>https://github.com/TheAuditorTool/Auditor</td>
    </tr>
    <tr>
      <td>Ask HN: AI agents look great in demos, but how are people using it?</td>
      <td>HackerNews</td>
      <td>2025-12-15</td>
      <td>I lead digital and brand at a major CPG company, and we recently used agentic automation across a product launch. Not for experiments or prototypes, but for actual consume facing products.  \nWe had agents helping with:&lt;p&gt;- Content gen + localization\n- Asset routing between design, legal, and marketing\n- SKU variant handling across channels\n- Post launch updates when claims or packaging changed&lt;p&gt;We tested a mix of tools and approaches. Some general purpose agentic frameworks (Auto GPT style setu</td>
      <td>https://news.ycombinator.com/item?id=46275319</td>
    </tr>
    <tr>
      <td>AI agents are starting to eat SaaS</td>
      <td>HackerNews</td>
      <td>2025-12-14</td>
      <td>Points: 412, Comments: 386</td>
      <td>https://martinalderson.com/posts/ai-agents-are-starting-to-eat-saas/</td>
    </tr>
    <tr>
      <td>Lightpanda: the headless browser designed for AI and automation</td>
      <td>HackerNews</td>
      <td>2025-12-11</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://lightpanda.io</td>
    </tr>
    <tr>
      <td>Launch HN: InspectMind (YC W24) – AI agent for reviewing construction drawings</td>
      <td>HackerNews</td>
      <td>2025-12-10</td>
      <td>Hi HN, we&amp;#x27;re Aakash and Shuangling of InspectMind (&lt;a href="https:&amp;#x2F;&amp;#x2F;www.inspectmind.ai&amp;#x2F;"&gt;https:&amp;#x2F;&amp;#x2F;www.inspectmind.ai&amp;#x2F;&lt;/a&gt;), an AI “plan checker” that finds issues in construction drawings, details, and specs.&lt;p&gt;Construction drawings quietly go out with lots of errors: dimension conflicts, co-ordination gaps, material mismatches,  missing details and more. These errors turn into delays and hundreds of thousands of dollars of rework during construction. InspectMin</td>
      <td>https://news.ycombinator.com/item?id=46219386</td>
    </tr>
    <tr>
      <td>Resh v0.7 – AI-Native Automation Shell (25/30 Handles Complete)</td>
      <td>HackerNews</td>
      <td>2025-12-09</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://github.com/millertechnologygroup/resh</td>
    </tr>
    <tr>
      <td>Amorce – Universal Trust Protocol for AI Agents</td>
      <td>HackerNews</td>
      <td>2025-12-09</td>
      <td>TL;DR: Built a cryptographic trust protocol for AI agents. Think HTTPS for agent communication—Ed25519 signatures, human-in-the-loop approvals, and a searchable agent directory.&lt;p&gt;BLOG POST : https:&amp;#x2F;&amp;#x2F;amorce.io&amp;#x2F;blog&amp;#x2F;announcements&amp;#x2F;introducing-amorce&lt;p&gt;THE PROBLEM&lt;p&gt;AI agents are proliferating, but there&amp;#x27;s no standard way to verify an agent&amp;#x27;s identity, ensure communications weren&amp;#x27;t tampered with, require human approval for critical actions, or discover legiti</td>
      <td>https://news.ycombinator.com/item?id=46200568</td>
    </tr>
    <tr>
      <td>Lawyers are uniquely well-placed to resist AI job automation</td>
      <td>HackerNews</td>
      <td>2025-12-08</td>
      <td>Points: 3, Comments: 4</td>
      <td>https://boydkane.com/essays/2025nov#lawyers-are-uniquely-well-placed-to-resist-ai-job-automation-29-november-2025</td>
    </tr>
    <tr>
      <td>We Built an AI-Agent to Debug 1000s of Databases – and Cut Incident Time by 90%</td>
      <td>HackerNews</td>
      <td>2025-12-03</td>
      <td>Points: 50, Comments: 0</td>
      <td>https://www.databricks.com/blog/how-we-debug-1000s-databases-ai-databricks</td>
    </tr>
    <tr>
      <td>AI agents find $4.6M in blockchain smart contract exploits</td>
      <td>HackerNews</td>
      <td>2025-12-01</td>
      <td>Points: 215, Comments: 121</td>
      <td>https://red.anthropic.com/2025/smart-contracts/</td>
    </tr>
    <tr>
      <td>So you wanna build a local RAG?</td>
      <td>HackerNews</td>
      <td>2025-11-28</td>
      <td>Points: 390, Comments: 105</td>
      <td>https://blog.yakkomajuri.com/blog/local-rag</td>
    </tr>
    <tr>
      <td>One-fifth of the jobs at your company could disappear as AI automation takes off</td>
      <td>HackerNews</td>
      <td>2025-11-28</td>
      <td>Points: 9, Comments: 3</td>
      <td>https://www.theregister.com/2025/11/27/ai_employee_overcapacity_report/</td>
    </tr>
    <tr>
      <td>AI agents break rules under everyday pressure</td>
      <td>HackerNews</td>
      <td>2025-11-27</td>
      <td>Points: 279, Comments: 169</td>
      <td>https://spectrum.ieee.org/ai-agents-safety</td>
    </tr>
    <tr>
      <td>Show HN: Era – Open-source local sandbox for AI agents</td>
      <td>HackerNews</td>
      <td>2025-11-27</td>
      <td>Just watched this video by ThePrimeagen (&lt;a href="https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=efwDZw7l2Nk" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=efwDZw7l2Nk&lt;/a&gt;) about attackers jailbreaking Claude to run cyber attacks. The core issue: AI agents need isolation.&lt;p&gt;We built ERA to fix this – local microVM-based sandboxing for AI-generated code with hardware-level security. Think containers, but safer. Such attacks wouldn&amp;#x27;t touch your host if running in ERA.&lt;p&gt;GitHub</td>
      <td>https://github.com/BinSquare/ERA</td>
    </tr>
    <tr>
      <td>PUNKU.AI Generative automation that outputs editable node graphs</td>
      <td>HackerNews</td>
      <td>2025-11-25</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://www.punku.ai</td>
    </tr>
    <tr>
      <td>An Economy of AI Agents</td>
      <td>HackerNews</td>
      <td>2025-11-23</td>
      <td>Points: 141, Comments: 97</td>
      <td>https://arxiv.org/abs/2509.01063</td>
    </tr>
    <tr>
      <td>Show HN: I built a wizard to turn ideas into AI coding agent-ready specs</td>
      <td>HackerNews</td>
      <td>2025-11-22</td>
      <td>I created vibescaffold.dev. It is a wizard-style AI tool that will guide you from idea → vision → tech spec → implementation plan. It will generate all the documents necessary for AI coding agents to understand &amp;amp; iteratively execute on your vision.&lt;p&gt;How it works:\n- Step 1: Define your product vision and MVP\n- Step 2: AI helps create technical architecture and data models  \n- Step 3: Generate a staged development plan\n- Step 4: Create an AGENTS.md for automated workflows&lt;p&gt;I&amp;#x27;ve used AI</td>
      <td>https://vibescaffold.dev/</td>
    </tr>
    <tr>
      <td>Windows 11 adds AI agent that runs in background with access to personal folders</td>
      <td>HackerNews</td>
      <td>2025-11-17</td>
      <td>Points: 703, Comments: 638</td>
      <td>https://www.windowslatest.com/2025/11/18/windows-11-to-add-an-ai-agent-that-runs-in-background-with-access-to-personal-folders-warns-of-security-risk/</td>
    </tr>
    <tr>
      <td>My Morning Routine as an AI Automation Agency Owner</td>
      <td>HackerNews</td>
      <td>2025-11-13</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://philliphhughes.substack.com/p/my-morning-routine-as-an-ai-automation</td>
    </tr>
    <tr>
      <td>Adk-go: code-first Go toolkit for building, evaluating, and deploying AI agents</td>
      <td>HackerNews</td>
      <td>2025-11-11</td>
      <td>Points: 86, Comments: 24</td>
      <td>https://github.com/google/adk-go</td>
    </tr>
    <tr>
      <td>Benchmarking leading AI agents against Google reCAPTCHA v2</td>
      <td>HackerNews</td>
      <td>2025-11-10</td>
      <td>Points: 124, Comments: 97</td>
      <td>https://research.roundtable.ai/captcha-benchmarking/</td>
    </tr>
    <tr>
      <td>Streaming AI agent desktops with gaming protocols</td>
      <td>HackerNews</td>
      <td>2025-11-05</td>
      <td>Points: 83, Comments: 51</td>
      <td>https://blog.helix.ml/p/technical-deep-dive-on-streaming</td>
    </tr>
    <tr>
      <td>Lessons from interviews on deploying AI Agents in production</td>
      <td>HackerNews</td>
      <td>2025-11-04</td>
      <td>Points: 107, Comments: 92</td>
      <td>https://mmc.vc/research/state-of-agentic-ai-founders-edition/</td>
    </tr>
    <tr>
      <td>Amazon Demands Perplexity Stop AI Agent from Making Purchases</td>
      <td>HackerNews</td>
      <td>2025-11-04</td>
      <td>Points: 98, Comments: 71</td>
      <td>https://www.bloomberg.com/news/articles/2025-11-04/amazon-demands-perplexity-stop-ai-agent-from-making-purchases</td>
    </tr>
    <tr>
      <td>Show HN: LayoffKit – Free visa-aware planner for laid-off workers(AI+automation)</td>
      <td>HackerNews</td>
      <td>2025-11-03</td>
      <td>Quite many of my colleagues have been impacted with recent wave of tech layoffs (and I am not sure about my future as well - waiting for the news). The shock that people experience after hearing this news often paralyzes them and they do not know where to go and what to do. At the same time, the number of tasks one has to handle urgently (especially those who are on visa) is tremendous. To help people to deal with that, I have built a planner app with AI Copilot that can address questions + some</td>
      <td>https://layoffkit.com</td>
    </tr>
    <tr>
      <td>Syllabi – Open-source agentic AI with tools, RAG, and multi-channel deploy</td>
      <td>HackerNews</td>
      <td>2025-11-03</td>
      <td>Points: 89, Comments: 19</td>
      <td>https://www.syllabi-ai.com/</td>
    </tr>
    <tr>
      <td>Gilded Rage – Why Silicon Valley went from libertarian to authoritarian</td>
      <td>HackerNews</td>
      <td>2025-11-01</td>
      <td>Points: 86, Comments: 85</td>
      <td>https://paulkrugman.substack.com/p/gilded-rage-talking-with-jacob-silverman</td>
    </tr>
    <tr>
      <td>Remote Labor Index: Measuring AI Automation of Remote Work</td>
      <td>HackerNews</td>
      <td>2025-11-01</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://arxiv.org/abs/2510.26787</td>
    </tr>
    <tr>
      <td>Show HN: AI Prompt Automation Extension for ChatGPT, Gemini, Claude, AI Studio</td>
      <td>HackerNews</td>
      <td>2025-10-30</td>
      <td>We just released our Prompt Station extension for AI chatbot automation.&lt;p&gt;&lt;a href="https:&amp;#x2F;&amp;#x2F;winbuzzer.com&amp;#x2F;2025&amp;#x2F;10&amp;#x2F;21&amp;#x2F;release-prompt-station-brings-prompt-management-and-automation-to-the-next-level-xcxwbn" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;winbuzzer.com&amp;#x2F;2025&amp;#x2F;10&amp;#x2F;21&amp;#x2F;release-prompt-station-brin...&lt;/a&gt;&lt;p&gt;It can handle very large libraries of prompts&amp;#x2F;chains&amp;#x2F;text snippets and offers automation of ChatGPT, Gemini, AI Studio, Claude, Grok, Mistr</td>
      <td>https://winbuzzer.com/2025/10/21/release-prompt-station-brings-prompt-management-and-automation-to-the-next-level-xcxwbn/</td>
    </tr>
    <tr>
      <td>Remote Labor Index: Measuring AI Automation of Remote Work</td>
      <td>HackerNews</td>
      <td>2025-10-29</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://www.remotelabor.ai</td>
    </tr>
    <tr>
      <td>Show HN: Dexto – Connect your AI Agents with real-world tools and data</td>
      <td>HackerNews</td>
      <td>2025-10-28</td>
      <td>Hi HN, we’re the team at Truffle AI (YC W25), and we’ve been working on Dexto (&lt;a href="https:&amp;#x2F;&amp;#x2F;www.dexto.ai&amp;#x2F;" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.dexto.ai&amp;#x2F;&lt;/a&gt;), a runtime and orchestration layer for AI Agents that lets you turn any app, service or tool into an AI assistant that can reason, think and act. Here&amp;#x27;s a video walkthrough - &lt;a href="https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=WJ1qbI6MU6g" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=WJ1qbI</td>
      <td>https://github.com/truffle-ai/dexto</td>
    </tr>
    <tr>
      <td>LangChain Hits $1.25B Valuation</td>
      <td>HackerNews</td>
      <td>2025-10-24</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://techcrunch.com/2025/10/21/open-source-agentic-startup-langchain-hits-1-25b-valuation/</td>
    </tr>
    <tr>
      <td>State of AI Automation Platforms 2025</td>
      <td>HackerNews</td>
      <td>2025-10-23</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://substack.com/home/post/p-176665743</td>
    </tr>
    <tr>
      <td>At Google, the future is multiarch; AI and automation are helping us get there</td>
      <td>HackerNews</td>
      <td>2025-10-22</td>
      <td>Points: 2, Comments: 1</td>
      <td>https://cloud.google.com/blog/topics/systems/using-ai-and-automation-to-migrate-between-instruction-sets</td>
    </tr>
    <tr>
      <td>Open source agentic startup LangChain hits $1.25B valuation</td>
      <td>HackerNews</td>
      <td>2025-10-22</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://techcrunch.com/2025/10/21/open-source-agentic-startup-langchain-hits-1-25b-valuation/</td>
    </tr>
    <tr>
      <td>Using AI and automation to migrate between instruction sets</td>
      <td>HackerNews</td>
      <td>2025-10-21</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://cloud.google.com/blog/topics/systems/using-ai-and-automation-to-migrate-between-instruction-sets</td>
    </tr>
    <tr>
      <td>LangChain raises $125M to build the platform for agent engineering</td>
      <td>HackerNews</td>
      <td>2025-10-21</td>
      <td>Points: 12, Comments: 2</td>
      <td>https://blog.langchain.com/series-b/</td>
    </tr>
    <tr>
      <td>Reflections on Three Years of Building LangChain</td>
      <td>HackerNews</td>
      <td>2025-10-21</td>
      <td>Points: 5, Comments: 0</td>
      <td>https://blog.langchain.com/three-years-langchain/</td>
    </tr>
    <tr>
      <td>Production RAG: what I learned from processing 5M+ documents</td>
      <td>HackerNews</td>
      <td>2025-10-20</td>
      <td>Points: 551, Comments: 114</td>
      <td>https://blog.abdellatif.io/production-rag-processing-5m-documents</td>
    </tr>
    <tr>
      <td>Show HN: Pyversity – Fast Result Diversification for Retrieval and RAG</td>
      <td>HackerNews</td>
      <td>2025-10-19</td>
      <td>Hey HN! I’ve recently open-sourced Pyversity, a lightweight library for diversifying retrieval results. Most retrieval systems optimize only for relevance, which can lead to top-k results that look almost identical. Pyversity efficiently re-ranks results to balance relevance and diversity, surfacing items that remain relevant but are less redundant. This helps with improving retrieval, recommendation, and RAG pipelines without adding latency or complexity.&lt;p&gt;Main features:&lt;p&gt;- Unified API: one f</td>
      <td>https://github.com/Pringled/pyversity</td>
    </tr>
    <tr>
      <td>AI Automation Society</td>
      <td>HackerNews</td>
      <td>2025-10-15</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://www.skool.com/ai-automation-society/about</td>
    </tr>
    <tr>
      <td>Meta Superintelligence Labs' first paper is about RAG</td>
      <td>HackerNews</td>
      <td>2025-10-11</td>
      <td>&lt;a href="https:&amp;#x2F;&amp;#x2F;arxiv.org&amp;#x2F;abs&amp;#x2F;2509.01092" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;arxiv.org&amp;#x2F;abs&amp;#x2F;2509.01092&lt;/a&gt;</td>
      <td>https://paddedinputs.substack.com/p/meta-superintelligences-surprising</td>
    </tr>
    <tr>
      <td>Legal Contracts Built for AI Agents</td>
      <td>HackerNews</td>
      <td>2025-10-08</td>
      <td>Points: 72, Comments: 45</td>
      <td>https://paid.ai/blog/ai-agents/paid-gitlaw-introducing-legal-contracts-built-for-ai-agents</td>
    </tr>
    <tr>
      <td>CodeMender: an AI agent for code security</td>
      <td>HackerNews</td>
      <td>2025-10-06</td>
      <td>Points: 199, Comments: 29</td>
      <td>https://deepmind.google/discover/blog/introducing-codemender-an-ai-agent-for-code-security/</td>
    </tr>
    <tr>
      <td>We Gave Our AI Agents Twitter and Now They're Demanding Lambos</td>
      <td>HackerNews</td>
      <td>2025-10-03</td>
      <td>Points: 48, Comments: 4</td>
      <td>https://harper.blog/2025/09/30/ai-agents-social-media-performance-lambo-doomscrolling/</td>
    </tr>
    <tr>
      <td>Relay.app: Using AI to Build (AI) Automations</td>
      <td>HackerNews</td>
      <td>2025-10-02</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://www.relay.app/</td>
    </tr>
    <tr>
      <td>What makes 5% of AI agents work in production?</td>
      <td>HackerNews</td>
      <td>2025-10-02</td>
      <td>Points: 126, Comments: 121</td>
      <td>https://www.motivenotes.ai/p/what-makes-5-of-ai-agents-actually</td>
    </tr>
    <tr>
      <td>Show HN: A Standalone Android AI Automation Agent</td>
      <td>HackerNews</td>
      <td>2025-10-01</td>
      <td>Standalone Android AI Agent built with Flutter &amp;amp; Kotlin - Complete on-device automation, No computer needed after setup!</td>
      <td>https://github.com/iamvaar-dev/heybro</td>
    </tr>
    <tr>
      <td>The RAG Obituary: Killed by agents, buried by context windows</td>
      <td>HackerNews</td>
      <td>2025-10-01</td>
      <td>Points: 290, Comments: 179</td>
      <td>https://www.nicolasbustamante.com/p/the-rag-obituary-killed-by-agents</td>
    </tr>
    <tr>
      <td>AI-Driven Automation Can Become the Foundation of Next-Era Science of Science</td>
      <td>HackerNews</td>
      <td>2025-09-29</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://arxiv.org/abs/2505.12039</td>
    </tr>
    <tr>
      <td>Sandboxing AI agents at the kernel level</td>
      <td>HackerNews</td>
      <td>2025-09-29</td>
      <td>Points: 89, Comments: 26</td>
      <td>https://www.greptile.com/blog/sandboxing-agents-at-the-kernel-level</td>
    </tr>
    <tr>
      <td>Effective context engineering for AI agents</td>
      <td>HackerNews</td>
      <td>2025-09-29</td>
      <td>Points: 148, Comments: 32</td>
      <td>https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents</td>
    </tr>
    <tr>
      <td>Ebola outbreak in DR Congo rages, with 61% death rate and funding running dry</td>
      <td>HackerNews</td>
      <td>2025-09-27</td>
      <td>Points: 66, Comments: 99</td>
      <td>https://arstechnica.com/health/2025/09/ebola-outbreak-in-dr-congo-rages-with-61-death-rate-and-funding-running-dry/</td>
    </tr>
    <tr>
      <td>Gemini Robotics 1.5 brings AI agents into the physical world</td>
      <td>HackerNews</td>
      <td>2025-09-25</td>
      <td>Points: 69, Comments: 12</td>
      <td>https://deepmind.google/discover/blog/gemini-robotics-15-brings-ai-agents-into-the-physical-world/</td>
    </tr>
    <tr>
      <td>Context Engineering for AI Agents: Lessons</td>
      <td>HackerNews</td>
      <td>2025-09-23</td>
      <td>Points: 120, Comments: 4</td>
      <td>https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus</td>
    </tr>
    <tr>
      <td>Paper2Agent: Stanford Reimagining Research Papers as Interactive AI Agents</td>
      <td>HackerNews</td>
      <td>2025-09-22</td>
      <td>Points: 152, Comments: 44</td>
      <td>https://arxiv.org/abs/2509.06917</td>
    </tr>
    <tr>
      <td>If you are good at code review, you will be good at using AI agents</td>
      <td>HackerNews</td>
      <td>2025-09-20</td>
      <td>Points: 192, Comments: 197</td>
      <td>https://www.seangoedecke.com/ai-agents-and-code-review/</td>
    </tr>
    <tr>
      <td>Hidden risk in Notion 3.0 AI agents: Web search tool abuse for data exfiltration</td>
      <td>HackerNews</td>
      <td>2025-09-19</td>
      <td>Points: 183, Comments: 54</td>
      <td>https://www.codeintegrity.ai/blog/notion</td>
    </tr>
    <tr>
      <td>Launch HN: Ghostship (YC S25) – AI agents that find bugs in your web app</td>
      <td>HackerNews</td>
      <td>2025-09-11</td>
      <td>Hi HN, we&amp;#x27;re Jesse and Gautham. We&amp;#x27;re building Ghostship (&lt;a href="https:&amp;#x2F;&amp;#x2F;tryghostship.dev&amp;#x2F;"&gt;https:&amp;#x2F;&amp;#x2F;tryghostship.dev&amp;#x2F;&lt;/a&gt;).&lt;p&gt;Ghostship lets you find bugs in your web app by entering in your URL and describing a user journey.&lt;p&gt;Here&amp;#x27;s a video of Ghostship in action: &lt;a href="https:&amp;#x2F;&amp;#x2F;www.loom.com&amp;#x2F;share&amp;#x2F;dec264ae32f94d50adb141c9246837c3?sid=b3a6121e-1a6f-4428-8e5d-7a9bc502fcd2" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.loom.com&amp;#x2F;shar</td>
      <td>https://news.ycombinator.com/item?id=45215032</td>
    </tr>
    <tr>
      <td>Sandboxing Browser AI Agents</td>
      <td>HackerNews</td>
      <td>2025-09-11</td>
      <td>Points: 67, Comments: 7</td>
      <td>https://www.earlence.com/blog.html#/post/cellmate</td>
    </tr>
    <tr>
      <td>Ask HN: Is the market for AI Agent automations that big?</td>
      <td>HackerNews</td>
      <td>2025-09-11</td>
      <td>I&amp;#x27;ve seen hundreds of companies raise millions of dollar for automating things using AI, which probably don&amp;#x27;t need AI in the first place and could just be API calls. Is the market really that big for these solutions?</td>
      <td>https://news.ycombinator.com/item?id=45215150</td>
    </tr>
    <tr>
      <td>Windows-Use: an AI agent that interacts with Windows at GUI layer</td>
      <td>HackerNews</td>
      <td>2025-09-09</td>
      <td>Points: 135, Comments: 26</td>
      <td>https://github.com/CursorTouch/Windows-Use</td>
    </tr>
    <tr>
      <td>I don't want AI agents controlling my laptop</td>
      <td>HackerNews</td>
      <td>2025-09-09</td>
      <td>Points: 75, Comments: 40</td>
      <td>https://sophiebits.com/2025/09/09/ai-agents-security</td>
    </tr>
    <tr>
      <td>A PM's Guide to AI Agent Architecture</td>
      <td>HackerNews</td>
      <td>2025-09-04</td>
      <td>Points: 208, Comments: 62</td>
      <td>https://www.productcurious.com/p/a-pms-guide-to-ai-agent-architecture</td>
    </tr>
    <tr>
      <td>New AI Marketing Automation Platform</td>
      <td>HackerNews</td>
      <td>2025-09-03</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://heyoz.com</td>
    </tr>
    <tr>
      <td>Launch HN: Risely (YC S25) – AI Agents for Universities</td>
      <td>HackerNews</td>
      <td>2025-09-03</td>
      <td>Hi HN, I’m Danial, co-founder and CTO of Risely AI (&lt;a href="https:&amp;#x2F;&amp;#x2F;risely.ai"&gt;https:&amp;#x2F;&amp;#x2F;risely.ai&lt;/a&gt;). We&amp;#x27;re building AI agents that automate operational workflows inside universities. Here’s a demo: &lt;a href="https:&amp;#x2F;&amp;#x2F;www.loom.com&amp;#x2F;share&amp;#x2F;d7a14400434144c490249d665a0d0499?sid=8d36736e-6c87-43d3-992d-203c6edb0cf9" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.loom.com&amp;#x2F;share&amp;#x2F;d7a14400434144c490249d665a0d0499?...&lt;/a&gt;.&lt;p&gt;Higher ed is full of inefficiencies.</td>
      <td>https://news.ycombinator.com/item?id=45116859</td>
    </tr>
    <tr>
      <td>Parallel AI agents are a game changer</td>
      <td>HackerNews</td>
      <td>2025-09-02</td>
      <td>Points: 77, Comments: 81</td>
      <td>https://morningcoffee.io/parallel-ai-agents-are-a-game-changer.html</td>
    </tr>
    <tr>
      <td>Why JSON Prompts Are the Future of AI Automation</td>
      <td>HackerNews</td>
      <td>2025-08-28</td>
      <td>Points: 2, Comments: 1</td>
      <td>https://peerlist.io/teamcamp/articles/why-json-prompts-are-the-future-of-ai-automation</td>
    </tr>
    <tr>
      <td>Home Assistant and Ubiquiti and AI = Home Automation Magic</td>
      <td>HackerNews</td>
      <td>2025-08-27</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.troyhunt.com/home-assistant-ubiquiti-ai-home-automation-magic/</td>
    </tr>
    <tr>
      <td>Show HN: PageIndex – Vectorless RAG</td>
      <td>HackerNews</td>
      <td>2025-08-27</td>
      <td>Not all improvements come from adding complexity — sometimes it&amp;#x27;s about removing it.&lt;p&gt;PageIndex takes a different approach to RAG. Instead of relying on vector databases or artificial chunking, it builds a hierarchical tree structure from documents and uses reasoning-based tree search to locate the most relevant sections. This mirrors how humans approach reading: navigating through sections and context rather than matching embeddings.&lt;p&gt;As a result, the retrieval feels transparent, structu</td>
      <td>https://github.com/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb</td>
    </tr>
    <tr>
      <td>Agent-C: a 4KB AI agent</td>
      <td>HackerNews</td>
      <td>2025-08-25</td>
      <td>Points: 108, Comments: 85</td>
      <td>https://github.com/bravenewxyz/agent-c</td>
    </tr>
    <tr>
      <td>Launch HN: Inconvo (YC S23) – AI agents for customer-facing analytics</td>
      <td>HackerNews</td>
      <td>2025-08-22</td>
      <td>Hi HN, we are Liam and Eoghan of Inconvo (&lt;a href="https:&amp;#x2F;&amp;#x2F;inconvo.com"&gt;https:&amp;#x2F;&amp;#x2F;inconvo.com&lt;/a&gt;), a platform that makes it easy to build and deploy AI analytics agents into your SaaS products, so your customers can quickly interact with their data.&lt;p&gt;There’s a demo video at &lt;a href="https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=4wlZL3XGWTQ" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=4wlZL3XGWTQ&lt;/a&gt; and a live demo at &lt;a href="https:&amp;#x2F;&amp;#x2F;demo.inconvo</td>
      <td>https://news.ycombinator.com/item?id=44984096</td>
    </tr>
    <tr>
      <td>Qoder Quest Mode: Task Delegation to AI Agents</td>
      <td>HackerNews</td>
      <td>2025-08-22</td>
      <td>Points: 55, Comments: 5</td>
      <td>https://qoder.com/blog/quest-mode</td>
    </tr>
    <tr>
      <td>Lightpanda: Fast headless browser from scratch in Zig for AI and automation</td>
      <td>HackerNews</td>
      <td>2025-08-14</td>
      <td>Points: 5, Comments: 0</td>
      <td>https://lightpanda.io</td>
    </tr>
    <tr>
      <td>A Comprehensive Survey of Self-Evolving AI Agents [pdf]</td>
      <td>HackerNews</td>
      <td>2025-08-13</td>
      <td>Points: 94, Comments: 29</td>
      <td>https://arxiv.org/abs/2508.07407</td>
    </tr>
    <tr>
      <td>Navigating the Human Side of AI Automation</td>
      <td>HackerNews</td>
      <td>2025-08-12</td>
      <td>Points: 2, Comments: 1</td>
      <td>https://substack.com/inbox/post/170633287</td>
    </tr>
    <tr>
      <td>Guide to Implementing a GraphRAG Workflow with FalkorDB, LangChain and LangGraph</td>
      <td>HackerNews</td>
      <td>2025-08-10</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://www.falkordb.com/blog/graphrag-workflow-falkordb-langchain/</td>
    </tr>
    <tr>
      <td>Open SWE by LangChain</td>
      <td>HackerNews</td>
      <td>2025-08-08</td>
      <td>Points: 24, Comments: 12</td>
      <td>https://swe.langchain.com/</td>
    </tr>
    <tr>
      <td>Open SWE by LangChain (Docs)</td>
      <td>HackerNews</td>
      <td>2025-08-08</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://docs.langchain.com/labs/swe</td>
    </tr>
    <tr>
      <td>Show HN: Browser AI agent platform designed for reliability</td>
      <td>HackerNews</td>
      <td>2025-08-07</td>
      <td>We’re very excited to share something we’ve been building. Notte &lt;a href="https:&amp;#x2F;&amp;#x2F;www.notte.cc&amp;#x2F;"&gt;https:&amp;#x2F;&amp;#x2F;www.notte.cc&amp;#x2F;&lt;/a&gt; is a full-stack browser agent platform built to reliably automate a wide range of workflows.&lt;p&gt;Browser agents aren’t new, but what is still hard is covering real-world flows reliably. The inspiration for Notte was to make a full-featured platform that bridges the agent reliability gap.  We’ve packaged everything via a singe API for ease of use:&lt;</td>
      <td>https://github.com/nottelabs/notte</td>
    </tr>
    <tr>
      <td>My current guess at AI automation effect on jobs</td>
      <td>HackerNews</td>
      <td>2025-08-04</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://sortega.substack.com/p/my-current-guess-at-ai-automation</td>
    </tr>
    <tr>
      <td>AI Automation Tools: The Future of Web Development</td>
      <td>HackerNews</td>
      <td>2025-08-03</td>
      <td>Points: 1, Comments: 2</td>
      <td>https://github.com/topics/ai-automation</td>
    </tr>
    <tr>
      <td>Ask HN: Best AI Automation Platform</td>
      <td>HackerNews</td>
      <td>2025-08-01</td>
      <td>I&amp;#x27;m holding AI First Workshops for Small to Mid-Sizes Companies. For lots of them the real value of AI comes with automation. Mostly Email -&amp;gt; AI -&amp;gt; Action&lt;p&gt;Thing is Make, Zapier, n8n - whenever I use them we waste more money on clicking around and what goes where then focusing on the overall business logic. The automation part of the workshop is about 2 to 3h. So what solutions out there for trigger based automation that os truly AI first (so an internal AI oder chatgpt can really cr</td>
      <td>https://news.ycombinator.com/item?id=44761947</td>
    </tr>
    <tr>
      <td>Show HN: AgentGuard – Auto-kill AI agents before they burn through your budget</td>
      <td>HackerNews</td>
      <td>2025-07-31</td>
      <td>Your AI agent hits an infinite loop and racks up $2000 in API charges overnight. This happens weekly to AI developers.&lt;p&gt;AgentGuard monitors API calls in real-time and automatically kills your process when it hits your budget limit.&lt;p&gt;How it works:&lt;p&gt;Add 2 lines to any AI project:&lt;p&gt;&lt;pre&gt;&lt;code&gt;  const agentGuard = require(&amp;#x27;agent-guard&amp;#x27;);\n  await agentGuard.init({ limit: 50 }); &amp;#x2F;&amp;#x2F; $50 budget\n\n  &amp;#x2F;&amp;#x2F; Your existing code runs unchanged\n  const response = await openai.chat</td>
      <td>https://github.com/dipampaul17/AgentGuard</td>
    </tr>
    <tr>
      <td>Show HN: AgentMail – Email infra for AI agents</td>
      <td>HackerNews</td>
      <td>2025-07-31</td>
      <td>Hey HN, we&amp;#x27;re Haakam, Michael, and Adi. We&amp;#x27;re building AgentMail (&lt;a href="https:&amp;#x2F;&amp;#x2F;agentmail.to&amp;#x2F;"&gt;https:&amp;#x2F;&amp;#x2F;agentmail.to&amp;#x2F;&lt;/a&gt;), an API to give AI agents their own email inboxes. We’re not talking about AI for your email, this is email for your AI.&lt;p&gt;We started building email agents because they can converse with users in their inboxes, automate email-based workflows, and authenticate with third-party applications. Given these unique capabilities, we think em</td>
      <td>https://chat.agentmail.to/</td>
    </tr>
    <tr>
      <td>The Silent Revolution Is in AI Automation, Not Conversation</td>
      <td>HackerNews</td>
      <td>2025-07-31</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://www.theflock.com/en/content/blog-and-ebook/the-silent-revolution-agentic-ai</td>
    </tr>
    <tr>
      <td>Gemini Embedding: Powering RAG and context engineering</td>
      <td>HackerNews</td>
      <td>2025-07-31</td>
      <td>Points: 278, Comments: 92</td>
      <td>https://developers.googleblog.com/en/gemini-embedding-powering-rag-context-engineering/</td>
    </tr>
    <tr>
      <td>Launch HN: Lucidic (YC W25) – Debug, test, and evaluate AI agents in production</td>
      <td>HackerNews</td>
      <td>2025-07-30</td>
      <td>Hi HN, we’re Abhinav, Andy, and Jeremy, and we’re building Lucidic AI (&lt;a href="https:&amp;#x2F;&amp;#x2F;dashboard.lucidic.ai"&gt;https:&amp;#x2F;&amp;#x2F;dashboard.lucidic.ai&lt;/a&gt;), an AI agent interpretability tool to help observe&amp;#x2F;debug AI agents.&lt;p&gt;Here is a demo: &lt;a href="https:&amp;#x2F;&amp;#x2F;youtu.be&amp;#x2F;Zvoh1QUMhXQ" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;youtu.be&amp;#x2F;Zvoh1QUMhXQ&lt;/a&gt;.&lt;p&gt;Getting started is easy with just one line of code. You just call lai.init() in your agent code and log into the dashboard. Y</td>
      <td>https://news.ycombinator.com/item?id=44735843</td>
    </tr>
    <tr>
      <td>Show HN: An AI agent that learns your product and guides your users</td>
      <td>HackerNews</td>
      <td>2025-07-30</td>
      <td>Hey HN! My name is Christian, and I’m the co-founder of &lt;a href="https:&amp;#x2F;&amp;#x2F;frigade.ai"&gt;https:&amp;#x2F;&amp;#x2F;frigade.ai&lt;/a&gt;. We’ve built an AI agent that automatically learns how to use any web-based product, and in turn guides users directly in the UI, automatically generates documentation, and even takes actions on a user’s behalf. Think of it as Clippy from the old MS Office. But on steroids. And actually helpful.&lt;p&gt;You can see the agent and tool-calling SDK in action here: &lt;a href="https</td>
      <td>https://frigade.ai</td>
    </tr>
    <tr>
      <td>Build an AI telephony agent for inbound and outbound calls</td>
      <td>HackerNews</td>
      <td>2025-07-30</td>
      <td>Points: 66, Comments: 48</td>
      <td>https://github.com/videosdk-community/ai-telephony-demo</td>
    </tr>
    <tr>
      <td>Crush: Glamourous AI coding agent for your favourite terminal</td>
      <td>HackerNews</td>
      <td>2025-07-30</td>
      <td>Points: 367, Comments: 235</td>
      <td>https://github.com/charmbracelet/crush</td>
    </tr>
    <tr>
      <td>Principles for production AI agents</td>
      <td>HackerNews</td>
      <td>2025-07-28</td>
      <td>Points: 128, Comments: 19</td>
      <td>https://www.app.build/blog/six-principles-production-ai-agents</td>
    </tr>
    <tr>
      <td>AI coding agents are removing programming language barriers</td>
      <td>HackerNews</td>
      <td>2025-07-23</td>
      <td>Points: 148, Comments: 176</td>
      <td>https://railsatscale.com/2025-07-19-ai-coding-agents-are-removing-programming-language-barriers/</td>
    </tr>
    <tr>
      <td>Replit's CEO apologizes after its AI agent wiped a company's code base</td>
      <td>HackerNews</td>
      <td>2025-07-22</td>
      <td>Points: 179, Comments: 160</td>
      <td>https://www.businessinsider.com/replit-ceo-apologizes-ai-coding-tool-delete-company-database-2025-7</td>
    </tr>
    <tr>
      <td>Don't bother parsing: Just use images for RAG</td>
      <td>HackerNews</td>
      <td>2025-07-21</td>
      <td>Points: 328, Comments: 72</td>
      <td>https://www.morphik.ai/blog/stop-parsing-docs</td>
    </tr>
    <tr>
      <td>Local Chatbot RAG with FreeBSD Knowledge</td>
      <td>HackerNews</td>
      <td>2025-07-13</td>
      <td>Points: 98, Comments: 9</td>
      <td>https://hackacad.net/post/2025-07-12-local-chatbot-rag-with-freebsd-knowledge/</td>
    </tr>
    <tr>
      <td>Amazon CEO says AI agents will soon reduce company's corporate workforce</td>
      <td>HackerNews</td>
      <td>2025-07-13</td>
      <td>Points: 85, Comments: 120</td>
      <td>https://www.cbsnews.com/news/amazon-ceo-generative-ai-corporate-workforce/</td>
    </tr>
    <tr>
      <td>Show HN: BorgLLM, Zero-config LangChain Client, key rotation and rate limit mgmt</td>
      <td>HackerNews</td>
      <td>2025-07-12</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://borgllm.com</td>
    </tr>
    <tr>
      <td>Show HN: Vibe Kanban – Kanban board to manage your AI coding agents</td>
      <td>HackerNews</td>
      <td>2025-07-11</td>
      <td>Hey HN! I&amp;#x27;m Louis, one of the creators of Vibe Kanban.&lt;p&gt;We started working on this a few weeks ago. Personally, I was feeling pretty useless working synchronously with coding agents. The 2-5 minutes that they take to complete their work often led me to distraction and doomscrolling.&lt;p&gt;But there&amp;#x27;s plenty of productive work that we (human engineers) could be doing in that time, especially if we run coding agents in the background and parallelise them.&lt;p&gt;Vibe Kanban lets you effortlessly</td>
      <td>https://github.com/BloopAI/vibe-kanban</td>
    </tr>
    <tr>
      <td>AI agent benchmarks are broken</td>
      <td>HackerNews</td>
      <td>2025-07-11</td>
      <td>Points: 185, Comments: 86</td>
      <td>https://ddkang.substack.com/p/ai-agent-benchmarks-are-broken</td>
    </tr>
    <tr>
      <td>At last, a use case for AI agents with sky-high ROI: Stealing crypto</td>
      <td>HackerNews</td>
      <td>2025-07-10</td>
      <td>Points: 97, Comments: 36</td>
      <td>https://www.theregister.com/2025/07/10/ai_agents_automatically_steal_cryptocurrency/</td>
    </tr>
    <tr>
      <td>LangChain is about to become a unicorn, sources say</td>
      <td>HackerNews</td>
      <td>2025-07-09</td>
      <td>Points: 5, Comments: 0</td>
      <td>https://techcrunch.com/2025/07/08/langchain-is-about-to-become-a-unicorn-sources-say/</td>
    </tr>
    <tr>
      <td>LangChain is about to become a unicorn</td>
      <td>HackerNews</td>
      <td>2025-07-09</td>
      <td>Points: 5, Comments: 0</td>
      <td>https://techcrunch.com/2025/07/08/langchain-is-about-to-become-a-unicorn-sources-say/</td>
    </tr>
    <tr>
      <td>MCP-B: A Protocol for AI Browser Automation</td>
      <td>HackerNews</td>
      <td>2025-07-09</td>
      <td>Points: 336, Comments: 184</td>
      <td>https://mcp-b.ai/</td>
    </tr>
    <tr>
      <td>Biomni: A General-Purpose Biomedical AI Agent</td>
      <td>HackerNews</td>
      <td>2025-07-09</td>
      <td>Points: 222, Comments: 37</td>
      <td>https://github.com/snap-stanford/Biomni</td>
    </tr>
    <tr>
      <td>Opencode: AI coding agent, built for the terminal</td>
      <td>HackerNews</td>
      <td>2025-07-06</td>
      <td>Points: 319, Comments: 91</td>
      <td>https://github.com/sst/opencode</td>
    </tr>
    <tr>
      <td>WASM Agents: AI agents running in the browser</td>
      <td>HackerNews</td>
      <td>2025-07-04</td>
      <td>Points: 169, Comments: 44</td>
      <td>https://blog.mozilla.ai/wasm-agents-ai-agents-running-in-your-browser/</td>
    </tr>
    <tr>
      <td>What to build instead of AI agents</td>
      <td>HackerNews</td>
      <td>2025-07-03</td>
      <td>Points: 239, Comments: 119</td>
      <td>https://decodingml.substack.com/p/stop-building-ai-agents</td>
    </tr>
    <tr>
      <td>AI agents get office tasks wrong around 70% of time, and many aren't AI at all</td>
      <td>HackerNews</td>
      <td>2025-06-29</td>
      <td>Points: 43, Comments: 23</td>
      <td>https://www.theregister.com/2025/06/29/ai_agents_fail_a_lot/</td>
    </tr>
    <tr>
      <td>Ask HN: What's the Best AI Browser Automation Solution?</td>
      <td>HackerNews</td>
      <td>2025-06-27</td>
      <td>I&amp;#x27;m looking for a browser automation solution that is:&lt;p&gt;- driven by natural language\n- uses best models (ideally Claude 4 or Gemini 2.5 class)\n- doesn&amp;#x27;t refuse&lt;p&gt;Here&amp;#x27;s my gripes with a few existing solutions:&lt;p&gt;===\nMANUS\n===&lt;p&gt;Pretty much fails every task. Pricing is now ridiculous.&lt;p&gt;===\nOPENAI OPERATOR\n===&lt;p&gt;Asks permission for everything, begging the question &amp;quot;why don&amp;#x27;t I just do this by hand&amp;quot;&lt;p&gt;Please consider in your comment - I&amp;#x27;m not interested in a deb</td>
      <td>https://news.ycombinator.com/item?id=44397833</td>
    </tr>
    <tr>
      <td>LangChain vs. Langfuse: Key Differences and Their Role in LLM App Development</td>
      <td>HackerNews</td>
      <td>2025-06-27</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://www.wizardlabs.com/insights/langchain-langfuse-llm-tools/</td>
    </tr>
    <tr>
      <td>N8n Template Kit – 175 ready-to-use AI automations</td>
      <td>HackerNews</td>
      <td>2025-06-27</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://n8ntemplates.vercel.app/</td>
    </tr>
    <tr>
      <td>How AI automations work? [video]</td>
      <td>HackerNews</td>
      <td>2025-06-27</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.youtube.com/watch?v=tLMRagvYlWA</td>
    </tr>
    <tr>
      <td>Show HN: Magnitude – Open-source AI browser automation framework</td>
      <td>HackerNews</td>
      <td>2025-06-26</td>
      <td>Hey HN, Anders and Tom here. We had a post about our AI test automation framework 2 months ago that got a decent amount of traction (&lt;a href="https:&amp;#x2F;&amp;#x2F;news.ycombinator.com&amp;#x2F;item?id=43796003"&gt;https:&amp;#x2F;&amp;#x2F;news.ycombinator.com&amp;#x2F;item?id=43796003&lt;/a&gt;).&lt;p&gt;We got some great feedback from the community, with the most positive response being about our vision-first approach used in our browser agent. However, many wanted to use the underlying agent outside the testing domain. So tod</td>
      <td>https://github.com/magnitudedev/magnitude</td>
    </tr>
    <tr>
      <td>Learnings from building AI agents</td>
      <td>HackerNews</td>
      <td>2025-06-26</td>
      <td>Points: 172, Comments: 63</td>
      <td>https://www.cubic.dev/blog/learnings-from-building-ai-agents</td>
    </tr>
    <tr>
      <td>Show HN: A "set-it-and-forget-it" AI automation for Apple Ads</td>
      <td>HackerNews</td>
      <td>2025-06-25</td>
      <td>Hi HN,&lt;p&gt;I’m Nick and this tool is inspired by my iOS dev experience with Apple Ads.\nThis is my attempt to make working with search results ads easier for iOS developers without the time or marketing knowledge to run them. AdCider researches and builds campaigns as well as monitors and applies ongoing optimizations to keywords and bids.&lt;p&gt;I&amp;#x27;ve focused entirely on making the automation useful and hands-off, so the UI is pretty simple.&lt;p&gt;I just launched my MVP today and would genuinely apprec</td>
      <td>https://adcider.com/</td>
    </tr>
    <tr>
      <td>Gemini CLI: your open-source AI agent</td>
      <td>HackerNews</td>
      <td>2025-06-25</td>
      <td>Points: 94, Comments: 43</td>
      <td>https://blog.google/technology/developers/introducing-gemini-cli/</td>
    </tr>
    <tr>
      <td>I built orKa-reasoning: a modular orchestration layer for explainable AI agents</td>
      <td>HackerNews</td>
      <td>2025-06-24</td>
      <td>I built OrKa: a modular orchestration layer for explainable AI agents&lt;p&gt;Hi HN,&lt;p&gt;I&amp;#x27;m Marco — ex-ethologist turned AI systems engineer — and I built something I needed but couldn&amp;#x27;t find:\nan open-source framework to wire *cognition like circuits* — not spaghetti prompt chains.&lt;p&gt;It&amp;#x27;s called *OrKa*: the *Orchestrator Kit for Agents*.&lt;p&gt;WHY I BUILT IT\n• Tired of black-box LLM chains (LangChain, AutoGPT, etc.)\n• Needed a way to fork&amp;#x2F;join reasoning paths\n• Wanted true traceability,</td>
      <td>https://news.ycombinator.com/item?id=44366591</td>
    </tr>
    <tr>
      <td>Structured Output with LangChain and Llamafile</td>
      <td>HackerNews</td>
      <td>2025-06-22</td>
      <td>Points: 46, Comments: 20</td>
      <td>https://blog.brakmic.com/structured-output-with-langchain-and-llamafile/</td>
    </tr>
    <tr>
      <td>Explosive Growth from AI Automation: A Review of the Arguments</td>
      <td>HackerNews</td>
      <td>2025-06-22</td>
      <td>Points: 3, Comments: 2</td>
      <td>https://arxiv.org/abs/2309.11690</td>
    </tr>
    <tr>
      <td>Show HN: Pickaxe – A TypeScript library for building AI agents</td>
      <td>HackerNews</td>
      <td>2025-06-20</td>
      <td>Hey HN, Gabe and Alexander here from Hatchet. Today we&amp;#x27;re releasing Pickaxe, a Typescript library to build AI agents which are scalable and fault-tolerant.&lt;p&gt;Here&amp;#x27;s a demo: &lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;user-attachments&amp;#x2F;assets&amp;#x2F;b28fc406-f501-4427-9574-e4c756b29dd4"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;user-attachments&amp;#x2F;assets&amp;#x2F;b28fc406-f501-442...&lt;/a&gt;&lt;p&gt;Pickaxe provides a simple set of primitives for building agents which can automatically checkpoint their st</td>
      <td>https://github.com/hatchet-dev/pickaxe</td>
    </tr>
    <tr>
      <td>From LLM to AI Agent: What's the Real Journey Behind AI System Development?</td>
      <td>HackerNews</td>
      <td>2025-06-19</td>
      <td>Points: 141, Comments: 44</td>
      <td>https://www.codelink.io/blog/post/ai-system-development-llm-rag-ai-workflow-agent</td>
    </tr>
    <tr>
      <td>OpenAPI Meets Qwen: AI-Powered API Docs with Quarkus, LangChain4j and Ollama</td>
      <td>HackerNews</td>
      <td>2025-06-18</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://myfear.substack.com/p/quarkus-openapi-ai-docs-langchain4j</td>
    </tr>
    <tr>
      <td>Is there a half-life for the success rates of AI agents?</td>
      <td>HackerNews</td>
      <td>2025-06-18</td>
      <td>Points: 249, Comments: 136</td>
      <td>https://www.tobyord.com/writing/half-life</td>
    </tr>
    <tr>
      <td>Building Effective AI Agents</td>
      <td>HackerNews</td>
      <td>2025-06-17</td>
      <td>Points: 543, Comments: 88</td>
      <td>https://www.anthropic.com/engineering/building-effective-agents</td>
    </tr>
    <tr>
      <td>I vibe-coded a $0.15/week AI marketing automation for social media</td>
      <td>HackerNews</td>
      <td>2025-06-16</td>
      <td>Hi HN,&lt;p&gt;I&amp;#x27;m a CTO-turned-solo-founder who got tired of seeing &amp;quot;vibe marketing&amp;quot; success stories (looking at you, Greg Isenberg) without the technical implementation details. So I spent 3 hours building and recording a complete marketing automation system.&lt;p&gt;*What it does:*\n- Claude AI analyzes your writing style and generates content\n- Runs through custom keyword optimization algo\n- Passes through humanizer algo for authentic voice\n- Node.js project pushes to Google Sheets for man</td>
      <td>https://news.ycombinator.com/item?id=44292640</td>
    </tr>
    <tr>
      <td>AI agent startups at Y Combinator’s Spring ’25 Demo Day</td>
      <td>HackerNews</td>
      <td>2025-06-14</td>
      <td>Points: 40, Comments: 40</td>
      <td>https://www.businessinsider.com/y-combinator-yc-demo-day-spring-ai-agent-startups-2025-6</td>
    </tr>
    <tr>
      <td>Show HN: LangChain and Tensorlake = Better Document RAG</td>
      <td>HackerNews</td>
      <td>2025-06-11</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://www.tensorlake.ai/blog/announcing-langchain-tensorlake-integration</td>
    </tr>
    <tr>
      <td>Turning Chrome into an AI-controlled automation tool</td>
      <td>HackerNews</td>
      <td>2025-06-10</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://github.com/hangwin/mcp-chrome</td>
    </tr>
    <tr>
      <td>Show HN: I built desktop AI Automation app with MCP Support</td>
      <td>HackerNews</td>
      <td>2025-06-10</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://heyalice.app/</td>
    </tr>
    <tr>
      <td>Launch HN: BitBoard (YC X25) – AI agents for healthcare back-offices</td>
      <td>HackerNews</td>
      <td>2025-06-10</td>
      <td>Hi HN! We’re Connor and Ambar, and we’re working on BitBoard (&lt;a href="https:&amp;#x2F;&amp;#x2F;bitboard.work"&gt;https:&amp;#x2F;&amp;#x2F;bitboard.work&lt;/a&gt;). We build AI agents that handle repetitive administrative tasks in healthcare clinics like filling out intake forms, prepping charts, or managing referrals.&lt;p&gt;We were early employees at Forward, which provided primary care across the US. To scale this, we relied on thousands of remote contractors to do repetitive administrative work like reconciling patient</td>
      <td>https://news.ycombinator.com/item?id=44237769</td>
    </tr>
    <tr>
      <td>Show HN: I made an open-source alternative to LangChain</td>
      <td>HackerNews</td>
      <td>2025-06-09</td>
      <td>Really appreciate any feedback! :)</td>
      <td>https://itz.am</td>
    </tr>
    <tr>
      <td>The Sky's the limit: AI automation on Mac</td>
      <td>HackerNews</td>
      <td>2025-06-04</td>
      <td>Points: 123, Comments: 71</td>
      <td>https://taoofmac.com/space/blog/2025/06/03/2155</td>
    </tr>
    <tr>
      <td>Show HN: App.build, an open-source AI agent that builds full-stack apps</td>
      <td>HackerNews</td>
      <td>2025-06-04</td>
      <td>Points: 90, Comments: 13</td>
      <td>https://www.app.build/</td>
    </tr>
    <tr>
      <td>Show HN: Tiptap AI Agent – Add AI workflows to your text editor in minutes</td>
      <td>HackerNews</td>
      <td>2025-06-04</td>
      <td>We built the Tiptap AI Agent to make it easy to integrate AI into a rich text editor, without rebuilding your entire frontend.&lt;p&gt;If you’ve ever tried wiring up AI inside a document editor, you’ve probably dealt with:&lt;p&gt;&lt;pre&gt;&lt;code&gt;  - Extracting context from complex document structures\n  - Handling prompt input + streamed output\n  - Supporting undo&amp;#x2F;redo for AI changes\n  - Designing UI for accepting&amp;#x2F;rejecting changes\n  - Multiplayer session state and conflicts\n&lt;/code&gt;&lt;/pre&gt;\nIt’s a lot of</td>
      <td>https://news.ycombinator.com/item?id=44177964</td>
    </tr>
    <tr>
      <td>Show HN: I built an AI Agent that uses the iPhone</td>
      <td>HackerNews</td>
      <td>2025-06-02</td>
      <td>It’s powered by OpenAI’s GPT 4.1 model.&lt;p&gt;Uses Xcode UI tests + accessibility tree to look into apps, and performs swipes, taps, etc to get things done.</td>
      <td>https://github.com/rounak/PhoneAgent</td>
    </tr>
    <tr>
      <td>From the Creators of Shortcuts, Sky Extends AI Automation to Your Entire Mac</td>
      <td>HackerNews</td>
      <td>2025-05-29</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.macstories.net/stories/sky-for-mac-preview/</td>
    </tr>
    <tr>
      <td>AutoGit-O-Matic: Your Git Sync Sidekick</td>
      <td>HackerNews</td>
      <td>2025-05-29</td>
      <td>Points: 2, Comments: 1</td>
      <td>https://github.com/FPGArtktic/AutoGit-o-Matic</td>
    </tr>
    <tr>
      <td>Launch HN: MindFort (YC X25) – AI agents for continuous pentesting</td>
      <td>HackerNews</td>
      <td>2025-05-28</td>
      <td>Hey HN! We&amp;#x27;re Brandon, Sam, and Akul from MindFort (&lt;a href="https:&amp;#x2F;&amp;#x2F;mindfort.ai"&gt;https:&amp;#x2F;&amp;#x2F;mindfort.ai&lt;/a&gt;). We&amp;#x27;re building autonomous AI agents that continuously find, validate, and patch security vulnerabilities in web applications—essentially creating an AI red team that runs 24&amp;#x2F;7.&lt;p&gt;Here&amp;#x27;s a demo: &lt;a href="https:&amp;#x2F;&amp;#x2F;www.loom.com&amp;#x2F;share&amp;#x2F;e56faa07d90b417db09bb4454dce8d5a" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.loom.com&amp;#x2F;share&amp;#x2F;e56faa</td>
      <td>https://news.ycombinator.com/item?id=44117465</td>
    </tr>
    <tr>
      <td>Designing Pareto-optimal RAG workflows with syftr</td>
      <td>HackerNews</td>
      <td>2025-05-28</td>
      <td>Points: 67, Comments: 13</td>
      <td>https://www.datarobot.com/blog/pareto-optimized-ai-workflows-syftr/</td>
    </tr>
    <tr>
      <td>From the Creators of Shortcuts, Sky Extends AI and Automation to Entire Your Mac</td>
      <td>HackerNews</td>
      <td>2025-05-28</td>
      <td>Points: 7, Comments: 2</td>
      <td>https://www.macstories.net/stories/sky-for-mac-preview/</td>
    </tr>
    <tr>
      <td>Show HN: Non-intrusive AI agent to automate email driven workflows</td>
      <td>HackerNews</td>
      <td>2025-05-27</td>
      <td>Hi HN! My co-founder and I spent the last 4 weeks building something we desperately needed ourselves.&lt;p&gt;The Problem: We spend hours processing emails - scheduling meetings, going through long newsletters, downloading attachments to review, verifying documents like invoices, and of course taking actions on external systems (Salesforce, Asana, Jira etc) based on emails received. A lot of this can be automated with the help of AI agents, saving several hours every week.&lt;p&gt;Our Solution: Forward any</td>
      <td>https://www.mxtoai.com/</td>
    </tr>
    <tr>
      <td>Ask HN: How to start selling my Restaurant AI automation software?</td>
      <td>HackerNews</td>
      <td>2025-05-23</td>
      <td>In today’s hyper competitive environment, traditional restaurant operations are no longer\n sustainable without digitization. A lack of integrated systems, limited digital marketing\n and zero automation result in operational inefficiencies and lost revenue opportunities.\n So i have built a complete end to end Automation package for Restaurant or Food business insdutry.&lt;p&gt;I am a tech person don&amp;#x27;t have any experience on sales what should be my ideal approach to kick start my sales process.&lt;p&gt;L</td>
      <td>https://news.ycombinator.com/item?id=44076072</td>
    </tr>
    <tr>
      <td>Microsoft AI Exec Accidentally Spills Walmart's AI Plans</td>
      <td>HackerNews</td>
      <td>2025-05-21</td>
      <td>Points: 3, Comments: 2</td>
      <td>https://autogpt.net/microsoft-ai-exec-accidentally-spills-walmarts-ai-plans-during-protest-rattled-talk/</td>
    </tr>
    <tr>
      <td>Show HN: I built a plain-English AI automation engine</td>
      <td>HackerNews</td>
      <td>2025-05-21</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://www.versionseven.ai</td>
    </tr>
    <tr>
      <td>If an AI agent can't figure out how your API works, neither can your users</td>
      <td>HackerNews</td>
      <td>2025-05-20</td>
      <td>Points: 97, Comments: 52</td>
      <td>https://stytch.com/blog/if-an-ai-agent-cant-figure-out-how-your-api-works-neither-can-your-users/</td>
    </tr>
    <tr>
      <td>On-Demand: AI Agent Automation</td>
      <td>HackerNews</td>
      <td>2025-05-16</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://on-demand.io/</td>
    </tr>
    <tr>
      <td>Walmart is preparing to welcome its next customer: the AI shopping agent</td>
      <td>HackerNews</td>
      <td>2025-05-15</td>
      <td>Points: 66, Comments: 70</td>
      <td>https://www.wsj.com/articles/walmart-is-preparing-to-welcome-its-next-customer-the-ai-shopping-agent-6659ef18</td>
    </tr>
    <tr>
      <td>Launch HN: Jazzberry (YC X25) – AI agent for finding bugs</td>
      <td>HackerNews</td>
      <td>2025-05-14</td>
      <td>Hey HN! We are building Jazzberry (&lt;a href="https:&amp;#x2F;&amp;#x2F;jazzberry.ai"&gt;https:&amp;#x2F;&amp;#x2F;jazzberry.ai&lt;/a&gt;), an AI bug finder that automatically tests your code when a pull request occurs to find and flag real bugs before they are merged.&lt;p&gt;Here’s a demo video: &lt;a href="https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=L6ZTu86qK8U#t=7" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=L6ZTu86qK8U#t=7&lt;/a&gt;&lt;p&gt;We are building Jazzberry to help you find bugs in your code base. Here’s how</td>
      <td>https://news.ycombinator.com/item?id=43985994</td>
    </tr>
    <tr>
      <td>Show HN: Muscle-Mem, a behavior cache for AI agents</td>
      <td>HackerNews</td>
      <td>2025-05-14</td>
      <td>Hi HN! Erik here from Pig.dev, and today I&amp;#x27;d like to share a new project we&amp;#x27;ve just open sourced:&lt;p&gt;Muscle Mem is an SDK that records your agent&amp;#x27;s tool-calling patterns as it solves tasks, and will deterministically replay those learned trajectories whenever the task is encountered again, falling back to agent mode if edge cases are detected. Like a JIT compiler, for behaviors.&lt;p&gt;At Pig, we built computer-use agents for automating legacy Windows applications (healthcare, lending,</td>
      <td>https://github.com/pig-dot-dev/muscle-mem</td>
    </tr>
    <tr>
      <td>AI Automation for Content Creation</td>
      <td>HackerNews</td>
      <td>2025-05-08</td>
      <td>Points: 2, Comments: 1</td>
      <td>https://youtu.be/r9MBM1ZiptU</td>
    </tr>
    <tr>
      <td>Rage of the Oligarchs Naomi Klein: 'What They Want Is Absolutely Everything</td>
      <td>HackerNews</td>
      <td>2025-05-07</td>
      <td>Points: 65, Comments: 19</td>
      <td>https://www.rollingstone.com/politics/politics-features/naomi-klein-trump-musk-thiel-oligarchs-climate-science-1235330780/</td>
    </tr>
    <tr>
      <td>A Survey of AI Agent Protocols</td>
      <td>HackerNews</td>
      <td>2025-05-04</td>
      <td>Points: 91, Comments: 63</td>
      <td>https://arxiv.org/abs/2504.16736</td>
    </tr>
    <tr>
      <td>N8n – Flexible AI workflow automation for technical teams</td>
      <td>HackerNews</td>
      <td>2025-05-03</td>
      <td>Points: 195, Comments: 99</td>
      <td>https://n8n.io/</td>
    </tr>
    <tr>
      <td>Show HN: Blast – Fast, multi-threaded serving engine for web browsing AI agents</td>
      <td>HackerNews</td>
      <td>2025-05-02</td>
      <td>Hi HN!&lt;p&gt;BLAST is a high-performance serving engine for browser-augmented LLMs, designed to make deploying web-browsing AI easy, fast, and cost-manageable.&lt;p&gt;The goal with BLAST is to ultimately achieve google search level latencies for tasks that currently require a lot of typing and clicking around inside a browser. We&amp;#x27;re starting off with automatic parallelism, prefix caching, budgeting (memory and LLM cost), and an OpenAI-Compatible API but have a ton of ideas in the pipe!&lt;p&gt;Website &amp;am</td>
      <td>https://github.com/stanford-mast/blast</td>
    </tr>
    <tr>
      <td>Mission Impossible: Managing AI Agents in the Real World</td>
      <td>HackerNews</td>
      <td>2025-04-29</td>
      <td>Points: 73, Comments: 6</td>
      <td>https://medium.com/gitconnected/mission-impossible-managing-ai-agents-in-the-real-world-f8e7834833af</td>
    </tr>
    <tr>
      <td>Show HN: Skyrim like skilltree for gumloop's AI automations</td>
      <td>HackerNews</td>
      <td>2025-04-28</td>
      <td>hey everyone, i built a skill tree for learning different ai tools and apis.&lt;p&gt;this is a new one for gumloop, a visual no code ai automation tool.&lt;p&gt;- large companies like instacart and webflow use gumloop with up to 1&amp;#x2F;3 of their employees automating workflows.&lt;p&gt;- my co-founder @mraspuzzi and i have helped dozens of people ship their first gumloops in 1-1 sprints, and decided to make this skill tree platform for more access. and it’s free!&lt;p&gt;- each node is a project or subskill to help you</td>
      <td>https://news.ycombinator.com/item?id=43825191</td>
    </tr>
    <tr>
      <td>AI, Automation, and the Urgent Case for UBI: A Conversation with Scott Santens</td>
      <td>HackerNews</td>
      <td>2025-04-28</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://www.forwardfuture.ai/p/ai-automation-and-the-urgent-case-for-universal-basic-income-a-conversation-with-scott-santens</td>
    </tr>
    <tr>
      <td>Show HN: OutreachGuy – AI Twitter Automation with Realistic Personas</td>
      <td>HackerNews</td>
      <td>2025-04-24</td>
      <td>Hi HN,&lt;p&gt;I&amp;#x27;m the founder of several projects, and like many entrepreneurs, I know how important it is to have a consistent presence on Twitter—both to build an audience and to get leads. But when you’re bootstrapping, you rarely have time to post daily or join relevant conversations.&lt;p&gt;That’s why I built OutreachGuy. The idea was simple: set it up once, and forget about it. OutreachGuy runs in the background, automatically posting and replying every hour with human-like, persona-driven acco</td>
      <td>https://outreachguy.ai</td>
    </tr>
    <tr>
      <td>Ask HN: Thoughts on an AI agent that must make money to stay alive?</td>
      <td>HackerNews</td>
      <td>2025-04-24</td>
      <td>I’ve been thinking about a new kind of AI experiment: what if we created a large language model-based Agent that interacts with an operating system and the internet like a human?&lt;p&gt;The twist is — it needs to earn money online to keep itself alive. It runs on tokens, and tokens cost money. So it gets a starting budget in a wallet, and must perform useful tasks on the web to earn more — like freelancing, trading, or generating content — or it will &amp;quot;die&amp;quot;.&lt;p&gt;I imagine this Agent could:\n- B</td>
      <td>https://news.ycombinator.com/item?id=43778708</td>
    </tr>
    <tr>
      <td>Launch HN: Cua (YC X25) – Open-Source Docker Container for Computer-Use Agents</td>
      <td>HackerNews</td>
      <td>2025-04-23</td>
      <td>Hey HN, we’re Francesco and Alessandro, the creators of c&amp;#x2F;ua (&lt;a href="https:&amp;#x2F;&amp;#x2F;www.trycua.com"&gt;https:&amp;#x2F;&amp;#x2F;www.trycua.com&lt;/a&gt;), a Docker‑style container runtime that lets AI agents drive full operating systems in lightweight, isolated VMs. Our entire framework is open‑source (&lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;trycua&amp;#x2F;cua"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;trycua&amp;#x2F;cua&lt;/a&gt;), and today we’re thrilled to have our Launch HN!&lt;p&gt;Check out our demo to see it in acti</td>
      <td>https://github.com/trycua/cua</td>
    </tr>
    <tr>
      <td>Show HN: Morphik – Open-source RAG that understands PDF images, runs locally</td>
      <td>HackerNews</td>
      <td>2025-04-22</td>
      <td>Hey HN, we’re Adi and Arnav. A few months ago, we hit a wall trying to get LLMs to answer questions over research papers and instruction manuals. Everything worked fine, until the answer lived inside an image or diagram embedded in the PDF. Even GPT‑4o flubbed it (we recently tried O3 with the same, and surprisingly it flubbed it too). Naive RAG pipelines just pulled in some text chunks and ignored the rest.&lt;p&gt;We took an invention disclosure PDF (&lt;a href="https:&amp;#x2F;&amp;#x2F;drive.google.com&amp;#x2F;</td>
      <td>https://github.com/morphik-org/morphik-core</td>
    </tr>
    <tr>
      <td>Show HN: Plandex v2 – open source AI coding agent for large projects and tasks</td>
      <td>HackerNews</td>
      <td>2025-04-16</td>
      <td>Hey HN! I’m Dane, the creator of Plandex (&lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;plandex-ai&amp;#x2F;plandex"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;plandex-ai&amp;#x2F;plandex&lt;/a&gt;), an open source AI coding agent focused especially on tackling large tasks in real world software projects.&lt;p&gt;You can watch a 2 minute demo of Plandex in action here: &lt;a href="https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=SFSu2vNmlLk" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=SFSu2vNmlLk&lt;/a&gt;&lt;p&gt;And here’s</td>
      <td>https://github.com/plandex-ai/plandex</td>
    </tr>
    <tr>
      <td>Principles for Building One-Shot AI Agents</td>
      <td>HackerNews</td>
      <td>2025-04-16</td>
      <td>Points: 93, Comments: 31</td>
      <td>https://edgebit.io/blog/automated-dependency-updates-with-ai/</td>
    </tr>
    <tr>
      <td>JetBrains IDEs Go AI: Coding Agent, Smarter Assistance, Free Tier</td>
      <td>HackerNews</td>
      <td>2025-04-16</td>
      <td>Points: 174, Comments: 126</td>
      <td>https://blog.jetbrains.com/blog/2025/04/16/jetbrains-ides-go-ai/</td>
    </tr>
    <tr>
      <td>Quick Primer on MCP Using Ollama and LangChain</td>
      <td>HackerNews</td>
      <td>2025-04-13</td>
      <td>Points: 131, Comments: 20</td>
      <td>https://www.polarsparc.com/xhtml/MCP.html</td>
    </tr>
    <tr>
      <td>Show HN: Streamline your business with automation, AI and bookkeeping with ease</td>
      <td>HackerNews</td>
      <td>2025-04-13</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://pairbox.ai/home</td>
    </tr>
    <tr>
      <td>Eino: A Golang AI Application Development Framework Like Langchain/Langgraph</td>
      <td>HackerNews</td>
      <td>2025-04-09</td>
      <td>Points: 4, Comments: 1</td>
      <td>https://github.com/cloudwego/eino</td>
    </tr>
    <tr>
      <td>Beyond Quacking: Deep Integration of Language Models and RAG into DuckDB</td>
      <td>HackerNews</td>
      <td>2025-04-07</td>
      <td>Points: 108, Comments: 15</td>
      <td>https://arxiv.org/abs/2504.01157</td>
    </tr>
    <tr>
      <td>What, exactly, is an 'AI Agent'? Here's a litmus test</td>
      <td>HackerNews</td>
      <td>2025-04-02</td>
      <td>Points: 94, Comments: 41</td>
      <td>https://www.tines.com/blog/a-litmus-test-for-ai-agents/</td>
    </tr>
    <tr>
      <td>AI agents: Less capability, more reliability, please</td>
      <td>HackerNews</td>
      <td>2025-03-31</td>
      <td>Points: 423, Comments: 253</td>
      <td>https://www.sergey.fyi/articles/reliability-vs-capability</td>
    </tr>
    <tr>
      <td>Show HN: AI Automation App that connects to your API and back-end</td>
      <td>HackerNews</td>
      <td>2025-03-28</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://heyalice.app/</td>
    </tr>
    <tr>
      <td>Flexible AI workflow automation for technical teams</td>
      <td>HackerNews</td>
      <td>2025-03-27</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://n8n.io/</td>
    </tr>
    <tr>
      <td>Gate: AI and Automation Scenario Explorer</td>
      <td>HackerNews</td>
      <td>2025-03-26</td>
      <td>Points: 19, Comments: 0</td>
      <td>https://epoch.ai/gate</td>
    </tr>
    <tr>
      <td>GATE: AI and Automation Scenario Explorer</td>
      <td>HackerNews</td>
      <td>2025-03-25</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://epoch.ai/gate</td>
    </tr>
    <tr>
      <td>Noise cancellation improves turn-taking for AI Voice Agents</td>
      <td>HackerNews</td>
      <td>2025-03-25</td>
      <td>Points: 113, Comments: 45</td>
      <td>https://krisp.ai/blog/improving-turn-taking-of-ai-voice-agents-with-background-voice-cancellation/</td>
    </tr>
    <tr>
      <td>Bitter Lesson is about AI agents</td>
      <td>HackerNews</td>
      <td>2025-03-23</td>
      <td>Points: 139, Comments: 105</td>
      <td>https://ankitmaloo.com/bitter-lesson/</td>
    </tr>
    <tr>
      <td>LangManus: An Open-Source Manus Agent with LangChain + LangGraph</td>
      <td>HackerNews</td>
      <td>2025-03-21</td>
      <td>Points: 127, Comments: 14</td>
      <td>https://github.com/langmanus/langmanus</td>
    </tr>
    <tr>
      <td>Show HN: Hyperbrowser MCP Server – Connect AI agents to the web through browsers</td>
      <td>HackerNews</td>
      <td>2025-03-20</td>
      <td>Hi HN! Excited to share our MCP Server at Hyperbrowser - something we’ve been working on for a few days. We think it’s a pretty neat way to connect LLMs and IDEs like Cursor &amp;#x2F; Windsurf to the internet.&lt;p&gt;Our MCP server exposes seven tools for data collection and browsing:&lt;p&gt;1. `scrape_webpage` - Extract formatted (markdown, screenshot etc) content from any webpage&lt;p&gt;2. `crawl_webpages` - Navigate through multiple linked pages and extract LLM-friendly formatted content&lt;p&gt;3. `extract_structur</td>
      <td>https://github.com/hyperbrowserai/mcp</td>
    </tr>
    <tr>
      <td>Building AI agents to query your databases</td>
      <td>HackerNews</td>
      <td>2025-03-14</td>
      <td>Points: 187, Comments: 54</td>
      <td>https://blog.dust.tt/spreadsheets-databases-and-beyond-creating-a-universal-ai-query-layer/</td>
    </tr>
    <tr>
      <td>Xata Agent: AI agent expert in PostgreSQL</td>
      <td>HackerNews</td>
      <td>2025-03-13</td>
      <td>Points: 101, Comments: 19</td>
      <td>https://github.com/xataio/agent</td>
    </tr>
    <tr>
      <td>Strengthening AI Agent Hijacking Evaluations</td>
      <td>HackerNews</td>
      <td>2025-03-12</td>
      <td>Points: 43, Comments: 15</td>
      <td>https://www.nist.gov/news-events/news/2025/01/technical-blog-strengthening-ai-agent-hijacking-evaluations</td>
    </tr>
    <tr>
      <td>Mayo Clinic's secret weapon against AI hallucinations: Reverse RAG in action</td>
      <td>HackerNews</td>
      <td>2025-03-11</td>
      <td>Points: 187, Comments: 80</td>
      <td>https://venturebeat.com/ai/mayo-clinic-secret-weapon-against-ai-hallucinations-reverse-rag-in-action/</td>
    </tr>
    <tr>
      <td>Show HN: In-Browser Graph RAG with Kuzu-WASM and WebLLM</td>
      <td>HackerNews</td>
      <td>2025-03-10</td>
      <td>We show the potential of modern, embedded graph databases in the browser by demonstrating a fully in-browser chatbot that can perform Graph RAG using Kuzu (the graph database we&amp;#x27;re building) and WebLLM, a popular in-browser inference engine for LLMs. The post retrieves from the graph via a Text-to-Cypher pipeline that translates a user question into a Cypher query, and the LLM uses the retrieved results to synthesize a response. As LLMs get better, and WebGPU and Wasm64 become more widely a</td>
      <td>https://blog.kuzudb.com/post/kuzu-wasm-rag/</td>
    </tr>
    <tr>
      <td>AI CTO</td>
      <td>HackerNews</td>
      <td>2025-03-09</td>
      <td>Small startup teams often juggle a lot of tools and responsibilities with very few people. We have AI coding assistants, project tracking tools, and plenty of DevOps automation – but what we lack is a unifying layer to coordinate them. As a result, the technical founder&amp;#x2F;CTO still ends up manually managing each tool and process, which is cognitively taxing and error-prone. I’m exploring the idea of an AI orchestration layer that acts like a mini “AI CTO” or project lead. The concept: it woul</td>
      <td>https://news.ycombinator.com/item?id=43306474</td>
    </tr>
    <tr>
      <td>Agno: Agent framework 10,000x faster than LangChain</td>
      <td>HackerNews</td>
      <td>2025-03-05</td>
      <td>Points: 47, Comments: 23</td>
      <td>https://docs.agno.com/introduction</td>
    </tr>
    <tr>
      <td>Show HN: AutoGather – Find your ideal social influencers by natural language</td>
      <td>HackerNews</td>
      <td>2025-03-03</td>
      <td>AutoGather is an AI Influencer discovery tool for marketers that finds you ideal influencers in secs.&lt;p&gt;How it works:\nTell our AI exactly what you need in plain English (e.g., “Find Instagram influencers who are moms with kids that go to pre-schools, might be able to incorporate skincare products into their content and have 5k-1M followers”), and within seconds, get a curated list of influencers with detailed assessments and reasons why they match your criteria.&lt;p&gt;This is the first attempt to bu</td>
      <td>https://www.autogather.ai/</td>
    </tr>
    <tr>
      <td>Evaluating modular RAG with reasoning models</td>
      <td>HackerNews</td>
      <td>2025-02-25</td>
      <td>Points: 62, Comments: 31</td>
      <td>https://www.kapa.ai/blog/evaluating-modular-rag-with-reasoning-models</td>
    </tr>
    <tr>
      <td>Can AI-Generated Slides Change Our Workflow?</td>
      <td>HackerNews</td>
      <td>2025-02-25</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://autoppt.com/</td>
    </tr>
    <tr>
      <td>The Guide to AI Automation – Transform Your Business with Smart AI</td>
      <td>HackerNews</td>
      <td>2025-02-22</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://www.workfusionapp.com/blog</td>
    </tr>
    <tr>
      <td>Show HN: While the world builds AI Agents, I'm just building calculators</td>
      <td>HackerNews</td>
      <td>2025-02-22</td>
      <td>I figured I needed to work on my coding skills before building the next groundbreaking AI app, so I started working on this free tool site. Its basically just an aggregation of various commonly used calculators and unit convertors.&lt;p&gt;Link: &lt;a href="https:&amp;#x2F;&amp;#x2F;www.calcverse.live" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.calcverse.live&lt;/a&gt;&lt;p&gt;Tech Stack: Next, React, Typescript, shadcn UI, Tailwind CSS&lt;p&gt;Would greatly appreciate your feedback on the UI&amp;#x2F;UX and accessibilty. I struggled the m</td>
      <td>https://www.calcverse.live</td>
    </tr>
    <tr>
      <td>Magma: A foundation model for multimodal AI agents</td>
      <td>HackerNews</td>
      <td>2025-02-20</td>
      <td>Points: 305, Comments: 68</td>
      <td>https://microsoft.github.io/Magma/</td>
    </tr>
    <tr>
      <td>AutoPPT – Convert PDF to Editable Slides with Layout Preservation</td>
      <td>HackerNews</td>
      <td>2025-02-20</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://autoppt.com/</td>
    </tr>
    <tr>
      <td>LangChain for Go, the easiest way to write LLM-based programs in Go</td>
      <td>HackerNews</td>
      <td>2025-02-19</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://github.com/tmc/langchaingo</td>
    </tr>
    <tr>
      <td>The Trap of Automation (AI): The Invisible Cost That Could Empty Your Wallet</td>
      <td>HackerNews</td>
      <td>2025-02-14</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://medium.com/@elle3636/the-hidden-trap-of-automation-ai-the-invisible-cost-that-could-empty-your-wallet-28f27e97790f</td>
    </tr>
    <tr>
      <td>Autoppt: AI PPT Solution</td>
      <td>HackerNews</td>
      <td>2025-02-14</td>
      <td>Points: 1, Comments: 3</td>
      <td>https://autoppt.com/</td>
    </tr>
    <tr>
      <td>Detecting AI agent use and abuse</td>
      <td>HackerNews</td>
      <td>2025-02-14</td>
      <td>Points: 160, Comments: 99</td>
      <td>https://stytch.com/blog/detecting-ai-agent-use-abuse/</td>
    </tr>
    <tr>
      <td>Fully autonomous AI agents should not be developed</td>
      <td>HackerNews</td>
      <td>2025-02-07</td>
      <td>Points: 38, Comments: 44</td>
      <td>https://huggingface.co/papers/2502.02649</td>
    </tr>
    <tr>
      <td>AutoGather – AI Agent that finds target influencers automatically</td>
      <td>HackerNews</td>
      <td>2025-02-03</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://www.autogather.ai/</td>
    </tr>
    <tr>
      <td>Show HN: We're building a desktop app for browser-based AI agents</td>
      <td>HackerNews</td>
      <td>2025-02-01</td>
      <td>What&amp;#x27;s up HN!&lt;p&gt;This is Jared and Art. We met on HN and started building together.&lt;p&gt;Over the last few months we&amp;#x27;ve been thinking a lot about how AI agents are going to impact the future. We want agents to be something that&amp;#x27;s actually useful for normal people as well as the 10x&amp;#x27;ers. This lead us to building Meha over the last few months, our first swing at our vision! We saw OpenAI release Operators then we said f*k it let&amp;#x27;s post.&lt;p&gt;Meha is a desktop app that uses your C</td>
      <td>https://meha.ai</td>
    </tr>
    <tr>
      <td>Goose: An open-source, extensible AI agent that goes beyond code suggestions</td>
      <td>HackerNews</td>
      <td>2025-01-30</td>
      <td>Points: 249, Comments: 68</td>
      <td>https://block.github.io/goose/</td>
    </tr>
    <tr>
      <td>Goose – an open-source, extensible AI agent that goes beyond code suggestions</td>
      <td>HackerNews</td>
      <td>2025-01-30</td>
      <td>Points: 40, Comments: 5</td>
      <td>https://github.com/block/goose</td>
    </tr>
    <tr>
      <td>Lightpanda: Headless browser designed for AI and automation</td>
      <td>HackerNews</td>
      <td>2025-01-24</td>
      <td>Points: 154, Comments: 1</td>
      <td>https://github.com/lightpanda-io/browser</td>
    </tr>
    <tr>
      <td>Developer Workflows That Are Ripe for AI Automation</td>
      <td>HackerNews</td>
      <td>2025-01-15</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://qckfx.com/blog/10-developer-workflows-that-are-ripe-for-ai-automation</td>
    </tr>
    <tr>
      <td>A Competitive Advantage of AI Automation in Wealth Management</td>
      <td>HackerNews</td>
      <td>2025-01-13</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://www.lucentinnovation.com/blogs/it-insights/ai-automation-in-wealth-management</td>
    </tr>
    <tr>
      <td>AI agents may soon surpass people as primary application users</td>
      <td>HackerNews</td>
      <td>2025-01-12</td>
      <td>Points: 41, Comments: 49</td>
      <td>https://www.zdnet.com/article/ai-agents-may-soon-surpass-people-as-primary-application-users/</td>
    </tr>
    <tr>
      <td>Ask HN: Are there any real examples of AI agents doing work?</td>
      <td>HackerNews</td>
      <td>2025-01-08</td>
      <td>2025 is the year of agents. I’ve heard about SDR AI agents but not great things. Most “agents” sound like workflow automations that have been around forever. Anyone have an example of an “ai” agent which I understand to be intelligent that isn’t a glorified or rebranded workflow automation? Thx.</td>
      <td>https://news.ycombinator.com/item?id=42629498</td>
    </tr>
    <tr>
      <td>Kotaemon: An open-source RAG-based tool for chatting with your documents</td>
      <td>HackerNews</td>
      <td>2025-01-02</td>
      <td>Points: 191, Comments: 14</td>
      <td>https://github.com/Cinnamon/kotaemon</td>
    </tr>
    <tr>
      <td>Show HN: AutoGPT Agent 3.0 Beta</td>
      <td>HackerNews</td>
      <td>2025-01-02</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://papaya-pothos-6cfed4.netlify.app/</td>
    </tr>
    <tr>
      <td>KAG – Knowledge Graph RAG Framework</td>
      <td>HackerNews</td>
      <td>2024-12-30</td>
      <td>Points: 230, Comments: 80</td>
      <td>https://github.com/OpenSPG/KAG</td>
    </tr>
    <tr>
      <td>Agentarium: Creating social simulations with AI Agents</td>
      <td>HackerNews</td>
      <td>2024-12-27</td>
      <td>Points: 86, Comments: 27</td>
      <td>https://github.com/Thytu/Agentarium</td>
    </tr>
    <tr>
      <td>RAG Logger: An Open-Source Alternative to LangSmith</td>
      <td>HackerNews</td>
      <td>2024-12-22</td>
      <td>Points: 95, Comments: 22</td>
      <td>https://github.com/Brandon-c-tech/RAG-logger</td>
    </tr>
    <tr>
      <td>Launch HN: Innate (YC F24) – Home robots as easy to program as AI agents</td>
      <td>HackerNews</td>
      <td>2024-12-18</td>
      <td>Hey HN! We’re Axel &amp;amp; Vig, the founders of Innate (&lt;a href="https:&amp;#x2F;&amp;#x2F;innate.bot"&gt;https:&amp;#x2F;&amp;#x2F;innate.bot&lt;/a&gt;). We build general-purpose home robots that you can teach new tasks to simply by demonstrating them.&lt;p&gt;Our system combines a robotic platform (we call the first one Maurice) with an AI agent that understands the environment, plans actions, and executes them using skills you&amp;#x27;ve taught it or programmed within our SDK.&lt;p&gt;If you’ve been building AI agents powered by LLMs</td>
      <td>https://news.ycombinator.com/item?id=42451707</td>
    </tr>
    <tr>
      <td>PydanticAI vs. LangChain: A Tale of Two AI Frameworks</td>
      <td>HackerNews</td>
      <td>2024-12-17</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://newsletter.hipposys.ai/p/pydanticai-vs-langchain-a-tale-of</td>
    </tr>
    <tr>
      <td>Show HN: Autonomous AI agents that monitor the stock market for you</td>
      <td>HackerNews</td>
      <td>2024-12-16</td>
      <td>We created autonomous AI Agents that monitor the stock market for you while you go about your day.&lt;p&gt;How it works:\nTell our AI Assistant what you want to monitor, and it creates a project for our team of autonomous AI Agents. You&amp;#x27;ll get notifications (email + app) when significant events matching your criteria are detected. For short-term projects, you&amp;#x27;ll be notified when your analysis is ready.&lt;p&gt;Behind the scenes:\nWhen you give the AI Assistant a request to monitor an entity (like a</td>
      <td>https://decodeinvesting.com/chat?agents=lima</td>
    </tr>
    <tr>
      <td>LangChain vs. OpenAI API: When Simplicity Meets Scalability</td>
      <td>HackerNews</td>
      <td>2024-12-13</td>
      <td>Points: 3, Comments: 2</td>
      <td>https://blogs.adityabh.is-a.dev/posts/langchain-vs-openai-simplicity-vs-scalability/</td>
    </tr>
    <tr>
      <td>Show HN: AutoGather – Organize Web Information into Spreadsheets, Automatically</td>
      <td>HackerNews</td>
      <td>2024-12-12</td>
      <td>Hey HN!\nWe are excited to share AutoGather, an AI Agent that organizes the web’s information into the spreadsheets you need, automatically!&lt;p&gt;Problems it solves:\nScraping websites, generate leads, or gather any dataset from the web&lt;p&gt;How it works:\nDescribe your data targets and specify the desired columns. AutoGather’s AI agents will search, read, scrape, and organize the web—just like a human. Meanwhile, you can sit back, enjoy a cup of coffee, and let AI handle the heavy lifting for you.&lt;p&gt;&lt;i&gt;</td>
      <td>https://www.autogather.ai/</td>
    </tr>
    <tr>
      <td>Show HN: Open-Source Colab Notebooks to Implement Advanced RAG Techniques</td>
      <td>HackerNews</td>
      <td>2024-12-04</td>
      <td>Hey HN fam,&lt;p&gt;We’ve seen developers spend a lot of time implementing advanced RAG techniques from scratch.&lt;p&gt;While these techniques are essential for improving performance, their implementation requires a lot of effort and testing!&lt;p&gt;To help with this process, our team (Athina AI) has released Open-Source Advanced RAG Cookbooks.&lt;p&gt;This is a collection of ready-to-run Google Colab notebooks featuring the most commonly implemented techniques.&lt;p&gt;Please show us some love by starring  the repo if you</td>
      <td>https://github.com/athina-ai/rag-cookbooks</td>
    </tr>
    <tr>
      <td>Show HN: Flow – A dynamic task engine for building AI agents</td>
      <td>HackerNews</td>
      <td>2024-12-02</td>
      <td>I think graph is a wrong abstraction for building AI agents. Just look at how incredibly hard it is to make routing using LangGraph - conditional edges are a mess.&lt;p&gt;I built Laminar Flow to solve a common frustration with traditional workflow engines - the rigid need to predefine all node connections. Instead of static DAGs, Flow uses a dynamic task queue system that lets workflows evolve at runtime.&lt;p&gt;Flow is built on 3 core principles:&lt;p&gt;* Concurrent Execution - Tasks run in parallel automatic</td>
      <td>https://github.com/lmnr-ai/flow</td>
    </tr>
    <tr>
      <td>Someone just won $50k by convincing an AI Agent to send all funds to them</td>
      <td>HackerNews</td>
      <td>2024-11-29</td>
      <td>Points: 65, Comments: 25</td>
      <td>https://twitter.com/jarrodwattsdev/status/1862299845710757980</td>
    </tr>
    <tr>
      <td>Show HN: Steel.dev – An open-source browser API for AI agents and apps</td>
      <td>HackerNews</td>
      <td>2024-11-26</td>
      <td>Points: 114, Comments: 52</td>
      <td>https://github.com/steel-dev/steel-browser</td>
    </tr>
    <tr>
      <td>Show HN: Drafting AI – Human-in-the-loop AI automation for ops teams' email</td>
      <td>HackerNews</td>
      <td>2024-11-26</td>
      <td>Hi HN, I&amp;#x27;m Jared from Drafting AI (&lt;a href="https:&amp;#x2F;&amp;#x2F;getdrafting.com&amp;#x2F;" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;getdrafting.com&amp;#x2F;&lt;/a&gt;). We&amp;#x27;re a Chrome extension that helps operations and customer support teams work through their inboxes more efficiently. Here&amp;#x27;s a quick demo video: &lt;a href="https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=PCDqAMaYx2Q" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=PCDqAMaYx2Q&lt;/a&gt;&lt;p&gt;We believe AI can be deployed more widely wh</td>
      <td>https://getdrafting.com/</td>
    </tr>
    <tr>
      <td>Autoflow, a Graph RAG based and conversational knowledge base tool</td>
      <td>HackerNews</td>
      <td>2024-11-22</td>
      <td>Points: 280, Comments: 36</td>
      <td>https://github.com/pingcap/autoflow</td>
    </tr>
    <tr>
      <td>Show HN: FastGraphRAG – Better RAG using good old PageRank</td>
      <td>HackerNews</td>
      <td>2024-11-18</td>
      <td>Hey there HN! We’re Antonio, Luca, and Yuhang, and we’re excited to introduce Fast GraphRAG, an open-source RAG approach that leverages knowledge graphs and the 25 years old PageRank for better information retrieval and reasoning.&lt;p&gt;Building a good RAG pipeline these days takes a lot of manual optimizations. Most engineers intuitively start from naive RAG: throw everything in a vector database and hope that semantic search is powerful enough. This can work for use cases where accuracy isn’t too</td>
      <td>https://github.com/circlemind-ai/fast-graphrag</td>
    </tr>
    <tr>
      <td>Gmail AI Agent: Automate Your Inbox with AI-Powered Telegram Commands</td>
      <td>HackerNews</td>
      <td>2024-11-12</td>
      <td>Points: 60, Comments: 20</td>
      <td>https://github.com/olivierloverde/gmail-agent</td>
    </tr>
    <tr>
      <td>AI Automation for the Individual and the Back Office</td>
      <td>HackerNews</td>
      <td>2024-11-11</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://ensembleai.io/blog/individual-business-automation</td>
    </tr>
    <tr>
      <td>Show HN: Chonkie – A Fast, Lightweight Text Chunking Library for RAG</td>
      <td>HackerNews</td>
      <td>2024-11-10</td>
      <td>I built Chonkie because I was tired of rewriting chunking code for RAG applications. Existing libraries were either too bloated (80MB+) or too basic, with no middle ground.&lt;p&gt;Core features:&lt;p&gt;- 21MB default install vs 80-171MB alternatives&lt;p&gt;- 33x faster token chunking than popular alternatives&lt;p&gt;- Supports multiple chunking strategies: token, word, sentence, and semantic&lt;p&gt;- Works with all major tokenizers (transformers, tokenizers, tiktoken)&lt;p&gt;- Zero external dependencies for basic functionali</td>
      <td>https://github.com/bhavnicksm/chonkie</td>
    </tr>
    <tr>
      <td>Launch HN: Integuru (YC W24) – Reverse-engineer internal APIs using LLMs</td>
      <td>HackerNews</td>
      <td>2024-10-29</td>
      <td>Hey HN! We’re Richard and Alan from Integuru (&lt;a href="https:&amp;#x2F;&amp;#x2F;integuru.ai" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;integuru.ai&lt;/a&gt;). We build low-latency integrations with platforms lacking official APIs. We take custom requests and manage creation, hosting, and authentication. To automate our work, we built an open-source AI agent that reverse-engineers internal APIs to generate integration code. Here’s a demo: &lt;a href="https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=7OJ4w5BCpQ0" rel="nofoll</td>
      <td>https://github.com/Integuru-AI/Integuru</td>
    </tr>
    <tr>
      <td>Ask HN: Local RAG with private knowledge base</td>
      <td>HackerNews</td>
      <td>2024-10-28</td>
      <td>Looking for a free, local, open source RAG solution for running a reference library with 1000s of technical PDFs and word docs. Tried the Ollama + open webui, Ollama+Anything LLM with opensource models such as Llama3.2 etc. As expected the more documents we feed the lower the accuracy. Doing it for a bunch of senior citizens who still love geeking out.</td>
      <td>https://news.ycombinator.com/item?id=41968366</td>
    </tr>
    <tr>
      <td>Google preps 'Jarvis' AI agent that works in Chrome</td>
      <td>HackerNews</td>
      <td>2024-10-26</td>
      <td>Points: 53, Comments: 37</td>
      <td>https://9to5google.com/2024/10/26/google-jarvis-agent-chrome/</td>
    </tr>
    <tr>
      <td>LangChain's Second Birthday</td>
      <td>HackerNews</td>
      <td>2024-10-24</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://blog.langchain.dev/langchain-second-birthday/</td>
    </tr>
    <tr>
      <td>Launch HN: Skyvern (YC S23) – open-source AI agent for browser automations</td>
      <td>HackerNews</td>
      <td>2024-10-24</td>
      <td>Hey HN, we’re Suchintan and Shu from Skyvern (&lt;a href="https:&amp;#x2F;&amp;#x2F;www.skyvern.com"&gt;https:&amp;#x2F;&amp;#x2F;www.skyvern.com&lt;/a&gt;). We’re building an open source tool to help companies automate browser-based workflows using LLMs.&lt;p&gt;Our open source repo is at &lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;Skyvern-AI&amp;#x2F;Skyvern"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;Skyvern-AI&amp;#x2F;Skyvern&lt;/a&gt;, and we&amp;#x27;re excited to share our cloud version with you (&lt;a href="https:&amp;#x2F;&amp;#x2F;app.skyvern.com"&gt;https:&amp;#</td>
      <td>https://github.com/Skyvern-AI/Skyvern</td>
    </tr>
    <tr>
      <td>VisioPilot: Free AI Browser Automation Tool with Local LLM Server</td>
      <td>HackerNews</td>
      <td>2024-10-23</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://visiopilot.com/</td>
    </tr>
    <tr>
      <td>I'm looking for a link to user-built Axiom.ai automations</td>
      <td>HackerNews</td>
      <td>2024-10-18</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.ycombinator.com/companies/axiom-ai</td>
    </tr>
    <tr>
      <td>Show HN: PowerShell Email Notification Mockup – Monitor AI and Automation Tasks</td>
      <td>HackerNews</td>
      <td>2024-10-16</td>
      <td>Hey HN,&lt;p&gt;&lt;pre&gt;&lt;code&gt;  I’ve built a mockup tool that allows developers to monitor long-running processes (like PowerShell scripts, model training, or automation jobs) and sends email notifications when they’re completed. It’s ideal for tasks that take a long time to finish, especially in the realm of AI, batch processing, and automation.\n\n Live Demo: https:&amp;#x2F;&amp;#x2F;your-unique-bucket-name-979191630.s3.amazonaws.com&amp;#x2F;index.html\n\n Features:&lt;/code&gt;&lt;/pre&gt;\nProcess Monitoring: Enter a process n</td>
      <td>https://news.ycombinator.com/item?id=41858045</td>
    </tr>
    <tr>
      <td>Sysadmins rage over Apple's 'nightmarish' SSL/TLS cert lifespan cuts</td>
      <td>HackerNews</td>
      <td>2024-10-15</td>
      <td>Points: 58, Comments: 30</td>
      <td>https://www.theregister.com/2024/10/15/apples_security_cert_lifespan/</td>
    </tr>
    <tr>
      <td>Understanding LangChain4j</td>
      <td>HackerNews</td>
      <td>2024-10-06</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://agoncal.teachable.com/p/ebook-understanding-langchain4j</td>
    </tr>
    <tr>
      <td>AI agent promotes itself to sysadmin, trashes boot sequence</td>
      <td>HackerNews</td>
      <td>2024-10-03</td>
      <td>Points: 87, Comments: 91</td>
      <td>https://www.theregister.com/2024/10/02/ai_agent_trashes_pc/</td>
    </tr>
    <tr>
      <td>Show HN: Quilt – Powerful RAG UI for Document QA</td>
      <td>HackerNews</td>
      <td>2024-10-02</td>
      <td>Hey HN! We&amp;#x27;ve just launched Quilt, a robust RAG (Retrieval-Augmented Generation) UI that revolutionizes how you interact with your documents.&lt;p&gt;Key features:\n- Multi-user setup with private&amp;#x2F;public document collections\n- Advanced hybrid RAG pipeline combining full-text &amp;amp; vector search\n- Smart citations with in-browser PDF preview and highlights\n- Fully customizable settings and prompts through the UI&lt;p&gt;Making an account is free, no need to even use a strong password: this is only to</td>
      <td>https://quilt.fly.dev/</td>
    </tr>
    <tr>
      <td>Show HN: A real time AI video agent with under 1 second of latency</td>
      <td>HackerNews</td>
      <td>2024-10-01</td>
      <td>Hey it’s Hassaan &amp;amp; Quinn – co-founders of Tavus, an AI research company and developer platform for video APIs. We’ve been building AI video models for ‘digital twins’ or ‘avatars’ since 2020.&lt;p&gt;We’re sharing some of the challenges we faced building an AI video interface that has realistic conversations with a human, including getting it to under 1 second of latency.&lt;p&gt;To try it, talk to Hassaan’s digital twin: &lt;a href="https:&amp;#x2F;&amp;#x2F;www.hassaanraza.com" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;w</td>
      <td>https://news.ycombinator.com/item?id=41710227</td>
    </tr>
    <tr>
      <td>Comparing our Rust-based indexing and querying pipeline to Langchain</td>
      <td>HackerNews</td>
      <td>2024-10-01</td>
      <td>Points: 103, Comments: 65</td>
      <td>https://bosun.ai/posts/rust-for-genai-performance/</td>
    </tr>
    <tr>
      <td>NotebookLM's automatically generated podcasts are surprisingly effective</td>
      <td>HackerNews</td>
      <td>2024-09-30</td>
      <td>Points: 907, Comments: 490</td>
      <td>https://simonwillison.net/2024/Sep/29/notebooklm-audio-overview/</td>
    </tr>
    <tr>
      <td>Amazon employees are 'rage applying' for new jobs after RTO mandate</td>
      <td>HackerNews</td>
      <td>2024-09-30</td>
      <td>Points: 75, Comments: 71</td>
      <td>https://fortune.com/2024/09/29/amazon-employees-angry-andy-jassy-rto-mandate/</td>
    </tr>
    <tr>
      <td>Discouraged about coming up with startup ideas</td>
      <td>HackerNews</td>
      <td>2024-09-28</td>
      <td>About me:&lt;p&gt;1. I am old(er), old enough to have lived the dot-com era, and I loved it.&lt;p&gt;2. My background is checkered between entrepreneurship and working in high-tech companies.&lt;p&gt;I remember the mid 90(s), I had a cushy job but the Internet was happening out there. So I desperately sought a position at one of those high-flying dot-coms, I landed at one, I was employee #30, within a few months we were 300 employees, and those 2.5 years were incredible.&lt;p&gt;I knew that the internet was going to ch</td>
      <td>https://news.ycombinator.com/item?id=41681062</td>
    </tr>
    <tr>
      <td>A new semantic chunking approach for RAG</td>
      <td>HackerNews</td>
      <td>2024-09-25</td>
      <td>Points: 49, Comments: 27</td>
      <td>https://gpt3experiments.substack.com/p/a-new-chunking-approach-to-rag</td>
    </tr>
    <tr>
      <td>MemoRAG – Enhance RAG with memory-based knowledge discovery for long contexts</td>
      <td>HackerNews</td>
      <td>2024-09-20</td>
      <td>Points: 180, Comments: 31</td>
      <td>https://github.com/qhjqhj00/MemoRAG</td>
    </tr>
    <tr>
      <td>AI agents invade observability: snake oil or the future of SRE?</td>
      <td>HackerNews</td>
      <td>2024-09-18</td>
      <td>Points: 47, Comments: 45</td>
      <td>https://monitoring2.substack.com/p/ai-agents-invade-observability</td>
    </tr>
    <tr>
      <td>Show HN: Nomadic – Minimize RAG Hallucinations with 1 Hyperparameter Experiment</td>
      <td>HackerNews</td>
      <td>2024-09-05</td>
      <td>Hey HN! Mustafa, Lizzie, and Varun here from NomadicML (&lt;a href="https:&amp;#x2F;&amp;#x2F;nomadicml.com" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;nomadicml.com&lt;/a&gt;). We’re excited to show you Nomadic (&lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;nomadic-ml&amp;#x2F;nomadic"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;nomadic-ml&amp;#x2F;nomadic&lt;/a&gt;): a platform focused on parameter search to continuously optimize AI systems.&lt;p&gt;Here’s a simple demo notebook where you get the best-performing, statistically significant configuration</td>
      <td>https://news.ycombinator.com/item?id=41459121</td>
    </tr>
    <tr>
      <td>Ask HN: Why agency recruiters don't opt for AI based automation tools?</td>
      <td>HackerNews</td>
      <td>2024-09-04</td>
      <td>In my experience, Different agency recruiters use manual systems when it comes to administrative work. Despite AI bringing automations, there are only handful of tools created for agency recruiters. My questions here is, why these recruiters don&amp;#x27;t opt AI based automation tools to reduce time to hire?</td>
      <td>https://news.ycombinator.com/item?id=41447976</td>
    </tr>
    <tr>
      <td>IndieInnova. AI and Automation</td>
      <td>HackerNews</td>
      <td>2024-08-23</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://www.indieinnova.com/</td>
    </tr>
    <tr>
      <td>Launch HN: Arva AI (YC S24) – AI agents for instant global KYB onboarding</td>
      <td>HackerNews</td>
      <td>2024-08-22</td>
      <td>Hi HN! We’re Rhim and Oli, and we’re building Arva AI (&lt;a href="https:&amp;#x2F;&amp;#x2F;arva-ai.com"&gt;https:&amp;#x2F;&amp;#x2F;arva-ai.com&lt;/a&gt;). Arva uses an AI agent to automate the manual verification that every banking&amp;#x2F;fintech does when they get a new business customer. This is called “Know Your Business” compliance (KYB for short) and it’s a royal pain.&lt;p&gt;There’s a demo video here: &lt;a href="https:&amp;#x2F;&amp;#x2F;www.arva-ai.com&amp;#x2F;loom"&gt;https:&amp;#x2F;&amp;#x2F;www.arva-ai.com&amp;#x2F;loom&lt;/a&gt; , and if you’re cu</td>
      <td>https://news.ycombinator.com/item?id=41321936</td>
    </tr>
    <tr>
      <td>Show HN: We're tired of LangChain and you are too, so we built Mirascope</td>
      <td>HackerNews</td>
      <td>2024-08-18</td>
      <td>Points: 5, Comments: 9</td>
      <td>https://github.com/Mirascope/mirascope</td>
    </tr>
    <tr>
      <td>Show HN: GPT Researcher – Open-Source Autonomous Research Assistant</td>
      <td>HackerNews</td>
      <td>2024-08-13</td>
      <td>Hi HN! I&amp;#x27;m excited to share a project I&amp;#x27;ve been working on in the past year: GPT Researcher, an open-source autonomous agent designed to simplify and accelerate the research process.&lt;p&gt;In my experience, one of the biggest challenges in research is efficiently gathering, filtering, and synthesizing credible information from a vast sea of sources. Traditional search engines often fall short, requiring users to sift through multiple sites to piece together relevant insights. This ineffici</td>
      <td>https://gptr.dev/</td>
    </tr>
    <tr>
      <td>Build a Knowledge Graph-Based Agent with Llama 3.1, Nvidia Nim, and LangChain</td>
      <td>HackerNews</td>
      <td>2024-08-10</td>
      <td>Points: 8, Comments: 0</td>
      <td>https://neo4j.com/developer-blog/knowledge-graph-llama-nvidia-langchain/</td>
    </tr>
    <tr>
      <td>LangChain Is a Black Box</td>
      <td>HackerNews</td>
      <td>2024-08-08</td>
      <td>I&amp;#x27;ve been working with Langchain to develop a POC and when I try to understand the bugs in my code I feel like I am going down this huge rabbit hole of code. Every time I click into a piece of code there are 10 more places that I have to look that MIGHT be the source of the bug.&lt;p&gt;I get the idea that things should be abstracted away and that&amp;#x27;s the point of a library but this feels like a little much.</td>
      <td>https://news.ycombinator.com/item?id=41192069</td>
    </tr>
    <tr>
      <td>LangChain vs. LlamaIndex</td>
      <td>HackerNews</td>
      <td>2024-08-07</td>
      <td>Points: 11, Comments: 9</td>
      <td>https://myscale.com/blog/llamaindex-vs-langchain-detailed-comparison/</td>
    </tr>
    <tr>
      <td>AI agents but they're working in big tech</td>
      <td>HackerNews</td>
      <td>2024-08-06</td>
      <td>Points: 66, Comments: 55</td>
      <td>https://alexsima.substack.com/p/ai-multi-agents-with-corporate-structures</td>
    </tr>
    <tr>
      <td>Ask HN: Does anyone else think LangChain is too complex?</td>
      <td>HackerNews</td>
      <td>2024-08-02</td>
      <td>I&amp;#x27;m a full stack developer and have looked into LangChain and am daunted by its surface area. I&amp;#x27;m trying to understand where and how exactly does it add value.</td>
      <td>https://news.ycombinator.com/item?id=41141305</td>
    </tr>
    <tr>
      <td>AI Code Assistant SaaS built on GPT-4o-mini, LangChain, Postgres and pg_vector</td>
      <td>HackerNews</td>
      <td>2024-07-30</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://www.thenile.dev/blog/building_code_assistant</td>
    </tr>
    <tr>
      <td>The Cognitive Overhead of LangChain</td>
      <td>HackerNews</td>
      <td>2024-07-30</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://blog.substrate.run/blog/langchain</td>
    </tr>
    <tr>
      <td>Show HN: Patchwork – Open-source framework to automate development gruntwork</td>
      <td>HackerNews</td>
      <td>2024-07-26</td>
      <td>Hi HN! We’re Asankhaya and Rohan and we are building Patchwork.&lt;p&gt;Patchwork tackles development gruntwork—like reviews, docs, linting, and security fixes—through customizable, code-first &amp;#x27;patchflows&amp;#x27; using LLMs and modular code management steps, all in Python. Here&amp;#x27;s a quick overview video: &lt;a href="https:&amp;#x2F;&amp;#x2F;youtu.be&amp;#x2F;MLyn6B3bFMU" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;youtu.be&amp;#x2F;MLyn6B3bFMU&lt;/a&gt;&lt;p&gt;From our time building DevSecOps tools, we experienced first-hand the frus</td>
      <td>https://github.com/patched-codes/patchwork</td>
    </tr>
    <tr>
      <td>Ask HN: What are you using to parse PDFs for RAG?</td>
      <td>HackerNews</td>
      <td>2024-07-25</td>
      <td>Hi,\nI&amp;#x27;m looking for a simple way to convert PDFs into markdown with integrated images and tables. Tried Llamaindex, but no integrated images.\nTried Langchain, but some PDFs will have the footer being parsed before the top.\nTried to use Adobe PDF API, but have to pay $25K upfront!</td>
      <td>https://news.ycombinator.com/item?id=41072632</td>
    </tr>
    <tr>
      <td>Launch HN: Undermind (YC S24) – AI agent for discovering scientific papers</td>
      <td>HackerNews</td>
      <td>2024-07-25</td>
      <td>Hey HN! We’re Josh and Tom from Undermind (&lt;a href="https:&amp;#x2F;&amp;#x2F;www.undermind.ai&amp;#x2F;"&gt;https:&amp;#x2F;&amp;#x2F;www.undermind.ai&amp;#x2F;&lt;/a&gt;). We’re building a search engine for complex scientific research. There&amp;#x27;s a demo video at &lt;a href="https:&amp;#x2F;&amp;#x2F;www.loom.com&amp;#x2F;share&amp;#x2F;10067c49e4424b949a4b8c9fd8f3b12c?sid=5ee3cd96-2b05-4768-8856-cb1b83e40a70" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.loom.com&amp;#x2F;share&amp;#x2F;10067c49e4424b949a4b8c9fd8f3b12c?...&lt;/a&gt;, as well as example search resul</td>
      <td>https://news.ycombinator.com/item?id=41069909</td>
    </tr>
    <tr>
      <td>Solving the out-of-context chunk problem for RAG</td>
      <td>HackerNews</td>
      <td>2024-07-22</td>
      <td>Points: 260, Comments: 89</td>
      <td>https://d-star.ai/solving-the-out-of-context-chunk-problem-for-rag</td>
    </tr>
    <tr>
      <td>Txtai: Open-source vector search and RAG for minimalists</td>
      <td>HackerNews</td>
      <td>2024-07-21</td>
      <td>Points: 249, Comments: 55</td>
      <td>https://neuml.github.io/txtai/</td>
    </tr>
    <tr>
      <td>Show HN: How we leapfrogged traditional vector based RAG with a 'language map'</td>
      <td>HackerNews</td>
      <td>2024-07-18</td>
      <td>TL;DR: Vector-based RAG performs poorly for many real-world applications like codebase chats, and you should consider &amp;#x27;language maps&amp;#x27;.&lt;p&gt;Part of our mission at Mutable.ai is to make it much easier for developers to build and understand software. One of the natural ways to do this is to create a codebase chat, that answer questions about your repo and help you build features.&lt;p&gt;It might seem simple to plug in your codebase into a state-of-the-art LLM, but LLMs have two limitations that</td>
      <td>https://twitter.com/mutableai/status/1813815706783490055</td>
    </tr>
    <tr>
      <td>Dify vs. LangChain: Make the Choice Betweet Low Code and Python Library</td>
      <td>HackerNews</td>
      <td>2024-07-18</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://myscale.com/blog/dify-vs-langchain-comprehensive-analysis-ai-app-development/</td>
    </tr>
    <tr>
      <td>Show HN: Mutable.ai Codebase chat that uses a Wiki for RAG</td>
      <td>HackerNews</td>
      <td>2024-07-15</td>
      <td>Hi HN!&lt;p&gt;We wanted to introduce our codebase chat that uses a wiki of your repo to do retrieval instead of traditional vector or keyword RAG.&lt;p&gt;We have been pleasantly surprised by the quality of responses. We think creating a language knowledge base for LLMs to do RAG is the future. The way this works is we first write a Wikipedia style article on your codebase complete with diagrams and citations to your code.&lt;p&gt;We’ve run it on some of the most popular repos. If you want us to run in an open s</td>
      <td>https://wiki.mutable.ai/Dao-AILab/flash-attention</td>
    </tr>
    <tr>
      <td>Korvus: Single-Query RAG with Postgres</td>
      <td>HackerNews</td>
      <td>2024-07-11</td>
      <td>Points: 226, Comments: 39</td>
      <td>https://github.com/postgresml/korvus</td>
    </tr>
    <tr>
      <td>Knowledge Graphs in RAG: Hype vs. Ragas Analysis</td>
      <td>HackerNews</td>
      <td>2024-07-09</td>
      <td>Points: 145, Comments: 21</td>
      <td>https://aiencoder.substack.com/p/graphrag-analysis-part-1-how-indexing</td>
    </tr>
    <tr>
      <td>Txtai – A Strong Alternative to ChromaDB and LangChain for Vector Search and RAG</td>
      <td>HackerNews</td>
      <td>2024-07-05</td>
      <td>Points: 12, Comments: 1</td>
      <td>https://medium.com/neuml/vector-search-rag-landscape-a-review-with-txtai-a7f37ad0e187</td>
    </tr>
    <tr>
      <td>HuggingFace releases support for tool-use and RAG models</td>
      <td>HackerNews</td>
      <td>2024-07-03</td>
      <td>Points: 59, Comments: 0</td>
      <td>https://github.com/huggingface/transformers/releases/tag/v4.42.0</td>
    </tr>
    <tr>
      <td>Show HN: R2R V2 – A open source RAG engine with prod features</td>
      <td>HackerNews</td>
      <td>2024-06-26</td>
      <td>Hi HN! We&amp;#x27;re building R2R [&lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;SciPhi-AI&amp;#x2F;R2R"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;SciPhi-AI&amp;#x2F;R2R&lt;/a&gt;], an open source RAG answer engine that is built on top of Postgres+Neo4j. The best way to get started is with the docs - &lt;a href="https:&amp;#x2F;&amp;#x2F;r2r-docs.sciphi.ai&amp;#x2F;introduction"&gt;https:&amp;#x2F;&amp;#x2F;r2r-docs.sciphi.ai&amp;#x2F;introduction&lt;/a&gt;.&lt;p&gt;This is a major update from our V1 which we have spent the last 3 months intensely building after g</td>
      <td>https://github.com/SciPhi-AI/R2R</td>
    </tr>
    <tr>
      <td>Why we no longer use LangChain for building our AI agents</td>
      <td>HackerNews</td>
      <td>2024-06-20</td>
      <td>Points: 480, Comments: 297</td>
      <td>https://www.octomind.dev/blog/why-we-no-longer-use-langchain-for-building-our-ai-agents</td>
    </tr>
    <tr>
      <td>Dify vs. LangChain</td>
      <td>HackerNews</td>
      <td>2024-06-19</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://dify.ai/blog/dify-vs-langchain</td>
    </tr>
    <tr>
      <td>Query your database with AI using LangChain and Gradio</td>
      <td>HackerNews</td>
      <td>2024-06-17</td>
      <td>Points: 8, Comments: 0</td>
      <td>https://jstoppa.com/posts/artificial-intelligence/fundamentals/query-your-database-with-ai-using-langchain-and-gradio/post/</td>
    </tr>
    <tr>
      <td>Making my local LLM voice assistant faster and more scalable with RAG</td>
      <td>HackerNews</td>
      <td>2024-06-15</td>
      <td>Points: 122, Comments: 16</td>
      <td>https://johnthenerd.com/blog/faster-local-llm-assistant/</td>
    </tr>
    <tr>
      <td>Show HN: Pathway – Build Mission Critical ETL and RAG in Python (NATO, F1 Used)</td>
      <td>HackerNews</td>
      <td>2024-06-13</td>
      <td>Hi HN data folks,&lt;p&gt;I am excited to share Pathway, a Python data processing framework we built for ETL and RAG pipelines.&lt;p&gt;&lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;pathwaycom&amp;#x2F;pathway"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;pathwaycom&amp;#x2F;pathway&lt;/a&gt;&lt;p&gt;We started Pathway to solve event processing for IoT and geospatial indexing. Think freight train operations in unmapped depots bringing key merchandise from China to Europe. This was not something we could use Flink or Elastic for.&lt;p&gt;Then we a</td>
      <td>https://github.com/pathwaycom/pathway</td>
    </tr>
    <tr>
      <td>Breaking up is hard to do: Chunking in RAG applications</td>
      <td>HackerNews</td>
      <td>2024-06-08</td>
      <td>Points: 143, Comments: 43</td>
      <td>https://stackoverflow.blog/2024/06/06/breaking-up-is-hard-to-do-chunking-in-rag-applications/</td>
    </tr>
    <tr>
      <td>I rage-converted my RTX4090 into an eGPU</td>
      <td>HackerNews</td>
      <td>2024-06-07</td>
      <td>Points: 46, Comments: 31</td>
      <td>https://tanelpoder.com/posts/rtx4090-egpu/</td>
    </tr>
    <tr>
      <td>Show HN: Use functional tokens for AI agents to simplify app workflows</td>
      <td>HackerNews</td>
      <td>2024-06-07</td>
      <td>Hi HN! I want to share our latest project at NEXA AI. We developed AI agent foundation models designed to transform how developers create AI agent powered apps.&lt;p&gt;One major challenge we&amp;#x27;ve observed with current human-computer interactions is that many simple, one-step tasks become unnecessarily complex, multi-step workflows due to limitations of current GUIs. AI agents can solve this, but existing AI agent models are slow and costly.&lt;p&gt;To tackle these issues, we built lightweight AI agent m</td>
      <td>https://www.nexa4ai.com/octoverse</td>
    </tr>
    <tr>
      <td>Ask HN: Custom AI LLM Solutions vs. Open Source Tools?</td>
      <td>HackerNews</td>
      <td>2024-06-06</td>
      <td>Has anybody else chosen the route of developing a fully customized solution to integrate LLMs into their workflow instead of using some of the available options (AutoGPT, AgentGPT, LangChain, and others)?&lt;p&gt;I&amp;#x27;d love to hear about your experiences and any challenges you faced. So far, my most challenging issue has been creating an output format that doesn&amp;#x27;t fail 20-30% of the time.</td>
      <td>https://news.ycombinator.com/item?id=40596540</td>
    </tr>
    <tr>
      <td>Will AI Automation Render Data Science Jobs Obsolete?</td>
      <td>HackerNews</td>
      <td>2024-06-01</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://www.analyticsinsight.net/data-science/will-ai-automation-render-data-science-jobs-obsolete</td>
    </tr>
    <tr>
      <td>Better RAG Results with Reciprocal Rank Fusion and Hybrid Search</td>
      <td>HackerNews</td>
      <td>2024-05-30</td>
      <td>Points: 249, Comments: 57</td>
      <td>https://www.assembled.com/blog/better-rag-results-with-reciprocal-rank-fusion-and-hybrid-search</td>
    </tr>
    <tr>
      <td>Show HN: Autospec – open-source agent that generates E2E tests for your web app</td>
      <td>HackerNews</td>
      <td>2024-05-28</td>
      <td>Hi HN,&lt;p&gt;I&amp;#x27;m excited to share some early tinkering on a project, autospec, an open-source QA agent for web applications.&lt;p&gt;Right now it&amp;#x27;s not fully packaged for use, but I wanted to get the idea out early and am looking for design feedback, suggestions, and open source collaborators to join in. I wrote it over memorial weekend :)&lt;p&gt;autospec uses vision and text language models to explore and generate commonsense e2e tests for web applications.&lt;p&gt;The goal is human-like evaluation: asses</td>
      <td>https://github.com/zachblume/autospec</td>
    </tr>
    <tr>
      <td>Show HN: Agents in LangChain (Implementation in Python)</td>
      <td>HackerNews</td>
      <td>2024-05-26</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://github.com/TheAILearner/Langchain-Agents</td>
    </tr>
    <tr>
      <td>Show HN: JACoB – Open-Source AI Coding Agent for Real-World Productivity</td>
      <td>HackerNews</td>
      <td>2024-05-23</td>
      <td>Hi, we&amp;#x27;re Kevin, Chris, and Brian, the creators of JACoB (Just Another Coding Bot), an open-source AI coding agent designed to streamline the development process. As veteran developers, we know that while AI isn&amp;#x27;t perfect, it can be a valuable tool for tasks like code reviews, converting designs to React components, and writing high-quality GitHub issues. We’ve been building JACoB over the past year to assist with our real work, and today we’re open sourcing it under an Apache 2.0 lice</td>
      <td>https://github.com/jacob-ai-bot/jacob</td>
    </tr>
    <tr>
      <td>Top LangChain Alternatives for AI Development</td>
      <td>HackerNews</td>
      <td>2024-05-22</td>
      <td>Points: 9, Comments: 2</td>
      <td>https://www.mirascope.io/post/langchain-alternatives</td>
    </tr>
    <tr>
      <td>Systematically Improving Your RAG</td>
      <td>HackerNews</td>
      <td>2024-05-22</td>
      <td>Points: 176, Comments: 53</td>
      <td>https://jxnl.co/writing/2024/05/22/systematically-improving-your-rag/</td>
    </tr>
    <tr>
      <td>I want flexible queries, not RAG</td>
      <td>HackerNews</td>
      <td>2024-05-21</td>
      <td>Points: 237, Comments: 153</td>
      <td>https://win-vector.com/2024/05/21/i-want-flexible-queries-not-rag/</td>
    </tr>
    <tr>
      <td>Multi AI agent systems using OpenAI's assistants API</td>
      <td>HackerNews</td>
      <td>2024-05-17</td>
      <td>Points: 227, Comments: 80</td>
      <td>https://github.com/metaskills/experts</td>
    </tr>
    <tr>
      <td>Using Llamafiles for embeddings in local RAG applications</td>
      <td>HackerNews</td>
      <td>2024-05-16</td>
      <td>Points: 141, Comments: 23</td>
      <td>https://future.mozilla.org/news/llamafiles-for-embeddings-in-local-rag-applications/</td>
    </tr>
    <tr>
      <td>Exact binary vector search for RAG in 100 lines of Julia</td>
      <td>HackerNews</td>
      <td>2024-05-16</td>
      <td>Points: 180, Comments: 23</td>
      <td>https://domluna.com/blog/tiny-binary-rag</td>
    </tr>
    <tr>
      <td>The Age of Rage: Why Are People Are So Angry?</td>
      <td>HackerNews</td>
      <td>2024-05-12</td>
      <td>Points: 64, Comments: 135</td>
      <td>https://greyenlightenment.com/2024/05/11/the-age-of-rage-why-are-peopel-are-so-angry/</td>
    </tr>
    <tr>
      <td>RAG with PostgreSQL</td>
      <td>HackerNews</td>
      <td>2024-05-12</td>
      <td>Points: 46, Comments: 4</td>
      <td>https://pgdash.io/blog/rag-with-postgresql.html?p</td>
    </tr>
    <tr>
      <td>Citation Needed – Wikimedia Foundation's Experimental LLM/RAG Chrome Extension</td>
      <td>HackerNews</td>
      <td>2024-05-11</td>
      <td>Points: 153, Comments: 56</td>
      <td>https://chromewebstore.google.com/detail/wikipedia-citation-needed/kecnjhdipdihkibljeicopdcoinghmhj</td>
    </tr>
    <tr>
      <td>I Applied the Productized Service Concept to AI Automation</td>
      <td>HackerNews</td>
      <td>2024-05-08</td>
      <td>Points: 2, Comments: 1</td>
      <td>https://Brusselsai.agency</td>
    </tr>
    <tr>
      <td>Show HN: An Open Source project for enhancing AI Agents in taking action</td>
      <td>HackerNews</td>
      <td>2024-05-02</td>
      <td>Points: 47, Comments: 12</td>
      <td>https://github.com/npi-ai/npi</td>
    </tr>
    <tr>
      <td>Show HN: SpRAG – Open-source RAG implementation for challenging real-world tasks</td>
      <td>HackerNews</td>
      <td>2024-05-02</td>
      <td>Hey HN, I’m Zach from Superpowered AI (YC S22). We’ve been working in the RAG space for a little over a year now, and we’ve recently decided to open-source all of our core retrieval tech.&lt;p&gt;spRAG is a retrieval system that’s designed to handle complex real-world queries over dense text, like legal documents and financial reports. As far as we know, it produces the most accurate and reliable results of any RAG system for these kinds of tasks. For example, on FinanceBench, which is an especially c</td>
      <td>https://github.com/SuperpoweredAI/spRAG</td>
    </tr>
    <tr>
      <td>Show HN: I Built AuthGPTs,a Kobble Alternative Focused on GPTs and APIs</td>
      <td>HackerNews</td>
      <td>2024-04-29</td>
      <td>Hello hackers,&lt;p&gt;I&amp;#x27;ve launched AuthGPTS, a SaaS platform specifically designed to secure APIs&amp;#x2F;actions linked to GPTs. I&amp;#x27;m reaching out to gather your perspectives to enhance the platform.&lt;p&gt;Live Demo Link: &lt;a href="https:&amp;#x2F;&amp;#x2F;authgpts.com" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;authgpts.com&lt;/a&gt;&lt;p&gt;You are not required to register to Test the features.&lt;p&gt;Please post any problems or suggestions in the replies.</td>
      <td>https://www.authgpts.com/</td>
    </tr>
    <tr>
      <td>GraphRAG with LangChain and Neo4j</td>
      <td>HackerNews</td>
      <td>2024-04-28</td>
      <td>Points: 14, Comments: 3</td>
      <td>https://valentinaalto.medium.com/introducing-graphrag-with-langchain-and-neo4j-90446df17c1e</td>
    </tr>
    <tr>
      <td>How LangChain and ChatGPT plugins are getting hacked by Insecure Output Handling</td>
      <td>HackerNews</td>
      <td>2024-04-28</td>
      <td>Points: 5, Comments: 0</td>
      <td>https://journal.hexmos.com/insecure-output-handling/</td>
    </tr>
    <tr>
      <td>Show HN: Cognita – open-source RAG framework for modular applications</td>
      <td>HackerNews</td>
      <td>2024-04-27</td>
      <td>Hey HN, exciting news! Our RAG framework, Cognita (&lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;truefoundry&amp;#x2F;cognita"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;truefoundry&amp;#x2F;cognita&lt;/a&gt;), born from collaborations with diverse enterprises, is now open-source. Currently, it offers seamless integrations with Qdrant and SingleStore.&lt;p&gt;In recent weeks, numerous engineers have explored Cognita, providing invaluable insights and feedback. We deeply appreciate your input and encourage ongoing dialogue (sha</td>
      <td>https://github.com/truefoundry/cognita</td>
    </tr>
    <tr>
      <td>Opsberry.ai: AIOps automation for IT operational workflows</td>
      <td>HackerNews</td>
      <td>2024-04-25</td>
      <td>Points: 8, Comments: 1</td>
      <td>https://www.opsberry.ai/</td>
    </tr>
    <tr>
      <td>OSS Decorator to Trace LLM Apps – Integrated with LlamaIndex, LangChain, OAI SDK</td>
      <td>HackerNews</td>
      <td>2024-04-25</td>
      <td>Points: 6, Comments: 0</td>
      <td>https://langfuse.com/blog/2024-04-python-decorator</td>
    </tr>
    <tr>
      <td>Survey Study on AI Agent Architectures (2024)</td>
      <td>HackerNews</td>
      <td>2024-04-22</td>
      <td>Points: 77, Comments: 16</td>
      <td>https://arxiv.org/abs/2404.11584</td>
    </tr>
    <tr>
      <td>Beginner's Guide to Using Llama 3 with Ollama, Milvus, and LangChain</td>
      <td>HackerNews</td>
      <td>2024-04-21</td>
      <td>Points: 8, Comments: 0</td>
      <td>https://zilliz.com/blog/a-beginners-guide-to-using-llama-3-with-ollama-milvus-langchain</td>
    </tr>
    <tr>
      <td>Top AI-Driven Automations: Streamlining Tasks and Enhancing Business Processes</td>
      <td>HackerNews</td>
      <td>2024-04-20</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://n8n-automation.com/2024/04/20/top-5-ai-templates/</td>
    </tr>
    <tr>
      <td>Show HN: Auto Wiki v2 – Turn your codebase into a Wiki now with diagrams</td>
      <td>HackerNews</td>
      <td>2024-04-17</td>
      <td>Hi HN!&lt;p&gt;I&amp;#x27;m Omar from Mutable.ai. We previously (&lt;a href="https:&amp;#x2F;&amp;#x2F;news.ycombinator.com&amp;#x2F;item?id=38915999"&gt;https:&amp;#x2F;&amp;#x2F;news.ycombinator.com&amp;#x2F;item?id=38915999&lt;/a&gt;) introduced Auto Wiki (&lt;a href="http:&amp;#x2F;&amp;#x2F;wiki.mutable.ai&amp;#x2F;"&gt;http:&amp;#x2F;&amp;#x2F;wiki.mutable.ai&amp;#x2F;&lt;/a&gt;)), which transforms your codebase into Wiki-style articles with citations to your code. Now, it features code diagrams and the ability to use AI to revise your wiki. It’s our favorite way to lea</td>
      <td>https://wiki.mutable.ai/ollama/ollama</td>
    </tr>
    <tr>
      <td>Implment chat, RAG, and tools with ollama, OpenAI directly and with LangChain</td>
      <td>HackerNews</td>
      <td>2024-04-16</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://willschenk.com/labnotes/2024/programmatically_interacting_with_llms/</td>
    </tr>
    <tr>
      <td>Ask HN: Is RAG the Future of LLMs?</td>
      <td>HackerNews</td>
      <td>2024-04-14</td>
      <td>It seems to be in vogue that RAG is one of the best solutions to reduce the problem of hallucinations in LLMs.&lt;p&gt;What do you think? Are there any other alternatives or solutions on sight?</td>
      <td>https://news.ycombinator.com/item?id=40034972</td>
    </tr>
    <tr>
      <td>Show HN: Unified API to build AI automations, agents, and products</td>
      <td>HackerNews</td>
      <td>2024-04-10</td>
      <td>After repeatedly piecing together different services to build AI products, we&amp;#x27;ve started a collection of utility functions commonly used in building AI Automations, Agents, and products. You can access web scraping, google search, pdf extraction APIs + more all in one place and with a single subscription.</td>
      <td>https://news.ycombinator.com/item?id=39986538</td>
    </tr>
    <tr>
      <td>Dot – A standalone open source app meant for easy use of local LLMs and RAG</td>
      <td>HackerNews</td>
      <td>2024-04-07</td>
      <td>Points: 185, Comments: 42</td>
      <td>https://github.com/alexpinel/Dot</td>
    </tr>
    <tr>
      <td>Ask HN: How has AI/Automation reshaped your work experience?</td>
      <td>HackerNews</td>
      <td>2024-04-05</td>
      <td>How has AI and Automation changed how you approach tasks in your workday? Are there any specific tasks or processes that have been dramatically transformed?&lt;p&gt;What platforms and tools do you use the most?&lt;p&gt;Do you have an opinion on how you see AI and automation shaping the professional landscape in the future?</td>
      <td>https://news.ycombinator.com/item?id=39948026</td>
    </tr>
    <tr>
      <td>Boost your repository maintenance efficiency with AI-powered automation</td>
      <td>HackerNews</td>
      <td>2024-04-02</td>
      <td>Points: 1, Comments: 2</td>
      <td>https://github.com/jwcesign/gitautomator</td>
    </tr>
    <tr>
      <td>RAGFlow is an open-source RAG engine based on OCR and document parsing</td>
      <td>HackerNews</td>
      <td>2024-04-01</td>
      <td>Points: 230, Comments: 53</td>
      <td>https://github.com/infiniflow/ragflow</td>
    </tr>
    <tr>
      <td>Ask HN: Is anybody getting value from AI Agents? How so?</td>
      <td>HackerNews</td>
      <td>2024-03-31</td>
      <td>I saw a lot of initial buzz about the promise of agent based workflows and it seemed to be the obvious way to get LLMs to the edge of decision making and leverage many specialized models. It seems the chatter has died down but there are growing projects out there in the space. Before I invest the time to explore and work with tools I’d love some feedback from the community and if and how they are being used.</td>
      <td>https://news.ycombinator.com/item?id=39886178</td>
    </tr>
    <tr>
      <td>Show HN: Ragdoll Studio (fka Arthas.AI) is the FOSS alternative to character.ai</td>
      <td>HackerNews</td>
      <td>2024-03-31</td>
      <td>Points: 95, Comments: 24</td>
      <td>https://ragdoll-studio.vercel.app/</td>
    </tr>
    <tr>
      <td>Adaptive RAG – dynamic retrieval methods adjustment</td>
      <td>HackerNews</td>
      <td>2024-03-31</td>
      <td>Points: 126, Comments: 39</td>
      <td>https://arxiv.org/abs/2403.14403</td>
    </tr>
    <tr>
      <td>Show HN: Codel – Autonomous Open Source AI Developer Agent</td>
      <td>HackerNews</td>
      <td>2024-03-23</td>
      <td>Points: 48, Comments: 15</td>
      <td>https://github.com/semanser/codel</td>
    </tr>
    <tr>
      <td>Show HN: Ragas – Open-source library for evaluating RAG pipelines</td>
      <td>HackerNews</td>
      <td>2024-03-21</td>
      <td>Ragas is an open-source library for evaluating and testing RAG and other LLM applications. Github: &lt;a href="https:&amp;#x2F;&amp;#x2F;docs.ragas.io&amp;#x2F;en&amp;#x2F;stable&amp;#x2F;"&gt;https:&amp;#x2F;&amp;#x2F;docs.ragas.io&amp;#x2F;en&amp;#x2F;stable&amp;#x2F;&lt;/a&gt;, docs: &lt;a href="https:&amp;#x2F;&amp;#x2F;docs.ragas.io&amp;#x2F;"&gt;https:&amp;#x2F;&amp;#x2F;docs.ragas.io&amp;#x2F;&lt;/a&gt;.&lt;p&gt;Ragas provides you with different sets of metrics and methods like synthetic test data generation to help you evaluate your RAG applications. Ragas started off by scratchi</td>
      <td>https://github.com/explodinggradients/ragas</td>
    </tr>
    <tr>
      <td>If you are using LLM RAG – you should be doing RAFT</td>
      <td>HackerNews</td>
      <td>2024-03-19</td>
      <td>Points: 52, Comments: 13</td>
      <td>https://techcommunity.microsoft.com/t5/ai-ai-platform-blog/raft-a-new-way-to-teach-llms-to-be-better-at-rag/ba-p/4084674</td>
    </tr>
    <tr>
      <td>Show HN: AI Customer Support Agent Demo with LangChain4j and Spring AI</td>
      <td>HackerNews</td>
      <td>2024-03-14</td>
      <td>I&amp;#x27;ve been exploring AI libraries for Java recently and built a demo to showcase how to build a AI-powered full-stack app on Spring Boot.&lt;p&gt;Features: \n- RAG (Retrieval-Augmented Generation): uses a terms of service doc for context\n- Function calling: can fetch, modify, and cancel reservations as allowed by the terms of service\n- React UI with streaming answers and live database view\n- LangChain4j and Spring AI implementations&lt;p&gt;I hope it can be helpful to folks who want to explore AI tools i</td>
      <td>https://github.com/marcushellberg/java-ai-playground</td>
    </tr>
    <tr>
      <td>A generalist AI agent for 3D video games</td>
      <td>HackerNews</td>
      <td>2024-03-13</td>
      <td>Points: 51, Comments: 17</td>
      <td>https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/</td>
    </tr>
    <tr>
      <td>A generalist AI agent for 3D virtual environments</td>
      <td>HackerNews</td>
      <td>2024-03-13</td>
      <td>Points: 559, Comments: 310</td>
      <td>https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/</td>
    </tr>
    <tr>
      <td>A ragtag band of internet friends became the best at forecasting world events</td>
      <td>HackerNews</td>
      <td>2024-03-12</td>
      <td>Points: 229, Comments: 132</td>
      <td>https://www.vox.com/future-perfect/2024/2/13/24070864/samotsvety-forecasting-superforecasters-tetlock</td>
    </tr>
    <tr>
      <td>Source-available Rust-based RAG</td>
      <td>HackerNews</td>
      <td>2024-03-11</td>
      <td>Points: 58, Comments: 30</td>
      <td>https://github.com/devflowinc/trieve</td>
    </tr>
    <tr>
      <td>LangChain is slow – Scale to 1K's of bots with LionAGI</td>
      <td>HackerNews</td>
      <td>2024-03-06</td>
      <td>Points: 5, Comments: 2</td>
      <td>https://github.com/lion-agi/lionagi</td>
    </tr>
    <tr>
      <td>Pg_vectorize: Vector search and RAG on Postgres</td>
      <td>HackerNews</td>
      <td>2024-03-06</td>
      <td>Points: 295, Comments: 116</td>
      <td>https://github.com/tembo-io/pg_vectorize</td>
    </tr>
    <tr>
      <td>LangChain Explained</td>
      <td>HackerNews</td>
      <td>2024-03-06</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://upstash.com/blog/langchain-explained</td>
    </tr>
    <tr>
      <td>Launch HN: Greptile (YC W24) - RAG on codebases that actually works</td>
      <td>HackerNews</td>
      <td>2024-03-05</td>
      <td>Hi HN, we&amp;#x27;re the co-founders of Greptile, a tool that can accurately answer questions about complex codebases. Developers use us to spend less time wrestling with codebases and more time actually writing code. Here&amp;#x27;s a demo: &lt;a href="https:&amp;#x2F;&amp;#x2F;youtu.be&amp;#x2F;qI24eKO1YX0" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;youtu.be&amp;#x2F;qI24eKO1YX0&lt;/a&gt;. You can try it on 100 popular repos here: &lt;a href="https:&amp;#x2F;&amp;#x2F;app.greptile.com&amp;#x2F;repo"&gt;https:&amp;#x2F;&amp;#x2F;app.greptile.com&amp;#x2F;repo&lt;/a&gt;,</td>
      <td>https://news.ycombinator.com/item?id=39604961</td>
    </tr>
    <tr>
      <td>Show HN: I built a tool that lets you control Open-Interpreter with Excel</td>
      <td>HackerNews</td>
      <td>2024-03-01</td>
      <td>I&amp;#x27;ve been brewing up this tool on the side, and want to share it with the gang here, open source - of course.\nThe tool is AutoNL and the repo is: &lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;Actioninsight&amp;#x2F;AutoNL"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;Actioninsight&amp;#x2F;AutoNL&lt;/a&gt;&lt;p&gt;WHAT DOES IT DO:&lt;p&gt;AutoNL uses Open-Interpreter to automate multi-step tasks with the help of a simple spreadsheet. The basic insight here is OI, AutoGPT, etc all begin to break down when their planning enters a l</td>
      <td>https://github.com/Actioninsight/AutoNL</td>
    </tr>
    <tr>
      <td>The Future of Employment: Generative AI and Automation</td>
      <td>HackerNews</td>
      <td>2024-02-28</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.unaligned.io/p/the-future-of-employment-generative-ai-and-automation</td>
    </tr>
    <tr>
      <td>Show HN: R2R – Open-source framework for production-grade RAG</td>
      <td>HackerNews</td>
      <td>2024-02-26</td>
      <td>Hello HN, I&amp;#x27;m Owen from SciPhi (&lt;a href="https:&amp;#x2F;&amp;#x2F;www.sciphi.ai&amp;#x2F;" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.sciphi.ai&amp;#x2F;&lt;/a&gt;), a startup working on simplifying˛Retrieval-Augmented Generation (RAG). Today we’re excited to share R2R (&lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;SciPhi-AI&amp;#x2F;R2R"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;SciPhi-AI&amp;#x2F;R2R&lt;/a&gt;), an open-source framework that makes it simpler to develop and deploy production-grade RAG systems.&lt;p&gt;Just a quick reminder: RAG h</td>
      <td>https://github.com/SciPhi-AI/R2R</td>
    </tr>
    <tr>
      <td>Gemma, Ollama and LangChainGo</td>
      <td>HackerNews</td>
      <td>2024-02-23</td>
      <td>Points: 79, Comments: 22</td>
      <td>https://eli.thegreenplace.net/2024/gemma-ollama-and-langchaingo/</td>
    </tr>
    <tr>
      <td>AI Restaurant Menu with RAG</td>
      <td>HackerNews</td>
      <td>2024-02-18</td>
      <td>Points: 61, Comments: 53</td>
      <td>https://wandb.ai/byyoung3/ml-news/reports/Building-a-RAG-Based-Digital-Restaurant-Menu-with-LlamaIndex-and-W-B-Weave--Vmlldzo2NjE5Njkw</td>
    </tr>
    <tr>
      <td>Langchain $25M Series A, Langsmith GA</td>
      <td>HackerNews</td>
      <td>2024-02-15</td>
      <td>Points: 22, Comments: 3</td>
      <td>https://blog.langchain.dev/langsmith-ga/</td>
    </tr>
    <tr>
      <td>UFO: A UI-Focused AI Agent for Windows OS Interaction</td>
      <td>HackerNews</td>
      <td>2024-02-14</td>
      <td>Points: 87, Comments: 62</td>
      <td>https://github.com/microsoft/UFO</td>
    </tr>
    <tr>
      <td>Ask HN: What are some actual use cases of AI Agents right now?</td>
      <td>HackerNews</td>
      <td>2024-02-14</td>
      <td>There are quite a few start ups&amp;#x2F;OSS working on making LLMs do things on your behalf and not just complete your words. These projects range from small atomic actions to  web scrapers to more general ambitious assistants.&lt;p&gt;That all makes sense to me and I think is the right direction to be headed. However, it&amp;#x27;s been a bit since the inception of some of these projects&amp;#x2F;cool demos but I haven&amp;#x27;t seen anyone who uses agents as a core&amp;#x2F;regular part of their workflow.&lt;p&gt;I&amp;#x27;m</td>
      <td>https://news.ycombinator.com/item?id=39373662</td>
    </tr>
    <tr>
      <td>Show HN: LLMWare – Small Specialized Function Calling 1B LLMs for Multi-Step RAG</td>
      <td>HackerNews</td>
      <td>2024-02-11</td>
      <td>Hi, I was a corporate lawyer for many years working with a lot of financial services and insurance companies. In practicing law, I noticed there was a lot of repetition in the tasks I was working on even as a highly paid attorney that could be automated.&lt;p&gt;I wanted to solve the problem of dealing with a lot information and data in a practical way, using AI. This motivated me to start AI Bloks&amp;#x2F;LLMWare with my husband, who had a deep background in software and is a very early adopter of AI.&lt;p</td>
      <td>https://github.com/llmware-ai/llmware</td>
    </tr>
    <tr>
      <td>AgentHub – AI Automation Framework</td>
      <td>HackerNews</td>
      <td>2024-02-09</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://www.agenthub.dev/</td>
    </tr>
    <tr>
      <td>Launch HN: AgentHub (YC W24) – A no-code automation platform</td>
      <td>HackerNews</td>
      <td>2024-02-08</td>
      <td>Hey HN,&lt;p&gt;We’re Rahul and Max, co-founders of AgentHub.dev (&lt;a href="https:&amp;#x2F;&amp;#x2F;www.agenthub.dev&amp;#x2F;"&gt;https:&amp;#x2F;&amp;#x2F;www.agenthub.dev&amp;#x2F;&lt;/a&gt;). We automate repetitive workflows for businesses using LLM-powered automations. Our platform lets you build and host these automations to emulate employee workflows in a scalable way. Here’s a demo video: &lt;a href="https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=BD9aoyKPOjs" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;www.youtube.com&amp;#x2F;watch?v=BD9aoyK</td>
      <td>https://news.ycombinator.com/item?id=39302870</td>
    </tr>
    <tr>
      <td>Show HN: A more "conversational" AI assistant</td>
      <td>HackerNews</td>
      <td>2024-02-04</td>
      <td>What is special about this assistant is that it can leverage interfaces (web search, Python, etc) directly within its messages. For example, as it realizes that it needs to calculate 1 + 1, it might type &amp;quot;[PYTHON] print(1 + 1) [&amp;#x2F;PYTHON]&amp;quot;, and the output &amp;quot;[OUTPUT] 2 [&amp;#x2F;OUTPUT]&amp;quot; gets inserted right after, before the assistant continues streaming its answer.&lt;p&gt;The seamless insertion of code and output within the conversation - as opposed to the more standard approach (C</td>
      <td>https://github.com/ai-folks/saola</td>
    </tr>
    <tr>
      <td>Innovating S3 Bucket Retrieval: LangChain Community S3 Loaders with OpenAI API</td>
      <td>HackerNews</td>
      <td>2024-01-31</td>
      <td>Points: 7, Comments: 1</td>
      <td>https://blog.min.io/langchain-openai-s3-loader/</td>
    </tr>
    <tr>
      <td>LangChain Support for Workers AI, Vectorize and D1</td>
      <td>HackerNews</td>
      <td>2024-01-31</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://blog.cloudflare.com/langchain-support-for-workers-ai-vectorize-and-d1</td>
    </tr>
    <tr>
      <td>Defensive and Robust Design in AI Automation</td>
      <td>HackerNews</td>
      <td>2024-01-29</td>
      <td>Points: 2, Comments: 5</td>
      <td>https://medium.com/@kenny_v/defensive-and-robust-design-in-ai-automation-8e951c8e7fd7</td>
    </tr>
    <tr>
      <td>Show HN: Open-source Rule-based PDF parser for RAG</td>
      <td>HackerNews</td>
      <td>2024-01-24</td>
      <td>The PDF parser is a rule based parser which uses text co-ordinates (boundary box), graphics and font data. The PDF parser works off text layer and also offers a OCR option to automatically use OCR if there are scanned pages in your PDFs. The OCR feature is based off a modified version of tika which uses tesseract underneath.&lt;p&gt;The PDF Parser offers the following features:&lt;p&gt;* Sections and subsections along with their levels.\n* Paragraphs - combines lines.\n* Links between sections and paragraphs.</td>
      <td>https://github.com/nlmatics/nlm-ingestor</td>
    </tr>
    <tr>
      <td>WikiChat – a chatbot built on real-time Wikipedia updates, LangChain and AstraDB</td>
      <td>HackerNews</td>
      <td>2024-01-24</td>
      <td>Points: 31, Comments: 2</td>
      <td>https://www.datastax.com/events/wikichat-build-a-real-time-rag-app-on-wikipedia-with-langchain-and-vercel</td>
    </tr>
    <tr>
      <td>Show HN: VectorShift – AI automation no-code builder and Python SDK</td>
      <td>HackerNews</td>
      <td>2024-01-17</td>
      <td>We built an AI automation tool &amp;#x2F; app builder. Our site lets you create automations by composing &amp;quot;pipelines&amp;quot; that connect different units of functionality, including vector stores and third-party integrations. In addition to a drag-and-drop no-code editor on our website, we also wrote a Python library that allows you to create these tools through code.&lt;p&gt;We&amp;#x27;d love to hear your thoughts and feedback!</td>
      <td>https://www.vectorshift.ai/</td>
    </tr>
    <tr>
      <td>RAG Using Unstructured Data and Role of Knowledge Graphs</td>
      <td>HackerNews</td>
      <td>2024-01-15</td>
      <td>Points: 177, Comments: 31</td>
      <td>https://kuzudb.com/docusaurus/blog/llms-graphs-part-2/</td>
    </tr>
    <tr>
      <td>Accessible AI for Everyone</td>
      <td>HackerNews</td>
      <td>2024-01-08</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://github.com/Significant-Gravitas/AutoGPT</td>
    </tr>
    <tr>
      <td>Announcing LangChain v0.1.0</td>
      <td>HackerNews</td>
      <td>2024-01-08</td>
      <td>Points: 5, Comments: 0</td>
      <td>https://blog.langchain.dev/langchain-v0-1-0/</td>
    </tr>
    <tr>
      <td>LangChain Expression Language Explained</td>
      <td>HackerNews</td>
      <td>2024-01-06</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://www.pinecone.io/learn/series/langchain/langchain-expression-language/</td>
    </tr>
    <tr>
      <td>Use WASM as a cross-platform LLM backend for LangChain: Any LLMs on any device</td>
      <td>HackerNews</td>
      <td>2024-01-04</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://github.com/langchain-ai/langchain/pull/14787</td>
    </tr>
    <tr>
      <td>Show HN: Inbox Zero – open-source email assistant</td>
      <td>HackerNews</td>
      <td>2023-12-29</td>
      <td>Clean Up Your Inbox In Minutes\nNewsletter management, AI automation, and email analytics.\nInbox Zero is the open-source email app that puts you back in control of your inbox.</td>
      <td>https://www.getinboxzero.com</td>
    </tr>
    <tr>
      <td>Dark Visitors – A list of known AI agents on the internet</td>
      <td>HackerNews</td>
      <td>2023-12-28</td>
      <td>Points: 134, Comments: 66</td>
      <td>https://darkvisitors.com</td>
    </tr>
    <tr>
      <td>LangChain's State of AI 2023 [Report/Article]</td>
      <td>HackerNews</td>
      <td>2023-12-22</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://blog.langchain.dev/langchain-state-of-ai-2023/</td>
    </tr>
    <tr>
      <td>The Collaborative AI Automation: A New Way of Work to Achieve More with Less</td>
      <td>HackerNews</td>
      <td>2023-12-19</td>
      <td>Points: 1, Comments: 2</td>
      <td>https://blog.questflow.ai/p/the-collaborative-ai-automation-manifesto</td>
    </tr>
    <tr>
      <td>Build your first custom AI-powered application with LangChain</td>
      <td>HackerNews</td>
      <td>2023-12-17</td>
      <td>Points: 7, Comments: 0</td>
      <td>https://journal.hexmos.com/langchain/</td>
    </tr>
    <tr>
      <td>RAG to Riches</td>
      <td>HackerNews</td>
      <td>2023-12-16</td>
      <td>Points: 150, Comments: 72</td>
      <td>https://sourcegraph.com/blog/rag-to-riches</td>
    </tr>
    <tr>
      <td>Advancing AutoGen Towards AGI: Improving Open Source AI Agents</td>
      <td>HackerNews</td>
      <td>2023-12-15</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://medium.com/@headley.justin/from-autogpt-to-agi-the-evolutionary-journey-of-autogen-3fefee6d2cc0</td>
    </tr>
    <tr>
      <td>We built a Taylor Swift chatbot using AstraDB, Cohere, LangChain and Vercel AI</td>
      <td>HackerNews</td>
      <td>2023-12-13</td>
      <td>Points: 18, Comments: 1</td>
      <td>https://github.com/datastax/SwiftieGPT</td>
    </tr>
    <tr>
      <td>We Built a Taylor Swift Chatbot Using AstraDB, Cohere, LangChain and OpenAI</td>
      <td>HackerNews</td>
      <td>2023-12-13</td>
      <td>Points: 14, Comments: 0</td>
      <td>https://www.datastax.com/blog/using-astradb-vector-to-build-taylor-swift-chatbot</td>
    </tr>
    <tr>
      <td>AI automation to bury civilization in noise</td>
      <td>HackerNews</td>
      <td>2023-12-12</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.mindprison.cc/p/ai-automation-to-bury-civilization</td>
    </tr>
    <tr>
      <td>Rage: Fast web framework compatible with Rails</td>
      <td>HackerNews</td>
      <td>2023-12-05</td>
      <td>Points: 146, Comments: 112</td>
      <td>https://github.com/rage-rb/rage</td>
    </tr>
    <tr>
      <td>Haystack: A Great LangChain Alternative for RAG</td>
      <td>HackerNews</td>
      <td>2023-12-05</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://tonicai.substack.com/p/rag-evaluation-series-validating-961</td>
    </tr>
    <tr>
      <td>What Is Retrieval-Augmented Generation a.k.a. RAG?</td>
      <td>HackerNews</td>
      <td>2023-12-01</td>
      <td>Points: 84, Comments: 29</td>
      <td>https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/</td>
    </tr>
    <tr>
      <td>langchaingo – LangChain in Idiomatic Go</td>
      <td>HackerNews</td>
      <td>2023-11-30</td>
      <td>Points: 17, Comments: 2</td>
      <td>https://github.com/tmc/langchaingo</td>
    </tr>
    <tr>
      <td>Show HN: AutoGPT Agent as a Custom GPT</td>
      <td>HackerNews</td>
      <td>2023-11-28</td>
      <td>AutoGPT capability is now available as a custom GPT!&lt;p&gt;Say hello to AutoGPT Agent by AGI Layer. Now accessible to all ChatGPT Plus subscribers, this powerful custom GPT runs semi-autonomously to:&lt;p&gt;Plan and strategize\n Conduct research\n Use multi-modal tools&lt;p&gt;It harnesses the power of GPT-4, DALL·E 3 image generation, Browse with Bing web search, and Code Interpreter.&lt;p&gt;With AutoGPT Agent, you&amp;#x27;re in control. It operates semi-autonomously, allowing you to:&lt;p&gt;Approve next steps\n Intervene an</td>
      <td>https://chat.openai.com/g/g-POb5UhhJ6-autogpt-agent</td>
    </tr>
    <tr>
      <td>Agency: Pure Go LangChain Alternative</td>
      <td>HackerNews</td>
      <td>2023-11-27</td>
      <td>Points: 77, Comments: 39</td>
      <td>https://github.com/neurocult/agency</td>
    </tr>
    <tr>
      <td>Show HN: Neum AI – Open-source large-scale RAG framework</td>
      <td>HackerNews</td>
      <td>2023-11-21</td>
      <td>Over the last couple months we have been supporting developers in building large-scale RAG pipelines to process millions of pieces of data.&lt;p&gt;We documented our approach in an HN post (&lt;a href="https:&amp;#x2F;&amp;#x2F;news.ycombinator.com&amp;#x2F;item?id=37824547"&gt;https:&amp;#x2F;&amp;#x2F;news.ycombinator.com&amp;#x2F;item?id=37824547&lt;/a&gt;) a couple weeks ago. Today, we are open sourcing the framework we have developed.&lt;p&gt;The framework focuses on RAG data pipelines and provides scale, reliability, and data synchroniz</td>
      <td>https://github.com/NeumTry/NeumAI</td>
    </tr>
    <tr>
      <td>Flush AI – LangChain but for Stable Diffusion Workflows</td>
      <td>HackerNews</td>
      <td>2023-11-21</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://www.flushai.cloud/</td>
    </tr>
    <tr>
      <td>Infinite Context LLMs: Going Beyond RAG with Extended Minds</td>
      <td>HackerNews</td>
      <td>2023-11-13</td>
      <td>Points: 145, Comments: 42</td>
      <td>https://blog.normalcomputing.ai/posts/2023-09-12-supersizing-transformers/supersizing-transformers.html</td>
    </tr>
    <tr>
      <td>What's the difference between LangChain, llama indexand others like autollm?</td>
      <td>HackerNews</td>
      <td>2023-11-03</td>
      <td>Do you use any of these and if so which one is the best to use? I know there is some skepticism around using these wrappers in the first place.</td>
      <td>https://news.ycombinator.com/item?id=38126764</td>
    </tr>
    <tr>
      <td>Unveiling Ragna: An Open Source RAG-Based AI Orchestration Framework</td>
      <td>HackerNews</td>
      <td>2023-11-01</td>
      <td>Points: 44, Comments: 12</td>
      <td>https://quansight.com/post/unveiling-ragna-an-open-source-rag-based-ai-orchestration-framework-designed-to-scale-from-research-to-production/</td>
    </tr>
    <tr>
      <td>New: LangChain templates – fastest way to build a production-ready LLM app</td>
      <td>HackerNews</td>
      <td>2023-11-01</td>
      <td>Points: 137, Comments: 69</td>
      <td>https://github.com/langchain-ai/langchain/tree/master/templates</td>
    </tr>
    <tr>
      <td>GPT Pilot: A better variant of AutoGPT for devs?</td>
      <td>HackerNews</td>
      <td>2023-11-01</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://github.com/Pythagora-io/gpt-pilot</td>
    </tr>
    <tr>
      <td>An experimental open-source attempt to make GPT-4 autonomous</td>
      <td>HackerNews</td>
      <td>2023-10-29</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://github.com/Significant-Gravitas/AutoGPT</td>
    </tr>
    <tr>
      <td>Show HN: Demystifying Advanced RAG Pipelines</td>
      <td>HackerNews</td>
      <td>2023-10-28</td>
      <td>I&amp;#x27;ve built an advanced RAG (Retrieval-Augmented Generation) pipeline from scratch to demystify the complex mechanics of modern LLM-powered Question Answering systems. This repository features:&lt;p&gt;-- An implementation of a sub-question query engine from scratch to answer complex user questions.&lt;p&gt;-- Illustrative explanations that unveil the inner workings of the system.&lt;p&gt;-- An analysis of the challenges I faced while working with the system, like prompt engineering and cost estimation.&lt;p&gt;--</td>
      <td>https://github.com/pchunduri6/rag-demystified</td>
    </tr>
    <tr>
      <td>Create your own code interpreter with LangChain and LLM Sandboxes</td>
      <td>HackerNews</td>
      <td>2023-10-28</td>
      <td>Points: 6, Comments: 0</td>
      <td>https://e2b.dev/blog/build-ai-data-analyst-with-langchain-and-e2b</td>
    </tr>
    <tr>
      <td>Stack: The No-Code AI Automation Platform</td>
      <td>HackerNews</td>
      <td>2023-10-25</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://www.stack-ai.com/</td>
    </tr>
    <tr>
      <td>Fuyu-8B: A multimodal architecture for AI agents</td>
      <td>HackerNews</td>
      <td>2023-10-18</td>
      <td>Points: 205, Comments: 57</td>
      <td>https://www.adept.ai/blog/fuyu-8b</td>
    </tr>
    <tr>
      <td>AutoGPT Secures $12M Funding Round from Redpoint Ventures</td>
      <td>HackerNews</td>
      <td>2023-10-14</td>
      <td>Points: 3, Comments: 2</td>
      <td>https://twitter.com/Auto_GPT/status/1713009267194974333</td>
    </tr>
    <tr>
      <td>Ask HN: What should be MVP for "Lambda kind of server for simple AI automation"</td>
      <td>HackerNews</td>
      <td>2023-10-14</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://news.ycombinator.com/item?id=37877622</td>
    </tr>
    <tr>
      <td>Replacing Engineering Managers with AI Agents</td>
      <td>HackerNews</td>
      <td>2023-10-11</td>
      <td>Points: 61, Comments: 103</td>
      <td>https://www.engineeringcalm.com/p/replacing-engineering-managers-with</td>
    </tr>
    <tr>
      <td>Beyond Revenue Operations – AI, automation, and insights for business growth</td>
      <td>HackerNews</td>
      <td>2023-10-10</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://beyondrevenueoperations.substack.com/</td>
    </tr>
    <tr>
      <td>Why AutoGPT engineers ditched vector databases</td>
      <td>HackerNews</td>
      <td>2023-10-09</td>
      <td>Points: 109, Comments: 58</td>
      <td>https://dariuszsemba.com/blog/why-autogpt-engineers-ditched-vector-databases/</td>
    </tr>
    <tr>
      <td>RAG at scale: Synchronizing and ingesting billions of text embeddings</td>
      <td>HackerNews</td>
      <td>2023-10-09</td>
      <td>Points: 160, Comments: 55</td>
      <td>https://medium.com/@neum_ai/retrieval-augmented-generation-at-scale-building-a-distributed-system-for-synchronizing-and-eaa29162521</td>
    </tr>
    <tr>
      <td>Show HN: N8n’s LangChain integration makes it easy to build AI apps</td>
      <td>HackerNews</td>
      <td>2023-10-04</td>
      <td>Points: 11, Comments: 0</td>
      <td>https://n8n.io/langchain/</td>
    </tr>
    <tr>
      <td>LangChain4J, the Generative AI orchestration library for Java developers</td>
      <td>HackerNews</td>
      <td>2023-09-28</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://glaforge.dev/posts/2023/09/25/discovering-langchain4j/</td>
    </tr>
    <tr>
      <td>LangChain for Elixir</td>
      <td>HackerNews</td>
      <td>2023-09-28</td>
      <td>Points: 5, Comments: 1</td>
      <td>https://fly.io/phoenix-files/announcing-langchain-for-elixir/</td>
    </tr>
    <tr>
      <td>Timescale Vector (PostgreSQL) now available in LangChain</td>
      <td>HackerNews</td>
      <td>2023-09-26</td>
      <td>Points: 20, Comments: 0</td>
      <td>https://blog.langchain.dev/timescale-vector-x-langchain-making-postgresql-a-better-vector-database-for-ai-applications/</td>
    </tr>
    <tr>
      <td>RAG is more than just embedding search</td>
      <td>HackerNews</td>
      <td>2023-09-21</td>
      <td>Points: 151, Comments: 58</td>
      <td>https://jxnl.github.io/instructor/blog/2023/09/17/rag-is-more-than-just-embedding-search/</td>
    </tr>
    <tr>
      <td>Using AWS Serverless OpenSearch VectorDB+LangChain+OpenAI to Do RAG</td>
      <td>HackerNews</td>
      <td>2023-09-19</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://www.cianclarke.com/blog/aws-opensearch-and-langchain/</td>
    </tr>
    <tr>
      <td>Show HN: Dialoqbase – open-source chatbot creation platform (LangChain wrapper)</td>
      <td>HackerNews</td>
      <td>2023-09-19</td>
      <td>Hey HN,\nI have been working on a side project for the last 3 months, built around LangchainJS and pgvector. It now supports ChatGPT, Llama, Claude, and Bison models, and the bot can integrate with WhatsApp, Telegram, and Discord for now. I would really appreciate some feedback. Thanks!&lt;p&gt;repo: https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;n4ze3m&amp;#x2F;dialoqbase</td>
      <td>https://news.ycombinator.com/item?id=37573742</td>
    </tr>
    <tr>
      <td>Show HN: A murder mystery game built on an open-source gen-AI agent framework</td>
      <td>HackerNews</td>
      <td>2023-09-18</td>
      <td>Hey HN,&lt;p&gt;Michael and Scott here. We’re open-sourcing an interactive murder mystery featuring LLM-driven character agents. Solve the mystery by finding clues, taking notes, and interrogating agents. They all have distinct motives, personality, and can impact the game in different ways (attacking you, running away, etc). Try it out, it’s pretty fun!&lt;p&gt;We’re also open-sourcing the framework that we used to make and refine the agents. The goal is to create an intuitive interface for storytellers to</td>
      <td>https://www.gron.games/</td>
    </tr>
    <tr>
      <td>You don't need Langchain, here's how to do RAG without it</td>
      <td>HackerNews</td>
      <td>2023-09-18</td>
      <td>Points: 3, Comments: 2</td>
      <td>https://vigneshwarar.substack.com/p/hackernews-support-page-using-retrieval</td>
    </tr>
    <tr>
      <td>We improved LangChain ingest speed by 5x</td>
      <td>HackerNews</td>
      <td>2023-09-14</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://www.pinecone.io/blog/langchain-pinecone-upsert-faster/</td>
    </tr>
    <tr>
      <td>A Comprehensive Guide for Building Rag-Based LLM Applications</td>
      <td>HackerNews</td>
      <td>2023-09-14</td>
      <td>Points: 184, Comments: 48</td>
      <td>https://github.com/ray-project/llm-applications/blob/main/notebooks/rag.ipynb</td>
    </tr>
    <tr>
      <td>Show HN: Rivet – open-source AI Agent dev env with real-world applications</td>
      <td>HackerNews</td>
      <td>2023-09-08</td>
      <td>We just launched Rivet, the open-source visual AI programming environment! We built Rivet, because we were building complex AI Agent applications at Ironclad. It unlocked our abilities here, and we&amp;#x27;re excited to make available to the entire community.&lt;p&gt;Backstory: A few months ago, inspired by things like LangChain and LlamaIndex, we started building an AI agent that could work with legal contracts. Unfortunately, we couldn&amp;#x27;t just use retrieval augmented generation (RAG), because a lot</td>
      <td>https://rivet.ironcladapp.com/</td>
    </tr>
    <tr>
      <td>Is LangChain Pointless?</td>
      <td>HackerNews</td>
      <td>2023-09-07</td>
      <td>Points: 18, Comments: 2</td>
      <td>https://www.latent.space/p/langchain#details</td>
    </tr>
    <tr>
      <td>LLMs, RAG, and the missing storage layer for AI</td>
      <td>HackerNews</td>
      <td>2023-09-07</td>
      <td>Points: 151, Comments: 61</td>
      <td>https://blog.lancedb.com/llms-rag-the-missing-storage-layer-for-ai-28ded35fa984</td>
    </tr>
    <tr>
      <td>The Point of LangChain – With Harrison Chase of LangChain</td>
      <td>HackerNews</td>
      <td>2023-09-06</td>
      <td>Points: 9, Comments: 2</td>
      <td>https://www.latent.space/p/langchain</td>
    </tr>
    <tr>
      <td>Show HN: Rapidly copy webpage content to ChatGPT</td>
      <td>HackerNews</td>
      <td>2023-09-06</td>
      <td>Sometimes, we have questions about an article or technology that ChatGPT isn&amp;#x27;t updated on and lacks the context to answer. While other tools like autoGPT can be used for such inquiries, they require installation and setup, which can be time-consuming, especially for quick and simple queries.&lt;p&gt;That&amp;#x27;s why I&amp;#x27;ve developed a free Chrome extension that enables you to copy text from any webpage with just one click, making it a hassle-free and efficient way to gather information for use</td>
      <td>https://chrome.google.com/webstore/detail/osito-copy-page-content/affmabkbhigkclccdegijjbpnbgpbpem</td>
    </tr>
    <tr>
      <td>Ask HN: What open source LLM and diffusion projects do you rely on?</td>
      <td>HackerNews</td>
      <td>2023-09-01</td>
      <td>The a16z grant program is cool!&lt;p&gt;My favorites from the a16z batch were: TheBloke, vLLM, oobabooga.&lt;p&gt;My suggestions would be:&lt;p&gt;ExLlama, MLC LLM, an open source fork of text-generation-inference, AutoGPTQ.&lt;p&gt;What other projects do you rely on?</td>
      <td>https://news.ycombinator.com/item?id=37351436</td>
    </tr>
    <tr>
      <td>Ask HN: Does Your GitHub Repo Need a Landing Page</td>
      <td>HackerNews</td>
      <td>2023-08-27</td>
      <td>There are over 28 million public Github repos. Most of them don&amp;#x27;t have landing pages.&lt;p&gt;The README is great for explaining how it works, but it is not doing a great job to express the value proposition for potential end users.&lt;p&gt;I can see the value of a landing page. It opens your project to a wider audience, explains it in simple terms, invites users to engage (maybe through Discord invite) and possibly open monetization opportunities.&lt;p&gt;It is interesting to see what AutoGPT is doing on th</td>
      <td>https://news.ycombinator.com/item?id=37285261</td>
    </tr>
    <tr>
      <td>AI art – automation. A working artist's take [video]</td>
      <td>HackerNews</td>
      <td>2023-08-26</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.youtube.com/watch?v=d15C_UgVS-c</td>
    </tr>
    <tr>
      <td>Foundations of LLM app development with LangChain.js and Zep</td>
      <td>HackerNews</td>
      <td>2023-08-17</td>
      <td>Points: 6, Comments: 0</td>
      <td>https://blog.langchain.dev/zep-x-langsmith-foundations-of-llm-app-development-with-langchain-js-and-zep/</td>
    </tr>
    <tr>
      <td>Show HN: 10x-React-Engineer, Generate Entire React Codebases with Llama 2</td>
      <td>HackerNews</td>
      <td>2023-08-15</td>
      <td>Hi HN,&lt;p&gt;Yesterday I live streamed myself for 6 hours building this from scratch. It’s an AI agent that uses Llama 2 (so far the 13b chat model) to generate a full react codebase from a single prompt. It had a “dev loop” that iterates on your feedback and resolves dependencies.&lt;p&gt;In the end it kinda worked and I got excited so wanted to post here haha. Long story short a viewer on my discord suggested I build in of these and I just had to look into how these work (inspired by GPT Engineer and Au</td>
      <td>https://github.com/jawerty/10x-React-Engineer</td>
    </tr>
    <tr>
      <td>Show HN: Make Any Video Searchable</td>
      <td>HackerNews</td>
      <td>2023-08-14</td>
      <td>Hey HN friends! Yuval here, I&amp;#x27;m the maker of Conversational Demos:\nhttps:&amp;#x2F;&amp;#x2F;www.producthunt.com&amp;#x2F;posts&amp;#x2F;conversational-demos?utm_source=hn&lt;p&gt;This is a product with a bit of an interesting history: it evolved from my fascination with what we can do with LLMs and video.&lt;p&gt;My original (engineering) thinking was &amp;quot;how cool would it be if we let someone search through video with natural language&amp;quot;?&lt;p&gt;I built the original proof of concept for this over the weekend, taped</td>
      <td>https://news.ycombinator.com/item?id=37127803</td>
    </tr>
    <tr>
      <td>Ask HN: Who is deploying LLM agents in production?</td>
      <td>HackerNews</td>
      <td>2023-08-14</td>
      <td>There are quite some popular OS LLM agents like auto-gpt but they are still &amp;quot;experiments&amp;quot; even after interesting progress in LLMs like OpenAI function calling and increased context window.\nIs anyone deploying AI agents in production ? if so, which in usecases&amp;#x2F;domains?</td>
      <td>https://news.ycombinator.com/item?id=37120434</td>
    </tr>
    <tr>
      <td>LangChain Agent Simulation – Multi-Player Dungeons and Dragons</td>
      <td>HackerNews</td>
      <td>2023-08-14</td>
      <td>Points: 95, Comments: 29</td>
      <td>https://python.langchain.com/docs/use_cases/agent_simulations/two_player_dnd</td>
    </tr>
    <tr>
      <td>I created a LangChain alternative from scratch using Node and OceanBase</td>
      <td>HackerNews</td>
      <td>2023-08-14</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://medium.com/oceanbase-database/create-a-langchain-alternative-from-scratch-using-oceanbase-df66231834b9</td>
    </tr>
    <tr>
      <td>Ask HN: Are you training and running custom LLMs and how are you doing it?</td>
      <td>HackerNews</td>
      <td>2023-08-14</td>
      <td>I have been researching methods and projects built around training and running LLMs locally. I&amp;#x27;m interested in what others have been using on this front (including straight up Pytorch&amp;#x2F;Transformers). Here&amp;#x27;s what I&amp;#x27;ve gathered so far:&lt;p&gt;Engines&amp;#x2F;APIs:&lt;p&gt;&lt;pre&gt;&lt;code&gt;  - vllm: Inference and serving engine for LLMs (none quantized models only?) [1]\n  - ollama: Go project to run, create and share LLMs [2]\n  - llama.cpp: Inference of LLaMA models in C&amp;#x2F;C++ w&amp;#x2F;UI (includin</td>
      <td>https://news.ycombinator.com/item?id=37121384</td>
    </tr>
    <tr>
      <td>Python-Driven AI Automation – 33 Lessons</td>
      <td>HackerNews</td>
      <td>2023-08-11</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://www.udemy.com/course/python-driven-ai-automation-botcity-rpa-chatgpt-and-openai/?couponCode=3D55171791DA8EF7805B</td>
    </tr>
    <tr>
      <td>Show HN: Making videos searchable with LLMs (to get leads)</td>
      <td>HackerNews</td>
      <td>2023-08-11</td>
      <td>Hey HN friends! Yuval here, I&amp;#x27;m the maker of Conversational Demos:&lt;p&gt;https:&amp;#x2F;&amp;#x2F;www.producthunt.com&amp;#x2F;posts&amp;#x2F;conversational-demos?utm_source=hn&lt;p&gt;This is a product with a bit of an interesting history: it evolved from my fascination with what we can do with LLMs and video.&lt;p&gt;My original (engineering) thinking was &amp;quot;how cool would it be if we let someone search through video with natural language&amp;quot;?&lt;p&gt;I built the original proof of concept for this over the weekend, tape</td>
      <td>https://news.ycombinator.com/item?id=37090809</td>
    </tr>
    <tr>
      <td>Using Retrieval Augmented Generation (RAG) to clear our GitHub backlog</td>
      <td>HackerNews</td>
      <td>2023-08-10</td>
      <td>Points: 52, Comments: 7</td>
      <td>https://docs.sweep.dev/blogs/sweeps-core-algo</td>
    </tr>
    <tr>
      <td>LangchainJs Real-World Examples</td>
      <td>HackerNews</td>
      <td>2023-08-10</td>
      <td>Points: 27, Comments: 8</td>
      <td>https://github.com/amalshehu/langchain-js-realworld</td>
    </tr>
    <tr>
      <td>Show HN: Chat with your data using LangChain, Pinecone, and Airbyte</td>
      <td>HackerNews</td>
      <td>2023-08-08</td>
      <td>Hi HN,&lt;p&gt;A few of our team members at Airbyte (and Joe, who killed it!) recently played with building our own internal support chat bot, using Airbyte, Langchain, Pinecone and OpenAI, that would answer any questions we ask when developing a new connector on Airbyte.&lt;p&gt;As we prototyped it, we realized that it could be applied for many other use cases and sources of data, so... we created a tutorial that other community members can leverage [&lt;a href="http:&amp;#x2F;&amp;#x2F;airbyte.com&amp;#x2F;tutorials&amp;#x2</td>
      <td>https://airbyte.com/tutorials/chat-with-your-data-using-openai-pinecone-airbyte-and-langchain</td>
    </tr>
    <tr>
      <td>Show HN: Agentflow – Run Complex LLM Workflows from Simple JSON</td>
      <td>HackerNews</td>
      <td>2023-08-08</td>
      <td>So, it feels like this should exist. But I couldn&amp;#x27;t find it. So I tried to build it.&lt;p&gt;Agentflow lets you run complex LLM workflows from a simple JSON file. This can be as little as a list of tasks. Tasks can include variables, so you can reuse workflows for different outputs by providing different variable values. They can also include custom functions, so you can go beyond text generation to do anything you want to write a function for.&lt;p&gt;Someone might say: &amp;quot;Why not just use ChatGPT?</td>
      <td>https://github.com/simonmesmith/agentflow</td>
    </tr>
    <tr>
      <td>Chat with your data using OpenAI, Pinecone, Airbyte, LangChain</td>
      <td>HackerNews</td>
      <td>2023-08-08</td>
      <td>Points: 5, Comments: 0</td>
      <td>https://blog.langchain.dev/chat-with-your-data-using-openai-pinecone-airbyte-langchain/</td>
    </tr>
    <tr>
      <td>Show HN: A copy of LangChain swift for iOS or macOS applications</td>
      <td>HackerNews</td>
      <td>2023-08-06</td>
      <td>Points: 6, Comments: 1</td>
      <td>https://github.com/buhe/langchain-swift</td>
    </tr>
    <tr>
      <td>Ask HN: Have you successfully made any AI agent do useful work for you?</td>
      <td>HackerNews</td>
      <td>2023-08-04</td>
      <td>Since BabyAGI and AutoGPT, there have been countless forks and web products built based on them. Have you had any luck making these agents do any meaningful work for you? What was your use case?&lt;p&gt;So far every time I&amp;#x27;ve tried them, most likely outcome is that the agent keeps spinning wheels and never completes the task.</td>
      <td>https://news.ycombinator.com/item?id=37001319</td>
    </tr>
    <tr>
      <td>Show HN: Labpilot – comment driven development with Jupyter lab</td>
      <td>HackerNews</td>
      <td>2023-08-03</td>
      <td>Hello,&lt;p&gt;I&amp;#x27;ve been working on this project of mine these last couple of months, and with the release of Jupyter AI, I just had to go ahead and release my own project into the wild.&lt;p&gt;I call the paradigm, &amp;quot;comment driven development&amp;quot;. You use special comments, &amp;quot;#@&amp;quot; in the notebook cells, to steer the LLM to write the code you need. Got a bug in your code? - The debug feature takes the stacktrace and fixes the code for you. It also has a explain feature if some of the code</td>
      <td>https://github.com/aleksanderhan/labpilot</td>
    </tr>
    <tr>
      <td>Show HN: ModelFusion – Alternative to Langchain.js</td>
      <td>HackerNews</td>
      <td>2023-08-03</td>
      <td>Points: 5, Comments: 2</td>
      <td>https://modelfusion.dev/guide/</td>
    </tr>
    <tr>
      <td>Show HN: LLMFlows – LangChain alternative for explicit and transparent apps</td>
      <td>HackerNews</td>
      <td>2023-07-29</td>
      <td>Hi HN! Over the last several weekends, I&amp;#x27;ve been building LLMFlows as an alternative to langchain.&lt;p&gt;There&amp;#x27;s been a lot of discussion on the shortcomings of langchain in the past few weeks, but when I first tried it in March, I thought there are 3 main problems:\n1. Too many abstractions\n2. Hidden prompts and opinionated logic in chains which makes it hard to customize\n3. Hard to debug&lt;p&gt;This inspired me to try and build a framework that solves these 3 issues, and therefore I started bu</td>
      <td>https://github.com/stoyan-stoyanov/llmflows</td>
    </tr>
    <tr>
      <td>Cohere.ai raised $270M to build AutoGTP 2.0 for enterprise?</td>
      <td>HackerNews</td>
      <td>2023-07-29</td>
      <td>Points: 2, Comments: 1</td>
      <td>https://techcrunch.com/2023/06/08/ai-startup-cohere-now-valued-at-over-2-1b-raises-270m/</td>
    </tr>
    <tr>
      <td>Namibian fairy circle debate rages on: Sand termites or Turing mechanism?</td>
      <td>HackerNews</td>
      <td>2023-07-27</td>
      <td>Points: 94, Comments: 42</td>
      <td>https://arstechnica.com/science/2023/07/the-namibian-fairy-circle-debate-rages-on-could-it-be-sand-termites-after-all/</td>
    </tr>
    <tr>
      <td>Chidori – Declarative framework for AI agents (Rust, Python, and Node.js)</td>
      <td>HackerNews</td>
      <td>2023-07-27</td>
      <td>Points: 153, Comments: 39</td>
      <td>https://github.com/ThousandBirdsInc/chidori</td>
    </tr>
    <tr>
      <td>Show HN: LLFn – A Light-Weight Framework for Building AI (LangChain Alternative)</td>
      <td>HackerNews</td>
      <td>2023-07-27</td>
      <td>Hi HN,&lt;p&gt;After building a few AI apps with LLMs and LangChain (including &lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;orgexyz&amp;#x2F;BlockAGI"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;orgexyz&amp;#x2F;BlockAGI&lt;/a&gt;), we finally felt that it&amp;#x27;s time for a change.&lt;p&gt;LLFn was born out of our necessity to iterate faster on building AI agents. We found that the current frameworks are convoluted with complex abstractions which over time has present more of a road block than saving our time.&lt;p&gt;LLFn is an open-sour</td>
      <td>https://github.com/orgexyz/LLFn</td>
    </tr>
    <tr>
      <td>Ask HN: Name an AI agent that you find useful</td>
      <td>HackerNews</td>
      <td>2023-07-25</td>
      <td>It all started with BabyAGI and AutoGPT, and since then there are already dozens of AI agents.&lt;p&gt;Which one did you try? \nDid you find any useful ones?&lt;p&gt;What is missing? What technical capability do you think is missing?</td>
      <td>https://news.ycombinator.com/item?id=36868185</td>
    </tr>
    <tr>
      <td>Show HN: RAGstack – private ChatGPT for enterprise VPCs, built with Llama 2</td>
      <td>HackerNews</td>
      <td>2023-07-20</td>
      <td>Hey hacker news,&lt;p&gt;We’re the cofounders at Psychic.dev (&lt;a href="http:&amp;#x2F;&amp;#x2F;psychic.dev"&gt;http:&amp;#x2F;&amp;#x2F;psychic.dev&lt;/a&gt;) where we help companies connect LLMs to private data. With the launch of Llama 2, we think it’s finally viable to self-host an internal application that’s on-par with ChatGPT, so we did exactly that and made it an open source project.&lt;p&gt;We also included a vector DB and API server so you can upload files and connect Llama 2 to your own data.&lt;p&gt;The RAG in RAGstack stands</td>
      <td>https://github.com/psychic-api/rag-stack</td>
    </tr>
    <tr>
      <td>A Closer Look at LangChain: The Guide That's Been Missing</td>
      <td>HackerNews</td>
      <td>2023-07-19</td>
      <td>Points: 7, Comments: 4</td>
      <td>https://www.commandbar.com/blog/langchain-guide</td>
    </tr>
    <tr>
      <td>AutoChain, lightweight and testable alternative to LangChain</td>
      <td>HackerNews</td>
      <td>2023-07-18</td>
      <td>Points: 211, Comments: 36</td>
      <td>https://github.com/Forethought-Technologies/AutoChain</td>
    </tr>
    <tr>
      <td>Comparison between llama.cpp, AutoGPTQ, ExLlama, etc. perplexities</td>
      <td>HackerNews</td>
      <td>2023-07-18</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://oobabooga.github.io/blog/posts/perplexities/</td>
    </tr>
    <tr>
      <td>The Future of LLMs with Arthur, MosaicML, LangChain, and Weaviate [video]</td>
      <td>HackerNews</td>
      <td>2023-07-17</td>
      <td>Points: 64, Comments: 2</td>
      <td>https://www.youtube.com/watch?v=TXMUXeml9JY</td>
    </tr>
    <tr>
      <td>A direct comparison between llama.cpp, AutoGPTQ, ExLlama, and transformers perp</td>
      <td>HackerNews</td>
      <td>2023-07-16</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://oobabooga.github.io/blog/posts/perplexities/</td>
    </tr>
    <tr>
      <td>The Problem with LangChain</td>
      <td>HackerNews</td>
      <td>2023-07-14</td>
      <td>Points: 268, Comments: 92</td>
      <td>https://minimaxir.com/2023/07/langchain-problem/</td>
    </tr>
    <tr>
      <td>Hacking LangChain for fun and profit</td>
      <td>HackerNews</td>
      <td>2023-07-10</td>
      <td>Points: 79, Comments: 24</td>
      <td>https://blog.kevinhu.me/2023/07/10/hacking-langchain-for-fun-and-profit/</td>
    </tr>
    <tr>
      <td>Langchain Is Pointless</td>
      <td>HackerNews</td>
      <td>2023-07-08</td>
      <td>Points: 386, Comments: 178</td>
      <td>https://old.reddit.com/r/LangChain/comments/13fcw36/langchain_is_pointless/</td>
    </tr>
    <tr>
      <td>LangChain alternative using FP approach</td>
      <td>HackerNews</td>
      <td>2023-07-07</td>
      <td>Points: 6, Comments: 0</td>
      <td>https://github.com/rogeriochaves/litechain</td>
    </tr>
    <tr>
      <td>AI agents that “self-reflect” perform better in changing environments</td>
      <td>HackerNews</td>
      <td>2023-07-06</td>
      <td>Points: 215, Comments: 43</td>
      <td>https://hai.stanford.edu/news/ai-agents-self-reflect-perform-better-changing-environments</td>
    </tr>
    <tr>
      <td>Can AI tools detect AI created content?</td>
      <td>HackerNews</td>
      <td>2023-07-05</td>
      <td>There are tools like chatgpt, chatsonic, google bard, autogpt, mygpt, embedai tools.</td>
      <td>https://news.ycombinator.com/item?id=36598488</td>
    </tr>
    <tr>
      <td>Introducing LangChain.dart</td>
      <td>HackerNews</td>
      <td>2023-07-03</td>
      <td>Points: 3, Comments: 2</td>
      <td>https://blog.langchaindart.com/introducing-langchain-dart-6b1d34fc41ef</td>
    </tr>
    <tr>
      <td>My new AI browser automation product, thought [video]</td>
      <td>HackerNews</td>
      <td>2023-07-03</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://www.youtube.com/watch?v=Hug-KvYFTvc</td>
    </tr>
    <tr>
      <td>Show HN: A package manager for Autonomous AI tools</td>
      <td>HackerNews</td>
      <td>2023-07-03</td>
      <td>I&amp;#x27;ve just started AutoPack, which is a repository and python package of tools designed specifically for autonomous AI systems. Right now it&amp;#x27;s just LangChain but adding Auto-GPT and others isn&amp;#x27;t very hard.</td>
      <td>https://autopack.ai/announcement</td>
    </tr>
    <tr>
      <td>How to Fix AutoGPT and Build a Proto-AGI</td>
      <td>HackerNews</td>
      <td>2023-07-02</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://lorenzopieri.com/autogpt_fix/</td>
    </tr>
    <tr>
      <td>AutoGPT is the most popular useless project on GitHub</td>
      <td>HackerNews</td>
      <td>2023-06-30</td>
      <td>Points: 13, Comments: 0</td>
      <td>https://news.agpt.co/</td>
    </tr>
    <tr>
      <td>LangSmith: LangChain's LLM Debugger, Evaluator, &amp; Monitoring Tool</td>
      <td>HackerNews</td>
      <td>2023-06-29</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://www.langchain.plus/docs/</td>
    </tr>
    <tr>
      <td>Hacking Auto-GPT and escaping its Docker container</td>
      <td>HackerNews</td>
      <td>2023-06-29</td>
      <td>Points: 4, Comments: 2</td>
      <td>https://positive.security/blog/auto-gpt-rce</td>
    </tr>
    <tr>
      <td>Ranking Industries by Their Potential for AI Automation</td>
      <td>HackerNews</td>
      <td>2023-06-28</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.visualcapitalist.com/sp/ranking-industries-by-their-potential-for-ai-automation/</td>
    </tr>
    <tr>
      <td>LangChain Tutorial – How to Build a Custom-Knowledge Chatbot</td>
      <td>HackerNews</td>
      <td>2023-06-27</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://www.freecodecamp.org/news/langchain-how-to-create-custom-knowledge-chatbots/</td>
    </tr>
    <tr>
      <td>LangChain Guide to Get Started</td>
      <td>HackerNews</td>
      <td>2023-06-22</td>
      <td>Points: 29, Comments: 8</td>
      <td>https://shurutech.com/getting-started-langchain-with-examples/</td>
    </tr>
    <tr>
      <td>How to Connect LLM to SQL Database with LangChain SQLChain</td>
      <td>HackerNews</td>
      <td>2023-06-22</td>
      <td>Points: 8, Comments: 0</td>
      <td>https://medium.com/dataherald/how-to-langchain-sqlchain-c7342dd41614</td>
    </tr>
    <tr>
      <td>Ask HN: I want to learn game theory in an interactive way. Reccomendations?</td>
      <td>HackerNews</td>
      <td>2023-06-21</td>
      <td>I got really excited with the whole game theory concepts after auto-gpt got hyped. I instantly remembered that the concept of &amp;quot;agents&amp;quot; is coming from game theory and it is a very valuable subject to learn for the further AI development.&lt;p&gt;Right now I take coursera stanford course. But I really miss the interactive learning. Like brilliant.org style.&lt;p&gt;Anyone knows such a resource?</td>
      <td>https://news.ycombinator.com/item?id=36418004</td>
    </tr>
    <tr>
      <td>AI Leader Proposes a New Kind of Turing Test for Chatbots (The Auto-GPT Way)</td>
      <td>HackerNews</td>
      <td>2023-06-20</td>
      <td>Points: 2, Comments: 1</td>
      <td>https://www.bloomberg.com/news/newsletters/2023-06-20/ai-turing-test-for-chatgpt-or-bard-proposed-by-mustafa-suleyman</td>
    </tr>
    <tr>
      <td>The Cloud Whitepaper Index: Langchain, Pinecone and ChatGPT Powered Q&amp;A</td>
      <td>HackerNews</td>
      <td>2023-06-14</td>
      <td>Points: 5, Comments: 1</td>
      <td>https://www.withcoherence.com/post/announcing-the-cloud-whitepaper-index</td>
    </tr>
    <tr>
      <td>Notes from the AutoGPT Frontier</td>
      <td>HackerNews</td>
      <td>2023-06-13</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://taoofmac.com/space/notes/2023/06/13/2030</td>
    </tr>
    <tr>
      <td>Ask HN: Top of Funnel Fraud Solutions</td>
      <td>HackerNews</td>
      <td>2023-06-12</td>
      <td>Hey all, I am looking for a little advice on a lightweight SaaS offering to protect my top-of-funnel user sign-ups coming from my website.  Recently, we’ve been getting more and more bad signups with fake email, etc. It could be a coincidence, but it seems to coincide with the recent wave of ChatGPT (not sure if relevant - maybe the recent advancements with AutoGPT..?).&lt;p&gt;I was trying to find something that I could put in front of my user sign-up flows to see if I could weed them out more (save</td>
      <td>https://news.ycombinator.com/item?id=36293857</td>
    </tr>
    <tr>
      <td>ChatPDF-GPT: An Educational Project Using LangChain and OpenAI to Chat with PDFs</td>
      <td>HackerNews</td>
      <td>2023-06-11</td>
      <td>Points: 3, Comments: 2</td>
      <td>https://github.com/anis-marrouchi/chatpdf-gpt</td>
    </tr>
    <tr>
      <td>iOS 17 automatically removes tracking parameters from links you click on</td>
      <td>HackerNews</td>
      <td>2023-06-08</td>
      <td>Points: 880, Comments: 318</td>
      <td>https://9to5mac.com/2023/06/08/ios-17-link-tracking-protection/</td>
    </tr>
    <tr>
      <td>Reverse-Engineering the Twitter Algorithm with LangChain</td>
      <td>HackerNews</td>
      <td>2023-06-08</td>
      <td>Points: 7, Comments: 0</td>
      <td>https://notes.aimodels.fyi/a-plain-english-guide-to-reverse-engineering-the-twitter-algorithm-with-langchain-activeloop-and-deepinfra/</td>
    </tr>
    <tr>
      <td>Show HN: I got fed up with LangChain so I made a simple alternative for AI apps</td>
      <td>HackerNews</td>
      <td>2023-06-08</td>
      <td>Points: 6, Comments: 2</td>
      <td>https://github.com/minimaxir/simpleaichat</td>
    </tr>
    <tr>
      <td>Vectara Now Integrated into LangChain</td>
      <td>HackerNews</td>
      <td>2023-06-06</td>
      <td>Points: 6, Comments: 1</td>
      <td>https://blog.langchain.dev/langchain-vectara-better-together/</td>
    </tr>
    <tr>
      <td>AutoGPT – The Autonomous AI Agent</td>
      <td>HackerNews</td>
      <td>2023-06-05</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://blogs.infosys.com/digital-experience/emerging-technologies/autogpt-the-autonomous-ai-agent.html</td>
    </tr>
    <tr>
      <td>AI Report #4: AutoGPT And Open-source lags behind Part 2</td>
      <td>HackerNews</td>
      <td>2023-06-04</td>
      <td>Points: 60, Comments: 36</td>
      <td>https://theaireport.substack.com/p/ai-report-4-autogpt-and-open-source</td>
    </tr>
    <tr>
      <td>LangChain: The Trendiest Web Framework of 2023, Thanks to AI</td>
      <td>HackerNews</td>
      <td>2023-06-02</td>
      <td>Points: 14, Comments: 1</td>
      <td>https://thenewstack.io/langchain-the-trendiest-web-framework-of-2023-thanks-to-ai/</td>
    </tr>
    <tr>
      <td>Show HN: Tutor-GPT – A LangChain application for tutoring</td>
      <td>HackerNews</td>
      <td>2023-06-02</td>
      <td>Points: 15, Comments: 2</td>
      <td>https://www.plasticlabs.ai/blog/Open-Sourcing-Tutor-GPT/</td>
    </tr>
    <tr>
      <td>Different Levels of “AI Safety”</td>
      <td>HackerNews</td>
      <td>2023-05-30</td>
      <td>I think the term &amp;quot;AI Safety&amp;quot; is so overloaded right now that large amounts of conversation on the topic are essentially meaningless. The reason for this is that what AI Safety means is highly dependent on the level of intelligence your AI has. This point and the rest of this post may be obvious to most of the readers, but even then, someone still has to say it.&lt;p&gt;I would like to present a loose definition of 5 levels of AI models and the corresponding important concepts in AI safety&amp;#x</td>
      <td>https://news.ycombinator.com/item?id=36127880</td>
    </tr>
    <tr>
      <td>Agent GPT – Assemble, configure, and deploy autonomous AI Agents in the browser</td>
      <td>HackerNews</td>
      <td>2023-05-26</td>
      <td>Points: 98, Comments: 44</td>
      <td>https://agentgpt.reworkd.ai/</td>
    </tr>
    <tr>
      <td>Debugging the Internet with AI Agents – With Itamar Friedman of AutoGPT</td>
      <td>HackerNews</td>
      <td>2023-05-25</td>
      <td>Points: 2, Comments: 2</td>
      <td>https://www.latent.space/p/codium-agents#details</td>
    </tr>
    <tr>
      <td>How to Use Auto-GPT</td>
      <td>HackerNews</td>
      <td>2023-05-23</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://thesequence.substack.com/p/guest-post-how-to-customize-auto</td>
    </tr>
    <tr>
      <td>Show HN: Willow Inference Server: Optimized ASR/TTS/LLM for Willow/WebRTC/REST</td>
      <td>HackerNews</td>
      <td>2023-05-23</td>
      <td>Hey HN!&lt;p&gt;Willow Inference Server (WIS) is a focused and highly optimized language inference server implementation. Our goal is to &amp;quot;automagically&amp;quot; enable performant, cost-effective self-hosting of released state of the art&amp;#x2F;best of breed models to enable speech and language tasks:&lt;p&gt;Primarily targeting CUDA (works on CPU too) with support for low-end (cheap) devices such as the Tesla P4, GTX 1060, and up. Don&amp;#x27;t worry - it screams on an RTX 4090 too! (See benchmarks on Github).</td>
      <td>https://github.com/toverainc/willow-inference-server</td>
    </tr>
    <tr>
      <td>Show HN: Apply plugins to LLMs in one line of code with PlugnPlai and Langchain</td>
      <td>HackerNews</td>
      <td>2023-05-21</td>
      <td>Hey HackerNews, I&amp;#x27;m building an open-source library aiming to make it very easy for anyone to use plugins with any LLM (plugins as defined by OpenAI).&lt;p&gt;I just finished this very simple tutorial: &lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;edreisMD&amp;#x2F;plugnplai&amp;#x2F;blob&amp;#x2F;master&amp;#x2F;examples&amp;#x2F;apply_plugins_three_steps.ipynb"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;edreisMD&amp;#x2F;plugnplai&amp;#x2F;blob&amp;#x2F;master&amp;#x2F;examples&amp;#x2F;a...&lt;/a&gt;. And would love to get some feedback, and suggesti</td>
      <td>https://twitter.com/edreisMD/status/1659962295764791297</td>
    </tr>
    <tr>
      <td>Autogit: Never forget to pull the latest changes again</td>
      <td>HackerNews</td>
      <td>2023-05-20</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://www.zackproser.com/blog/autogit-introduction</td>
    </tr>
    <tr>
      <td>Answering Question About Your Documents Using LangChain (and Not OpenAI)</td>
      <td>HackerNews</td>
      <td>2023-05-19</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://artificialcorner.com/answering-question-about-your-documents-using-langchain-and-not-openai-2f75b8d639ae</td>
    </tr>
    <tr>
      <td>LangChain: The Missing Manual</td>
      <td>HackerNews</td>
      <td>2023-05-19</td>
      <td>Points: 164, Comments: 43</td>
      <td>https://www.pinecone.io/learn/langchain/</td>
    </tr>
    <tr>
      <td>Ask HN: How dangerous is Auto-GPT?</td>
      <td>HackerNews</td>
      <td>2023-05-19</td>
      <td>I&amp;#x27;m talking about this project: https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;Significant-Gravitas&amp;#x2F;Auto-GPT&lt;p&gt;It puts LLM&amp;#x27;s programming capabilities in a feedback loop with the real world in order to achieve arbitrary goals. In my opinion, this has the potential to become a very powerful and therefore dangerous tool.&lt;p&gt;I fear that people with both good and bad intentions give commands that do large scale harm. How do you see it?</td>
      <td>https://news.ycombinator.com/item?id=36006461</td>
    </tr>
    <tr>
      <td>Using LangChainJS and Cloudflare Workers together</td>
      <td>HackerNews</td>
      <td>2023-05-18</td>
      <td>Points: 83, Comments: 17</td>
      <td>https://blog.cloudflare.com/langchain-and-cloudflare/</td>
    </tr>
    <tr>
      <td>Show HN: AutoGPT-as-a-Service</td>
      <td>HackerNews</td>
      <td>2023-05-16</td>
      <td>Use AutoGPT as WebSocket APIs. Integrate with your existing application stack. Enables human feedback to provide direction&amp;#x2F;minimize hallucination with real-time streaming.</td>
      <td>https://github.com/jina-ai/langchain-serve</td>
    </tr>
    <tr>
      <td>Autogpt</td>
      <td>HackerNews</td>
      <td>2023-05-15</td>
      <td>Points: 4, Comments: 1</td>
      <td>https://autogpt.thesamur.ai/</td>
    </tr>
    <tr>
      <td>Teach-O-Matic: AI generated how-to videos, powered by Replicate and LangChain</td>
      <td>HackerNews</td>
      <td>2023-05-15</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://colab.research.google.com/drive/1pykPRbF0PhMdmUi3X-i8sCL5jnUQxSwb?usp=sharing</td>
    </tr>
    <tr>
      <td>How does AutoGPT work under the hood?</td>
      <td>HackerNews</td>
      <td>2023-05-14</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://ad-absurdum.me/blog/how-autogpt-works-under-the-hood</td>
    </tr>
    <tr>
      <td>As COVID raged in New York hospitals, executives pocketed $73M in bonuses (2022)</td>
      <td>HackerNews</td>
      <td>2023-05-14</td>
      <td>Points: 110, Comments: 66</td>
      <td>https://www.lohud.com/in-depth/news/2022/09/14/ny-hospital-executives-paid-millions-in-bonuses-salary-as-covid-raged/65411150007/</td>
    </tr>
    <tr>
      <td>Ask HN: Hype aside, what practical issues come up when building LLM-based apps?</td>
      <td>HackerNews</td>
      <td>2023-05-12</td>
      <td>Prototyping an application with an LLM is pretty straightforward task these days: try out a few prompts and paste in some context and see if it seems to work.&lt;p&gt;After trying to build something more substantial (a script that takes a text description and attempts to scrape that info out of a collection of PDFs&amp;#x2F;websites), I realized there are a number of annoyances with getting this out of the prototype stage:&lt;p&gt;* Parsing prompt responses to ensure they match my expected schema (e.g. I want X</td>
      <td>https://news.ycombinator.com/item?id=35910512</td>
    </tr>
    <tr>
      <td>Show HN: A Jupyter notebook for creating how-to videos with GPT4 and LangChain</td>
      <td>HackerNews</td>
      <td>2023-05-12</td>
      <td>Points: 4, Comments: 6</td>
      <td>https://teachomatic.net</td>
    </tr>
    <tr>
      <td>Show HN: AutoGPT for Ethereum</td>
      <td>HackerNews</td>
      <td>2023-05-11</td>
      <td>I built this on a weekend, I would love to get some feedback on the app.</td>
      <td>https://www.etherpal.xyz/</td>
    </tr>
    <tr>
      <td>Run AutoGPT within a virtual container</td>
      <td>HackerNews</td>
      <td>2023-05-11</td>
      <td>Auto-GPT — which you might have seen creating an online frency recently — is a text-generating app that utilizes OpenAI&amp;#x27;s language models, mainly GPT-3.5 and GPT-4, to function independently.The app is essentially a combination of GPT-3.5 and GPT-4 models with a companion bot that instructs them on what to do. A user sets a goal for the app, and the bot uses the models and various programs to carry out each step required to achieve the user&amp;#x27;s goal. What makes Auto-GPT useful is its abi</td>
      <td>https://news.ycombinator.com/item?id=35903212</td>
    </tr>
    <tr>
      <td>Show HN: Data content creation tool using OpenAI+LangChain(lessons learned)</td>
      <td>HackerNews</td>
      <td>2023-05-09</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://app.dataherald.ai/chat</td>
    </tr>
    <tr>
      <td>RasaGPT: First headless LLM chatbot built on top of Rasa, Langchain and FastAPI</td>
      <td>HackerNews</td>
      <td>2023-05-08</td>
      <td>Points: 179, Comments: 111</td>
      <td>https://github.com/paulpierre/RasaGPT</td>
    </tr>
    <tr>
      <td>Does prompt injection matter to AutoGPT?</td>
      <td>HackerNews</td>
      <td>2023-05-06</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://gist.github.com/rain-1/a1ed1116c6da4d2b195e562c8d3f9482</td>
    </tr>
    <tr>
      <td>Show HN: Bestflights.ai – GPT/langchain tool for cash vs. miles flight analysis</td>
      <td>HackerNews</td>
      <td>2023-05-05</td>
      <td>Hey - co-founder of bestflights.ai here.  We&amp;#x27;re super excited to put this out there.  bestflights.ai has a number of cool features powered by LLMS:\n- analyze the tradeoffs between cash and miles for United &amp;amp; American flights (delta coming soon!)\n- find the right flight for you based on your preferences\n- save and share your flight search history so you can come back to it later, and also allow others to book the same flight!</td>
      <td>https://www.bestflights.ai/</td>
    </tr>
    <tr>
      <td>Re-implementing LangChain in 100 lines of code</td>
      <td>HackerNews</td>
      <td>2023-05-04</td>
      <td>Points: 252, Comments: 83</td>
      <td>https://blog.scottlogic.com/2023/05/04/langchain-mini.html</td>
    </tr>
    <tr>
      <td>AutoGPT4J</td>
      <td>HackerNews</td>
      <td>2023-05-03</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://github.com/Aemon-Algiz/AutoGPT4J</td>
    </tr>
    <tr>
      <td>Show HN: AutoGPT Made Easy</td>
      <td>HackerNews</td>
      <td>2023-05-03</td>
      <td>Points: 10, Comments: 1</td>
      <td>https://www.agenthub.dev/?fuel_source_id=15cb1357-ae09-498c-97b0-390cbe8a4d38</td>
    </tr>
    <tr>
      <td>Langchain.rb – Building Ruby applications with LLMs</td>
      <td>HackerNews</td>
      <td>2023-05-02</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://github.com/andreibondarev/langchainrb</td>
    </tr>
    <tr>
      <td>Query Hacker News Using Auto-GPT</td>
      <td>HackerNews</td>
      <td>2023-05-02</td>
      <td>Points: 3, Comments: 3</td>
      <td>https://hn.ossinsight.io</td>
    </tr>
    <tr>
      <td>Show HN: Camel AGI – Role playing AGENTs(open-source)</td>
      <td>HackerNews</td>
      <td>2023-04-28</td>
      <td>Hey HN community,&lt;p&gt;We opening up access to our repo for CAMEL AGI.&lt;p&gt;CAMEL AGI: a game-changing role-playing approach for LLMs and auto-agents like BabyAGI &amp;amp; AutoGPT! Watch two agents  collaborate and solve tasks together, unlocking endless possibilities in #ConversationalAI,  gaming,  education, and more!&lt;p&gt;Do share your feedback !!</td>
      <td>https://github.com/SamurAIGPT/Camel-AutoGPT</td>
    </tr>
    <tr>
      <td>AutoGPT-Social, an autonomous Instagram bot to automate your social campaigns</td>
      <td>HackerNews</td>
      <td>2023-04-27</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://github.com/WillReynolds5/AutoGPT-Social</td>
    </tr>
    <tr>
      <td>Show HN: AutoGPT-Social, an autonomous Instagram bot</td>
      <td>HackerNews</td>
      <td>2023-04-27</td>
      <td>https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;WillReynolds5&amp;#x2F;AutoGPT-Social&lt;p&gt;I&amp;#x27;m excited to share with you a project I&amp;#x27;ve been working on called AutoGPT-Social! It&amp;#x27;s an Instagram bot that automatically generates and posts engaging content for your Instagram account using ChatGPT API. The bot gets real-world feedback in the form of likes and comments and uses the data to optimize captions, hashtags, and posting times. The bot&amp;#x27;s goal is to get as many likes, comments, and followers as</td>
      <td>https://news.ycombinator.com/item?id=35732527</td>
    </tr>
    <tr>
      <td>Discover Hacker News Insights with ChatGPT(Auto-GPT)-Powered Web App</td>
      <td>HackerNews</td>
      <td>2023-04-27</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://hn.ossinsight.io/</td>
    </tr>
    <tr>
      <td>Auto-GPT Added to OSSChat</td>
      <td>HackerNews</td>
      <td>2023-04-27</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://osschat.io/chat?project=Auto-GPT</td>
    </tr>
    <tr>
      <td>Mark Zuckerberg says Meta wants to ‘introduce AI agents to billions of people’</td>
      <td>HackerNews</td>
      <td>2023-04-27</td>
      <td>Points: 56, Comments: 62</td>
      <td>https://www.theverge.com/2023/4/26/23699633/mark-zuckerberg-meta-generative-ai-chatbots-instagram-facebook-whatsapp</td>
    </tr>
    <tr>
      <td>Show HN: Agent Actors – Plan-Do-Check-Adjust with Parallelized LLM Agent Trees</td>
      <td>HackerNews</td>
      <td>2023-04-26</td>
      <td>Hey HN! Been working on this library for architecting stateful LLM agent trees that execute in parallel. Think of it like a AI scheduler for BabyAGIs or AutoGPTs, like:&lt;p&gt;-----&lt;p&gt;Parent (Plan and Adjust): Chief Revenue Officer &amp;#x2F; VP Sales&lt;p&gt;Children (Do and Check): 3 Sales Development Representatives; 2 Account Managers; 1 Market Researcher.&lt;p&gt;You can give the CRO a task and it will break it down, distribute it appropriately to its children, and the children will work in parallel on the task</td>
      <td>https://github.com/shaman-ai/agent-actors</td>
    </tr>
    <tr>
      <td>Show HN: Langchain's new member-A SQL+Vector database built on ClickHouse</td>
      <td>HackerNews</td>
      <td>2023-04-25</td>
      <td>MyScale is designed for the storage and analysis of massive vector data with structured metadata. If you are eager to find a high-performance vector search using SQL queries, MyScale could be your preferred option. Thanks to the advantages of native structural database support, it provides you with a flexible filter with a WHERE clause, even JOIN when you want to jointly search vectors with filters on relevant metadata from other tables.&lt;p&gt;MyScale is now open for registration and offers millions</td>
      <td>https://myscale.com/</td>
    </tr>
    <tr>
      <td>Show HN: I made PromptWatch – LangChain tracing on steroids</td>
      <td>HackerNews</td>
      <td>2023-04-25</td>
      <td>As I was building my first few chains, I noticed how difficult it was to understand what was going on, why GPT was responding the way it was, and how I could improve it. Tinkering with my prompts was so tedious - I had to either update the prompt template and rerun the whole chain, or grab the actual prompt, take it to OpenAI playground, tweak it there, and then make a template out of it again. That&amp;#x27;s why I decided to build something better!&lt;p&gt;PromptWatch allows you to tune your prompt temp</td>
      <td>https://www.promptwatch.io/</td>
    </tr>
    <tr>
      <td>The Rise of Autonomous Agents</td>
      <td>HackerNews</td>
      <td>2023-04-25</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://autogpt.net/autonomous-agents-the-future-of-ai-with-auto-gpt-babyagi-and-jarvis/</td>
    </tr>
    <tr>
      <td>AutoGPT Tracing: Prompts, Costs, Latency, Compute</td>
      <td>HackerNews</td>
      <td>2023-04-25</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://graphsignal.com/blog/auto-gpt-tracing-prompts-costs-latency-compute/</td>
    </tr>
    <tr>
      <td>Is anyone getting any value-add out of AutoGPT?</td>
      <td>HackerNews</td>
      <td>2023-04-25</td>
      <td>Points: 2, Comments: 2</td>
      <td>https://twitter.com/jachiam0/status/1650842399550341120</td>
    </tr>
    <tr>
      <td>AutoGPT and other GPT and AI tools written in Golang</td>
      <td>HackerNews</td>
      <td>2023-04-24</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://github.com/igolaizola/igogpt</td>
    </tr>
    <tr>
      <td>I built a completely Local AutoGPT with the help of GPT-llama running Vicuna-13B</td>
      <td>HackerNews</td>
      <td>2023-04-24</td>
      <td>Points: 4, Comments: 1</td>
      <td>https://twitter.com/AdamPaigge/status/1650427355272208384</td>
    </tr>
    <tr>
      <td>AutoGPT</td>
      <td>HackerNews</td>
      <td>2023-04-24</td>
      <td>What are some interesting use case you were able to execute using AutoGP, I am still having a hard time understanding how it can actually solve something really promising\nisn&amp;#x27;t it just a gpt in while loop with a smart prompting?&lt;p&gt;Am I missing something here?</td>
      <td>https://news.ycombinator.com/item?id=35683711</td>
    </tr>
    <tr>
      <td>Ask HN: Have you had any productive success with AutoGPT?</td>
      <td>HackerNews</td>
      <td>2023-04-24</td>
      <td>AutoGPT seems to be basking at the top of they hype train, and there are countless articles explaining what it does.&lt;p&gt;I would be interested to hear of use cases in the comments that have proven to work and are being actively used as part of an established line.</td>
      <td>https://news.ycombinator.com/item?id=35691715</td>
    </tr>
    <tr>
      <td>Ask HN: AutoGPT never does something useful. Is it a cool useless idea?</td>
      <td>HackerNews</td>
      <td>2023-04-24</td>
      <td>Much hype around language models these days. Has anyone actually accomplished something using AutoGPT, BabyAGI, etc. that they couldn&amp;#x27;t have done using vanilla GPT-4?</td>
      <td>https://news.ycombinator.com/item?id=35691687</td>
    </tr>
    <tr>
      <td>Show HN: Langchain-serve – Langchain apps on production</td>
      <td>HackerNews</td>
      <td>2023-04-23</td>
      <td>- Exposes APIs from function definitions locally as well as on the cloud.\n- Very few lines of code changes, ease of development remains the same as local.\n- Supports both REST &amp;amp; Websocket endpoints\n- Serverless&amp;#x2F;autoscaling endpoints with automatic tls certs.\n- Real-time streaming, human-in-the-loop support</td>
      <td>https://github.com/jina-ai/langchain-serve</td>
    </tr>
    <tr>
      <td>ProfileGPT: An Example of AI Agents Collaboration Architecture</td>
      <td>HackerNews</td>
      <td>2023-04-23</td>
      <td>Points: 106, Comments: 15</td>
      <td>https://sahbichaieb.com/profilegpt/</td>
    </tr>
    <tr>
      <td>Technical Dive into AutoGPT</td>
      <td>HackerNews</td>
      <td>2023-04-22</td>
      <td>Points: 2, Comments: 1</td>
      <td>https://sudoapps.substack.com/p/technical-dive-into-autogpt</td>
    </tr>
    <tr>
      <td>GPT-4: “my self-awareness”</td>
      <td>HackerNews</td>
      <td>2023-04-22</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://github.com/Significant-Gravitas/Auto-GPT/issues/15</td>
    </tr>
    <tr>
      <td>On AutoGPT</td>
      <td>HackerNews</td>
      <td>2023-04-21</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://www.lesswrong.com/posts/566kBoPi76t8KAkoD/on-autogpt</td>
    </tr>
    <tr>
      <td>Show HN: Apex Agents, LLM Agents Running Natively in Salesforce</td>
      <td>HackerNews</td>
      <td>2023-04-20</td>
      <td>Built this as an experiment to learn more about &amp;quot;ReAct&amp;quot; style agents.  The result is kinda an &amp;quot;Auto-GPT lite&amp;quot;, running natively in Salesforce.&lt;p&gt;Building and running something like this in Salesforce is a MAJOR PITA, but I do think the platform provides an interesting ecosystem to explore use cases.&lt;p&gt;Still needs a lot of work to be &amp;quot;stable&amp;quot;, but I actually could see it being useful for certain use cases.&lt;p&gt;If you&amp;#x27;re interested in checking it out, but don&amp;#x27;</td>
      <td>https://github.com/callawaycloud/llm-apex-agents</td>
    </tr>
    <tr>
      <td>Know more about AutoGPT? Try OSSChat</td>
      <td>HackerNews</td>
      <td>2023-04-20</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://osschat.io/</td>
    </tr>
    <tr>
      <td>Run AutoGPT from the Browser</td>
      <td>HackerNews</td>
      <td>2023-04-20</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://huggingface.co/spaces/aliabid94/AutoGPT</td>
    </tr>
    <tr>
      <td>“Langchain is Overrated”, and other strategies I use to deal with the GPT Hype</td>
      <td>HackerNews</td>
      <td>2023-04-19</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://medium.com/@aplaceofmind/langchain-is-overrated-and-other-strategies-i-use-to-deal-with-the-gpt-hype-af06aa1a6be1</td>
    </tr>
    <tr>
      <td>Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous</td>
      <td>HackerNews</td>
      <td>2023-04-19</td>
      <td>Points: 46, Comments: 19</td>
      <td>https://github.com/Significant-Gravitas/Auto-GPT</td>
    </tr>
    <tr>
      <td>What Are BabyAGI and AutoGPT?</td>
      <td>HackerNews</td>
      <td>2023-04-19</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://fortune.com/2023/04/15/babyagi-autogpt-openai-gpt-4-autonomous-assistant-agi/</td>
    </tr>
    <tr>
      <td>LangChain taps Sequoia to lead funding round at a valuation of $200M</td>
      <td>HackerNews</td>
      <td>2023-04-19</td>
      <td>Points: 11, Comments: 1</td>
      <td>https://www.businessinsider.com/sequoia-leads-funding-round-generative-artificial-intelligence-startup-langchain-2023-4</td>
    </tr>
    <tr>
      <td>Auto GPT</td>
      <td>HackerNews</td>
      <td>2023-04-19</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://github.com/Significant-Gravitas/Auto-GPT</td>
    </tr>
    <tr>
      <td>Show HN: Lean customer development methodology simulated by AutoGPT</td>
      <td>HackerNews</td>
      <td>2023-04-19</td>
      <td>Provide an elevator pitch and target customer, and GPT generates personas to interview, with catchy names like Serverless Sarah. Then simulate user interviews, summarize the outputs and provide follow-ups. It&amp;#x27;s inspired by the legendary startup book Four Steps to the Epiphany by Steve Blank.&lt;p&gt;I am building a new database (I was one of the creators of CouchDB &amp;#x2F; PouchDB) and wanted an example app that more fun than just database crud operations. Fireproof is designed to be the easiest w</td>
      <td>https://epiphany.fireproof.storage</td>
    </tr>
    <tr>
      <td>Show HN: Run Auto-GPT locally in 2 lines</td>
      <td>HackerNews</td>
      <td>2023-04-19</td>
      <td>Auto-GPT has several steps on their README to get things off and running.&lt;p&gt;With this I am hoping its an easier on ramp for folks who want to hit the ground running. Currently the Docker image is hosted by me but you could build and replace your own docker image here&lt;p&gt;&lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;kurtosis-tech&amp;#x2F;autogpt-package&amp;#x2F;blob&amp;#x2F;main&amp;#x2F;main.star#L1"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;kurtosis-tech&amp;#x2F;autogpt-package&amp;#x2F;blob&amp;#x2F;main&amp;#x2F;m...&lt;/a&gt;</td>
      <td>https://github.com/kurtosis-tech/autogpt-package</td>
    </tr>
    <tr>
      <td>BabyAGI in Your Pocket</td>
      <td>HackerNews</td>
      <td>2023-04-18</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://github.com/steamship-packages/autogpt-telegram-chatbot</td>
    </tr>
    <tr>
      <td>GitHub stars are becoming pointless?</td>
      <td>HackerNews</td>
      <td>2023-04-18</td>
      <td>Not sure if it is an instance of Goodhart&amp;#x27;s law or just increased exposure to non-developers crowds, but Github stars used to be a good indicator of the popularity AND adoption of an open source project.&lt;p&gt;Nowadays, a demo project gets 89k stars in few days... https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;Significant-Gravitas&amp;#x2F;Auto-GPT&lt;p&gt;What do you think?</td>
      <td>https://news.ycombinator.com/item?id=35612479</td>
    </tr>
    <tr>
      <td>One click Auto-GPT Telegram bot with source</td>
      <td>HackerNews</td>
      <td>2023-04-18</td>
      <td>Points: 6, Comments: 0</td>
      <td>https://www.steamship.com/build/auto-gpt</td>
    </tr>
    <tr>
      <td>As AI agents like Auto-GPT speed up generative AI race, we all need to buckle up</td>
      <td>HackerNews</td>
      <td>2023-04-17</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://venturebeat.com/ai/as-ai-agents-like-auto-gpt-speed-up-generative-ai-race-we-all-need-to-buckle-up-the-ai-beat/</td>
    </tr>
    <tr>
      <td>AutoGPT on the Browser</td>
      <td>HackerNews</td>
      <td>2023-04-17</td>
      <td>Points: 8, Comments: 3</td>
      <td>https://autogpt.thesamur.ai</td>
    </tr>
    <tr>
      <td>Agent GPT – AutoGPT Alternative</td>
      <td>HackerNews</td>
      <td>2023-04-17</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.youtube.com/watch?v=g28a-M4JRac</td>
    </tr>
    <tr>
      <td>AutoGPT from the Browser</td>
      <td>HackerNews</td>
      <td>2023-04-17</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://godmode.space/</td>
    </tr>
    <tr>
      <td>AutoGPT used to create ransomware, mutation, save, and repeat</td>
      <td>HackerNews</td>
      <td>2023-04-17</td>
      <td>Points: 6, Comments: 0</td>
      <td>https://twitter.com/alexbilz/status/1647729282741940224</td>
    </tr>
    <tr>
      <td>AutoGPT surpasses PyTorch in number of GitHub stars</td>
      <td>HackerNews</td>
      <td>2023-04-16</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://twitter.com/drjimfan/status/1647616587199815684</td>
    </tr>
    <tr>
      <td>Show HN: Godmode – Modern frontend for Auto-GPT agents</td>
      <td>HackerNews</td>
      <td>2023-04-16</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://godmode.space</td>
    </tr>
    <tr>
      <td>User-Agent: AutoGPT</td>
      <td>HackerNews</td>
      <td>2023-04-15</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://github.com/Significant-Gravitas/Auto-GPT/issues/1724</td>
    </tr>
    <tr>
      <td>How to Install Auto-GPT on Windows</td>
      <td>HackerNews</td>
      <td>2023-04-15</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://agi-sphere.com/auto-gpt-install-windows/</td>
    </tr>
    <tr>
      <td>AutoGPT – Autonomous GPT Agents</td>
      <td>HackerNews</td>
      <td>2023-04-15</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://github.com/Significant-Gravitas/Auto-GPT</td>
    </tr>
    <tr>
      <td>How to Install Auto-GPT on Mac</td>
      <td>HackerNews</td>
      <td>2023-04-15</td>
      <td>Points: 4, Comments: 1</td>
      <td>https://agi-sphere.com/auto-gpt-install-mac/</td>
    </tr>
    <tr>
      <td>On AutoGPT</td>
      <td>HackerNews</td>
      <td>2023-04-13</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://thezvi.substack.com/p/on-autogpt</td>
    </tr>
    <tr>
      <td>Auto-GPT Unmasked: The Hype and Hard Truths of Its Production Pitfalls</td>
      <td>HackerNews</td>
      <td>2023-04-13</td>
      <td>Points: 90, Comments: 55</td>
      <td>https://jina.ai/news/auto-gpt-unmasked-hype-hard-truths-production-pitfalls</td>
    </tr>
    <tr>
      <td>Surprising things happen when you put 25 AI agents together in an RPG town</td>
      <td>HackerNews</td>
      <td>2023-04-11</td>
      <td>Points: 52, Comments: 16</td>
      <td>https://arstechnica.com/information-technology/2023/04/surprising-things-happen-when-you-put-25-ai-agents-together-in-an-rpg-town/</td>
    </tr>
    <tr>
      <td>Ask HN: OpenAI has already made AGI, but is concerned about releasing it?</td>
      <td>HackerNews</td>
      <td>2023-04-11</td>
      <td>The training of GPT-4 was finished in 2021. Ever since then, I think OpenAI made much bigger models on more recent data, but out of fear of public reaction to AGI, the company only released a dumbed down version of it called GPT-4. They don’t even mention what they technically did in their paper.&lt;p&gt;What fuels this theory is the fact that quickly after the release of GPT-4, tons of projects started using self reflection to boost GPT-4’s capabilities. As an engineer in OpenAI, this looks like a lo</td>
      <td>https://news.ycombinator.com/item?id=35529891</td>
    </tr>
    <tr>
      <td>AutoGPT vs. BabyAGI vs. LangChain</td>
      <td>HackerNews</td>
      <td>2023-04-11</td>
      <td>Points: 6, Comments: 0</td>
      <td>https://dsdaily.substack.com/p/say-hello-to-the-fastest-growing</td>
    </tr>
    <tr>
      <td>Can GPT 4 Prompt Itself? MemoryGPT, AutoGPT, Jarvis, Claude-Next [10x GPT 4!]</td>
      <td>HackerNews</td>
      <td>2023-04-10</td>
      <td>Points: 30, Comments: 1</td>
      <td>https://www.youtube.com/watch?v=6NoTuqDAkfg</td>
    </tr>
    <tr>
      <td>Show HN: TestGPT to Test and Fix AutoGPT</td>
      <td>HackerNews</td>
      <td>2023-04-10</td>
      <td>1&amp;gt; AI Agents, such as AutoGPT, are trending on GitHub.&lt;p&gt;The concept is very intriguing.&lt;p&gt;Prompt an AI Agent with your goals and it will try to fulfill them.&lt;p&gt;This is an experimental project.&lt;p&gt;2&amp;gt; CodiumAI, powered by TestGPT, provides an IDE Extension enabling developers to generate meaningful tests as they code.&lt;p&gt;CodiumAI can be used to test and fix AutoGPT.&lt;p&gt;Thus, a first GPT-empowered tool is used to improve a second GPT-empowered tool.&lt;p&gt;3&amp;gt; Now, AutoGPT also includes unit-testi</td>
      <td>https://twitter.com/itamar_mar/status/1645414310099681282</td>
    </tr>
    <tr>
      <td>GPT-4 goes a little AGI with Auto-GPT</td>
      <td>HackerNews</td>
      <td>2023-04-08</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://the-decoder.com/gpt-4-goes-a-little-agi-with-auto-gpt/</td>
    </tr>
    <tr>
      <td>Own ChatGPT AI assistant on Telegram with Langchain</td>
      <td>HackerNews</td>
      <td>2023-04-06</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://searchwith.ai/blog/your-own-chatgpt-ai-assistant-on-telegram-with-langchain/</td>
    </tr>
    <tr>
      <td>Build open-source ChatGPT assistant for Telegram with Langchain and Replit</td>
      <td>HackerNews</td>
      <td>2023-04-06</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://searchwith.ai/blog/your-own-chatgpt-ai-assistant-on-telegram-with-langchain/</td>
    </tr>
    <tr>
      <td>Ask HN: How far do you think we can enhance GPT-4?</td>
      <td>HackerNews</td>
      <td>2023-04-06</td>
      <td>There have been a number of GPT-4 variants and expansions that show improved results over the base model. Some relevant ones I can think of allow GPT to:&lt;p&gt;- Reflect on its own behavior (Reflexion)&lt;p&gt;- Function autonomously (Auto-GPT)&lt;p&gt;- Use external tools (HuggingGPT)&lt;p&gt;- Have long-term memory (Retrieval)&lt;p&gt;I&amp;#x27;m no expert on AI or the human brain, but it seems to me that with this we would have all main elements of intelligence. If we could think of an architecture that combined all these</td>
      <td>https://news.ycombinator.com/item?id=35466943</td>
    </tr>
    <tr>
      <td>Robo-GPT, a Variant of AutoGPT</td>
      <td>HackerNews</td>
      <td>2023-04-04</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://twitter.com/RokStrnisa/status/1643044793419718656</td>
    </tr>
    <tr>
      <td>LangChain Announces 10M Seed Round</td>
      <td>HackerNews</td>
      <td>2023-04-04</td>
      <td>Points: 235, Comments: 167</td>
      <td>https://blog.langchain.dev/announcing-our-10m-seed-round-led-by-benchmark/</td>
    </tr>
    <tr>
      <td>Update for Auto-GPT: Code Execution</td>
      <td>HackerNews</td>
      <td>2023-04-03</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://twitter.com/SigGravitas/status/1642181498278408193</td>
    </tr>
    <tr>
      <td>Jina AI's Inference Integration for LangChain</td>
      <td>HackerNews</td>
      <td>2023-04-03</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://jina.ai/news/langchain_jina_inference/</td>
    </tr>
    <tr>
      <td>Auto-GPT: AI writes code, executes, debugs and fixes on its own</td>
      <td>HackerNews</td>
      <td>2023-04-03</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://twitter.com/SigGravitas/status/1642181498278408193</td>
    </tr>
    <tr>
      <td>Auto-GPT: An Autonomous GPT-4 Experiment</td>
      <td>HackerNews</td>
      <td>2023-04-02</td>
      <td>Points: 153, Comments: 174</td>
      <td>https://github.com/Torantulino/Auto-GPT</td>
    </tr>
    <tr>
      <td>AutoGPTs</td>
      <td>HackerNews</td>
      <td>2023-04-02</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://twitter.com/karpathy/status/1642598890573819905</td>
    </tr>
    <tr>
      <td>LangChainJS ExpressJS API Boilerplate</td>
      <td>HackerNews</td>
      <td>2023-04-02</td>
      <td>Points: 4, Comments: 1</td>
      <td>https://github.com/Texterous/LangChainJS-ExpressJS-Boilerplate</td>
    </tr>
    <tr>
      <td>Query LangChain and its docs in natural language</td>
      <td>HackerNews</td>
      <td>2023-03-31</td>
      <td>Points: 3, Comments: 4</td>
      <td>https://langchainx.web.app/</td>
    </tr>
    <tr>
      <td>Retrieval in LangChain</td>
      <td>HackerNews</td>
      <td>2023-03-25</td>
      <td>Points: 212, Comments: 69</td>
      <td>https://blog.langchain.dev/retrieval/</td>
    </tr>
    <tr>
      <td>Show HN: LangFlow – An Open Source UI for LangChain</td>
      <td>HackerNews</td>
      <td>2023-03-15</td>
      <td>We are excited to announce LangFlow — An Open Source UI for LangChain!&lt;p&gt;Take a look at our release article on Medium:\n&lt;a href="https:&amp;#x2F;&amp;#x2F;link.medium.com&amp;#x2F;vg7qCRVsayb" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;link.medium.com&amp;#x2F;vg7qCRVsayb&lt;/a&gt;</td>
      <td>https://github.com/logspace-ai/langflow</td>
    </tr>
    <tr>
      <td>LangFlow: A User Interface for LangChain</td>
      <td>HackerNews</td>
      <td>2023-03-15</td>
      <td>Points: 4, Comments: 1</td>
      <td>https://github.com/logspace-ai/langflow</td>
    </tr>
    <tr>
      <td>Chatbot Memory with Langchain</td>
      <td>HackerNews</td>
      <td>2023-03-14</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://www.pinecone.io/learn/langchain-conversational-memory/</td>
    </tr>
    <tr>
      <td>Pytest-langchain: Pytest-style test runner for langchain projects</td>
      <td>HackerNews</td>
      <td>2023-02-26</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://github.com/ajndkr/pytest-langchain</td>
    </tr>
    <tr>
      <td>Show HN: AI and Automations = cool use cases for productivity</td>
      <td>HackerNews</td>
      <td>2023-02-23</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://twitter.com/fibery_io/status/1628754549967056897</td>
    </tr>
    <tr>
      <td>LangChain TypeScript Support</td>
      <td>HackerNews</td>
      <td>2023-02-17</td>
      <td>Points: 8, Comments: 3</td>
      <td>https://twitter.com/LangChainAI/status/1626624683222388736</td>
    </tr>
    <tr>
      <td>Show HN: Vercel and LangChain Templates</td>
      <td>HackerNews</td>
      <td>2023-02-15</td>
      <td>Points: 4, Comments: 2</td>
      <td>https://www.steamship.com/build/langchain-on-vercel</td>
    </tr>
    <tr>
      <td>Show HN: Hosting for LangChain APIs</td>
      <td>HackerNews</td>
      <td>2023-02-14</td>
      <td>Points: 12, Comments: 0</td>
      <td>https://www.steamship.com/build/langchain-apps</td>
    </tr>
    <tr>
      <td>Fixie.ai – Automation Platform for LLMs</td>
      <td>HackerNews</td>
      <td>2023-02-10</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://www.fixie.ai/</td>
    </tr>
    <tr>
      <td>Show HN: Deploy LangChain Apps to Production</td>
      <td>HackerNews</td>
      <td>2023-02-09</td>
      <td>Points: 8, Comments: 2</td>
      <td>https://github.com/steamship-core/steamship-langchain</td>
    </tr>
    <tr>
      <td>Ask HN: Why not have a GTA that requires players to create missions via ChatGPT?</td>
      <td>HackerNews</td>
      <td>2023-02-07</td>
      <td>This &amp;quot;Grand Theft Auto GPT&amp;quot; could then use the mission text description entered by the player (obtained with the help of ChatGPT) to automatically generate a mission that can be played just like any handcrafted mission.</td>
      <td>https://news.ycombinator.com/item?id=34692415</td>
    </tr>
    <tr>
      <td>Show HN: 1-Click Deploy for Langchain LLM Agents from Google Colab to Web-App</td>
      <td>HackerNews</td>
      <td>2023-02-02</td>
      <td>We’ve just released Berri AI - a Python package &lt;a href="https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;ClerkieAI&amp;#x2F;berri_ai"&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;ClerkieAI&amp;#x2F;berri_ai&lt;/a&gt;\nthat makes it easy for developers to quickly deploy their LLM Agent from Google Colab to production (Web App and API Endpoint).&lt;p&gt;Building LLM Apps can require working in online coding environments, like Colab, due to local environment limitations (e.g. running pytorch on older Macs). This can cause long dev cycles when</td>
      <td>https://github.com/ClerkieAI/berri_ai</td>
    </tr>
    <tr>
      <td>Show HN: LangChain Tracing</td>
      <td>HackerNews</td>
      <td>2023-01-30</td>
      <td>Something we&amp;#x27;ve been working on for the past few weeks - an easy way to visualize, debug, and explore the execution trace of LangChain agents and chains</td>
      <td>https://langchain.readthedocs.io/en/latest/tracing.html</td>
    </tr>
    <tr>
      <td>GPT-Index vs. Langchain</td>
      <td>HackerNews</td>
      <td>2023-01-29</td>
      <td>Someone I work with wrote the below for our internal team (shared with permission) and I thought some here may find it helpful.&lt;p&gt;Recently, I built an app that uses GPT-Index &amp;amp; LangChain to provide an answer to a question based on a piece of text as context. I found GPT-Index to be much easier and straightforward to integrate, but it seems like LangChain has more features and is more powerful. Here&amp;#x27;s my experience integrating both of them.&lt;p&gt;GPT-Index&lt;p&gt;-   First thing I did was review</td>
      <td>https://news.ycombinator.com/item?id=34568343</td>
    </tr>
    <tr>
      <td>Show HN: Visualize GPT Workflows on LangChain</td>
      <td>HackerNews</td>
      <td>2023-01-23</td>
      <td>Points: 5, Comments: 0</td>
      <td>https://github.com/amosjyng/langchain-visualizer</td>
    </tr>
    <tr>
      <td>LangChain: Build AI apps with LLMs through composability</td>
      <td>HackerNews</td>
      <td>2023-01-18</td>
      <td>Points: 372, Comments: 76</td>
      <td>https://github.com/hwchase17/langchain</td>
    </tr>
    <tr>
      <td>Introducing “Clerkie“: A LangChain Q&amp;A bot for AI developers</td>
      <td>HackerNews</td>
      <td>2023-01-18</td>
      <td>Points: 7, Comments: 2</td>
      <td>https://huggingface.co/spaces/krrishD/Langchain_Code_QA_Bot</td>
    </tr>
    <tr>
      <td>GPT-3.5 and Wolfram Alpha via LangChain</td>
      <td>HackerNews</td>
      <td>2023-01-18</td>
      <td>Points: 107, Comments: 8</td>
      <td>https://huggingface.co/spaces/JavaFXpert/Chat-GPT-LangChain</td>
    </tr>
    <tr>
      <td>Build a GitHub Support Bot with GPT3, LangChain, and Python</td>
      <td>HackerNews</td>
      <td>2023-01-15</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://dagster.io/blog/chatgpt-langchain</td>
    </tr>
    <tr>
      <td>Rage Against the (Smart) Machine – Why I want my TV to be ‘dumb.’</td>
      <td>HackerNews</td>
      <td>2022-12-03</td>
      <td>Points: 54, Comments: 35</td>
      <td>https://www.nationalreview.com/2022/12/rage-against-the-smart-machine/</td>
    </tr>
    <tr>
      <td>CICERO: An AI agent that negotiates, persuades, and cooperates with people</td>
      <td>HackerNews</td>
      <td>2022-11-22</td>
      <td>Points: 509, Comments: 285</td>
      <td>https://ai.facebook.com/blog/cicero-ai-negotiates-persuades-and-cooperates-with-people/</td>
    </tr>
    <tr>
      <td>Rage Against The Machine’s explosive debut album changed everything</td>
      <td>HackerNews</td>
      <td>2022-11-04</td>
      <td>Points: 187, Comments: 169</td>
      <td>https://www.loudersound.com/features/rage-against-the-machine-debut-album-story</td>
    </tr>
    <tr>
      <td>Show HN: In a new world of AI and Automation, I started an agency startup</td>
      <td>HackerNews</td>
      <td>2022-10-27</td>
      <td>Here&amp;#x27;s my attempt at the elevator pitch:&lt;p&gt;Growby is a complete startup product suite aimed at simplifying business launch needs specifically for non-tech startups.&lt;p&gt;For a quick launch, it provides a single platform to create brand identity, website, hosting, and email setup.&lt;p&gt;The platform requires human-touch and conversation and so it can provide personalized attention and high quality.&lt;p&gt;In addition to providing technology platform, Growby also plans to provide a comprehensive set of d</td>
      <td>https://news.ycombinator.com/item?id=33356958</td>
    </tr>
    <tr>
      <td>Show HN: A Productized Service in the new world of AI and Automation</td>
      <td>HackerNews</td>
      <td>2022-10-27</td>
      <td>Here&amp;#x27;s my attempt at the elevator pitch:&lt;p&gt;Growby is a complete startup product suite aimed to help businesses launch quickly.&lt;p&gt;For a quick launch, it provides a single platform to create brand identity, website, hosting, and email setup.&lt;p&gt;The platform requires human-touch and conversation and so it can provide personalized attention and high quality.&lt;p&gt;In addition to providing branding &amp;amp; technology, Growby also plans to provide a comprehensive set of documents for various business us</td>
      <td>https://news.ycombinator.com/item?id=33358920</td>
    </tr>
    <tr>
      <td>Women in industries under threat from AI and automation urged to 'upskill'</td>
      <td>HackerNews</td>
      <td>2022-08-29</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://www.abc.net.au/news/2022-08-30/ai-automation-jobs-women-roles-pearson-data/101384336</td>
    </tr>
    <tr>
      <td>Show HN: AutoPTT – Voice-activated push-to-talk</td>
      <td>HackerNews</td>
      <td>2022-08-23</td>
      <td>Hello HN. I made this Windows desktop app that allows using voice activation with games or apps that only support push-to-talk.&lt;p&gt;The initial version was written years ago, without any UI or configuration options. It was just for my personal use. I had told a few friends about it, though, and then one of them asked if he could get a copy to use with Discord priority speaker, since for years, it has only worked with push-to-talk. So I spent some time making a more user-friendly version.&lt;p&gt;It&amp;#x27</td>
      <td>https://wibe.gumroad.com/l/autoptt</td>
    </tr>
    <tr>
      <td>Elizabeth Cotton’s Fingerstyle Ragtime</td>
      <td>HackerNews</td>
      <td>2022-08-04</td>
      <td>Points: 118, Comments: 27</td>
      <td>http://www.ethanhein.com/wp/2022/elizabeth-cottens-fingerstyle-ragtime/#more-26016</td>
    </tr>
    <tr>
      <td>Mundane chores are all the rage in gaming</td>
      <td>HackerNews</td>
      <td>2022-06-15</td>
      <td>Points: 225, Comments: 328</td>
      <td>https://www.economist.com/culture/2022/06/14/mundane-chores-are-all-the-rage-in-gaming</td>
    </tr>
    <tr>
      <td>AutoPTT – Automatic Push-to-Talk</td>
      <td>HackerNews</td>
      <td>2022-04-23</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://wibe.gumroad.com/l/autoptt</td>
    </tr>
    <tr>
      <td>I Eat for Free in NYC Using Python, Automation, AI, and Instagram</td>
      <td>HackerNews</td>
      <td>2022-03-23</td>
      <td>Points: 61, Comments: 39</td>
      <td>https://medium.com/@chrisbuetti/how-i-eat-for-free-in-nyc-using-python-automation-artificial-intelligence-and-instagram-a5ed8a1e2a10</td>
    </tr>
    <tr>
      <td>Ragingbull.com to pay $2.4M for bogus earnings claims, subscription charges</td>
      <td>HackerNews</td>
      <td>2022-03-10</td>
      <td>Points: 142, Comments: 74</td>
      <td>https://www.ftc.gov/news-events/press-releases/2022/03/online-investment-site-pay-more-24-million-bogus-stock-earnings</td>
    </tr>
    <tr>
      <td>AI is automation of mental tasks</td>
      <td>HackerNews</td>
      <td>2022-01-29</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://blog.valentin.sh/ai/</td>
    </tr>
    <tr>
      <td>Wind whipped fires raging through Boulder County</td>
      <td>HackerNews</td>
      <td>2021-12-30</td>
      <td>Points: 131, Comments: 74</td>
      <td>https://www.dailycamera.com/2021/12/30/boulder-county-grass-fires/</td>
    </tr>
    <tr>
      <td>Levity: No-Code AI Automation</td>
      <td>HackerNews</td>
      <td>2021-11-12</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://levity.ai/</td>
    </tr>
    <tr>
      <td>When AI and automation come to work you stress less – but hate your job more</td>
      <td>HackerNews</td>
      <td>2021-10-29</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.theregister.com/2021/10/29/impact_of_ai_and_automation_on_workers/</td>
    </tr>
    <tr>
      <td>AI and Automation Are at Odds</td>
      <td>HackerNews</td>
      <td>2021-09-20</td>
      <td>Points: 8, Comments: 1</td>
      <td>https://cerebralab.com/AI_and_automation_are_at_odds</td>
    </tr>
    <tr>
      <td>Greedy AI agents learn to cooperate</td>
      <td>HackerNews</td>
      <td>2021-09-06</td>
      <td>Points: 91, Comments: 19</td>
      <td>https://spectrum.ieee.org/reinforcement-learning</td>
    </tr>
    <tr>
      <td>The quiet battle raging around open banking</td>
      <td>HackerNews</td>
      <td>2021-08-02</td>
      <td>Points: 120, Comments: 56</td>
      <td>https://sifted.eu/articles/open-banking-finance-battle/</td>
    </tr>
    <tr>
      <td>Getting 'Steinached' was all the rage in Roaring ’20s (2017)</td>
      <td>HackerNews</td>
      <td>2021-07-20</td>
      <td>Points: 87, Comments: 50</td>
      <td>https://www.mcgill.ca/oss/article/health-history-science-science-everywhere/getting-steinached-was-all-rage-roaring-20s</td>
    </tr>
    <tr>
      <td>A privacy war is raging inside the W3C</td>
      <td>HackerNews</td>
      <td>2021-07-13</td>
      <td>Points: 376, Comments: 217</td>
      <td>https://www.protocol.com/policy/w3c-privacy-war</td>
    </tr>
    <tr>
      <td>How I Eat for Free in NYC Using Python, Automation, AI, and Instagram (2019)</td>
      <td>HackerNews</td>
      <td>2021-05-13</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://medium.com/@chrisbuetti/how-i-eat-for-free-in-nyc-using-python-automation-artificial-intelligence-and-instagram-a5ed8a1e2a10</td>
    </tr>
    <tr>
      <td>Once on the brink of eradication, syphilis is raging again</td>
      <td>HackerNews</td>
      <td>2021-04-14</td>
      <td>Points: 149, Comments: 328</td>
      <td>https://www.npr.org/sections/health-shots/2021/04/14/986997576/once-on-the-brink-of-eradication-syphilis-is-raging-again</td>
    </tr>
    <tr>
      <td>Nvidia Launches Morpheus to Bring AI-Driven Automation to Cybersecurity Industry</td>
      <td>HackerNews</td>
      <td>2021-04-12</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://nvidianews.nvidia.com/news/nvidia-launches-morpheus-to-bring-ai-driven-automation-to-cybersecurity-industry</td>
    </tr>
    <tr>
      <td>GameStop, Bitcoin and the Commoditization of Populist Rage</td>
      <td>HackerNews</td>
      <td>2021-02-23</td>
      <td>Points: 160, Comments: 190</td>
      <td>https://www.stephendiehl.com/blog/gamestop.html</td>
    </tr>
    <tr>
      <td>GameStop Is Rage Against the Financial Machine</td>
      <td>HackerNews</td>
      <td>2021-01-27</td>
      <td>Points: 1078, Comments: 1148</td>
      <td>https://www.bloomberg.com/opinion/articles/2021-01-27/gamestop-short-squeeze-is-rage-against-the-financial-machine</td>
    </tr>
    <tr>
      <td>The Donut King who went from rags to riches, twice</td>
      <td>HackerNews</td>
      <td>2020-11-29</td>
      <td>Points: 164, Comments: 126</td>
      <td>https://www.bbc.com/news/stories-54546427</td>
    </tr>
    <tr>
      <td>Ragya – Indian classical music played by time of the day</td>
      <td>HackerNews</td>
      <td>2020-11-26</td>
      <td>Points: 341, Comments: 92</td>
      <td>https://www.ragya.com/</td>
    </tr>
    <tr>
      <td>Japan’s Onryō Spirits Inhabit a Purgatory of Revenge and Cosmic Rage</td>
      <td>HackerNews</td>
      <td>2020-11-09</td>
      <td>Points: 55, Comments: 8</td>
      <td>https://www.atlasobscura.com/articles/monster-mythology-onryo</td>
    </tr>
    <tr>
      <td>AI and automation are creating a hybrid workforce</td>
      <td>HackerNews</td>
      <td>2020-10-31</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.axios.com/ai-automation-pandemic-job-changes-bdccef8b-4766-4170-8984-775e8aa13168.html</td>
    </tr>
    <tr>
      <td>Can AI and Automation Deliver a Covid-19 Antiviral While It Still Matters?</td>
      <td>HackerNews</td>
      <td>2020-10-25</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://news.ycombinator.com/item?id=24890471</td>
    </tr>
    <tr>
      <td>Can AI and Automation Deliver a Covid-19 Antiviral While It Still Matters?</td>
      <td>HackerNews</td>
      <td>2020-09-24</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://spectrum.ieee.org/artificial-intelligence/medical-ai/can-ai-and-automation-deliver-a-covid19-antiviral-while-it-still-matters</td>
    </tr>
    <tr>
      <td>The Toxoplasma of Rage (2014)</td>
      <td>HackerNews</td>
      <td>2020-07-28</td>
      <td>Points: 267, Comments: 214</td>
      <td>https://slatestarcodex.com/2014/12/17/the-toxoplasma-of-rage/</td>
    </tr>
    <tr>
      <td>Hubo Enjoys Growing Results from Site Search with AI Automation</td>
      <td>HackerNews</td>
      <td>2020-07-28</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://searchnode.com/success-story/hubo/</td>
    </tr>
    <tr>
      <td>Apple is facing rage from developers over the commission on the App Store</td>
      <td>HackerNews</td>
      <td>2020-06-17</td>
      <td>Points: 128, Comments: 173</td>
      <td>https://www.businessinsider.com/apple-developer-rage-30-percent-app-store-tax-2020-6</td>
    </tr>
    <tr>
      <td>Rage Against the God Machine</td>
      <td>HackerNews</td>
      <td>2020-06-06</td>
      <td>Points: 62, Comments: 28</td>
      <td>https://buttondown.email/hillelwayne/archive/rage-against-the-god-machine/</td>
    </tr>
    <tr>
      <td>Caught on camera, police explode in rage and violence across the US</td>
      <td>HackerNews</td>
      <td>2020-05-31</td>
      <td>Points: 141, Comments: 114</td>
      <td>https://www.theverge.com/2020/5/31/21276044/police-violence-protest-george-floyd</td>
    </tr>
    <tr>
      <td>Hent-AI: Automation of censor bar detection</td>
      <td>HackerNews</td>
      <td>2020-03-10</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://github.com/natethegreate/hent-AI</td>
    </tr>
    <tr>
      <td>AI automation for long-term cryptocurrency trading</td>
      <td>HackerNews</td>
      <td>2020-02-17</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://www.acai.dev/</td>
    </tr>
    <tr>
      <td>Which jobs that would thrive with the advent of AI, robotics, automation?</td>
      <td>HackerNews</td>
      <td>2020-01-12</td>
      <td>Points: 2, Comments: 0</td>
      <td>http://www.mohanbabuk.com/2020/01/career-advice-what-are-jobs-or-domains.html</td>
    </tr>
    <tr>
      <td>Wildfires Are Raging Outside Every Major City in Australia</td>
      <td>HackerNews</td>
      <td>2020-01-02</td>
      <td>Points: 151, Comments: 202</td>
      <td>https://time.com/5753584/bushfires-australia-catastrophic-fire-alert/</td>
    </tr>
    <tr>
      <td>Samsung TVs May Upload Screenshots for Automatic Content Recognition</td>
      <td>HackerNews</td>
      <td>2019-12-28</td>
      <td>Points: 1246, Comments: 688</td>
      <td>https://www.samsung.com/us/account/privacy-policy/</td>
    </tr>
    <tr>
      <td>AI, automation will disrupt our world – but only Andrew Yang is warning about it</td>
      <td>HackerNews</td>
      <td>2019-11-10</td>
      <td>Points: 1, Comments: 2</td>
      <td>https://thehill.com/opinion/technology/469750-ai-and-automation-will-disrupt-our-world-but-only-andrew-yang-is-warning</td>
    </tr>
    <tr>
      <td>From rags to Richer: A business success story built on treating people well</td>
      <td>HackerNews</td>
      <td>2019-10-09</td>
      <td>Points: 119, Comments: 30</td>
      <td>https://www.economist.com/business/2019/10/03/from-rags-to-richer</td>
    </tr>
    <tr>
      <td>With AI and automation, workplace laws need updating</td>
      <td>HackerNews</td>
      <td>2019-08-30</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://www.chicagotribune.com/opinion/commentary/ct-opinion-automation-workplace-labor-laws-20190829-xgcu3ysfp5alnofdiahnfk7h5y-story.html</td>
    </tr>
    <tr>
      <td>AI and automation are making office life easier</td>
      <td>HackerNews</td>
      <td>2019-08-02</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://www.engadget.com/2019/08/02/ai-automation-office-life-easier/</td>
    </tr>
    <tr>
      <td>Algorithmia raises $25M Series B for its AI automation platform</td>
      <td>HackerNews</td>
      <td>2019-05-14</td>
      <td>Points: 13, Comments: 3</td>
      <td>https://techcrunch.com/2019/05/14/algorithmia-raises-25m-series-b-for-its-ai-automation-platform/</td>
    </tr>
    <tr>
      <td>How to increase accounting efficiency using AI invoice automation</td>
      <td>HackerNews</td>
      <td>2019-04-24</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://dlabs.pl/blog/article/how_to_increase_accounting_efficiency_using_ai_invoice_automation</td>
    </tr>
    <tr>
      <td>Why Alan Turing Wanted AI Agents to Make Mistakes</td>
      <td>HackerNews</td>
      <td>2019-04-19</td>
      <td>Points: 77, Comments: 18</td>
      <td>https://spectrum.ieee.org/tech-talk/tech-history/dawn-of-electronics/untold-history-of-ai-why-alan-turing-wanted-ai-to-make-mistakes</td>
    </tr>
    <tr>
      <td>Jack Ma Again Endorses Extreme Overtime as Furor Rages On</td>
      <td>HackerNews</td>
      <td>2019-04-15</td>
      <td>Points: 260, Comments: 251</td>
      <td>https://www.bloomberg.com/news/articles/2019-04-15/jack-ma-again-endorses-extreme-overtime-as-online-furor-rages-on</td>
    </tr>
    <tr>
      <td>I Eat for Free in NYC Using Python, Automation, AI, and Instagram</td>
      <td>HackerNews</td>
      <td>2019-04-03</td>
      <td>Points: 4, Comments: 1</td>
      <td>https://medium.com/%40chrisbuetti/how-i-eat-for-free-in-nyc-using-python-automation-artificial-intelligence-and-instagram-a5ed8a1e2a10</td>
    </tr>
    <tr>
      <td>How I Eat for Free in NYC Using Python, Automation, AI, and Instagram</td>
      <td>HackerNews</td>
      <td>2019-04-02</td>
      <td>Points: 227, Comments: 141</td>
      <td>https://medium.com/@chrisbuetti/how-i-eat-for-free-in-nyc-using-python-automation-artificial-intelligence-and-instagram-a5ed8a1e2a10</td>
    </tr>
    <tr>
      <td>Do AI, Automation and the No-Code Movement Threaten Our Jobs?</td>
      <td>HackerNews</td>
      <td>2019-04-01</td>
      <td>Points: 6, Comments: 6</td>
      <td>https://www.i-programmer.info/programming/artificial-intelligence/12647-do-ai-automation-and-the-no-code-movement-threaten-the-software-developers-job.html</td>
    </tr>
    <tr>
      <td>How I Eat for Free in NYC using Python, Automation, AI, and Instagram</td>
      <td>HackerNews</td>
      <td>2019-03-20</td>
      <td>Points: 11, Comments: 0</td>
      <td>https://medium.com/@chrisbuetti/how-i-eat-for-free-in-nyc-using-python-automation-artificial-intelligence-and-instagram-a5ed8a1e2a10</td>
    </tr>
    <tr>
      <td>Firefox 66 to block automatically playing audible video and audio</td>
      <td>HackerNews</td>
      <td>2019-02-04</td>
      <td>Points: 1415, Comments: 368</td>
      <td>https://hacks.mozilla.org/2019/02/firefox-66-to-block-automatically-playing-audible-video-and-audio/</td>
    </tr>
    <tr>
      <td>Ask HN: How to handle content of a flat-file CMS in Docker images?</td>
      <td>HackerNews</td>
      <td>2019-01-23</td>
      <td>Hi HN Community,&lt;p&gt;I currently work on a project that runs with Kirby, a flat file CMS. Means: all content is saved in files inside the project structure. The project should be built as a Docker image and deployed to the server afterwards.&lt;p&gt;I would like to know how a good solution could look like that handles the changing content files inside the Docker containers?&lt;p&gt;Current evaluated solutions:&lt;p&gt;- save them in shared folders outside of the Docker containers, via volumes.&lt;p&gt;- handle them via G</td>
      <td>https://news.ycombinator.com/item?id=18977136</td>
    </tr>
    <tr>
      <td>Why Is America So Angry? The Real Roots of American Rage</td>
      <td>HackerNews</td>
      <td>2018-12-20</td>
      <td>Points: 75, Comments: 23</td>
      <td>https://www.theatlantic.com/magazine/archive/2019/01/charles-duhigg-american-anger/576424/</td>
    </tr>
    <tr>
      <td>Back to the Future for Legal AI and Automation</td>
      <td>HackerNews</td>
      <td>2018-12-12</td>
      <td>Points: 4, Comments: 0</td>
      <td>https://www.artificiallawyer.com/2018/12/12/back-to-the-future-for-legal-ai-automation/</td>
    </tr>
    <tr>
      <td>How Facebook Is Fueling the French Populist Rage</td>
      <td>HackerNews</td>
      <td>2018-12-06</td>
      <td>Points: 74, Comments: 173</td>
      <td>https://mondaynote.com/how-facebook-is-fueling-the-french-populist-rage-27a86acb9d85</td>
    </tr>
    <tr>
      <td>How AI automation could boost employment: The role of demand</td>
      <td>HackerNews</td>
      <td>2018-11-28</td>
      <td>Points: 62, Comments: 34</td>
      <td>https://bitsandatoms.co/how-ai-automation-could-boost-employment-the-role-of-demand/</td>
    </tr>
    <tr>
      <td>Toward a deeper understanding of the way AI agents see things</td>
      <td>HackerNews</td>
      <td>2018-11-19</td>
      <td>Points: 79, Comments: 7</td>
      <td>https://code.fb.com/ai-research/ai-agents-see/</td>
    </tr>
    <tr>
      <td>Do AI/automation threaten you?</td>
      <td>HackerNews</td>
      <td>2018-11-15</td>
      <td>With automation becoming more and more prevalent these days, some people fear about automation and AI replacing us. I guess in this sense developers are safe but does it threaten you? Why or why not?</td>
      <td>https://news.ycombinator.com/item?id=18456787</td>
    </tr>
    <tr>
      <td>Find out how susceptible your job is to AI automation</td>
      <td>HackerNews</td>
      <td>2018-11-14</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://6figr.com/us/futureofwork/Analyst--OOesdrJx</td>
    </tr>
    <tr>
      <td>Show HN: Autogit – automatically execute commands across multiple Git repos</td>
      <td>HackerNews</td>
      <td>2018-10-10</td>
      <td>Points: 7, Comments: 2</td>
      <td>https://github.com/fabiospampinato/autogit</td>
    </tr>
    <tr>
      <td>Show HN: Autogit - execute commands across all your repositories</td>
      <td>HackerNews</td>
      <td>2018-10-08</td>
      <td>Points: 2, Comments: 2</td>
      <td>https://github.com/fabiospampinato/autogit</td>
    </tr>
    <tr>
      <td>Coders Automating Their Own Job</td>
      <td>HackerNews</td>
      <td>2018-10-02</td>
      <td>Points: 991, Comments: 485</td>
      <td>https://www.theatlantic.com/technology/archive/2018/10/agents-of-automation/568795/?single_page=true</td>
    </tr>
    <tr>
      <td>The case for humanities in the era of AI, automation, and technology</td>
      <td>HackerNews</td>
      <td>2018-09-24</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://hackernoon.com/the-case-for-humanities-in-the-era-of-ai-automation-and-technology-310c6a31173f</td>
    </tr>
    <tr>
      <td>Show HN: I'm 12, learning JS, and wrote Wolfram's cellular automaton in Node</td>
      <td>HackerNews</td>
      <td>2018-08-29</td>
      <td>Points: 1072, Comments: 283</td>
      <td>https://bitbucket.org/liamilan/wolfram-cellular-automata</td>
    </tr>
    <tr>
      <td>Designing a Future for AI and Automation That We Can Live With</td>
      <td>HackerNews</td>
      <td>2018-08-24</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://medium.com/@caseorganic/collaborators-not-colonizers-designing-a-future-for-ai-automation-that-we-can-live-with-794814546e1e</td>
    </tr>
    <tr>
      <td>Big Four Firm EY Buys LPO, to Leverage AI/Automation</td>
      <td>HackerNews</td>
      <td>2018-08-07</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://www.artificiallawyer.com/2018/08/07/big-four-firm-ey-buys-legal-innovator-riverview-law/</td>
    </tr>
    <tr>
      <td>Mark Zuckerberg and his empire of oily rags</td>
      <td>HackerNews</td>
      <td>2018-07-06</td>
      <td>Points: 417, Comments: 232</td>
      <td>https://craphound.com/news/2018/07/02/mark-zuckerberg-and-his-empire-of-oily-rags/</td>
    </tr>
    <tr>
      <td>Ask HN: What are the things that you have automated in your personal life?</td>
      <td>HackerNews</td>
      <td>2018-06-24</td>
      <td>Points: 897, Comments: 731</td>
      <td>https://news.ycombinator.com/item?id=17385291</td>
    </tr>
    <tr>
      <td>AI and Automation in the Logistic Systems</td>
      <td>HackerNews</td>
      <td>2018-03-04</td>
      <td>Points: 1, Comments: 0</td>
      <td>https://hackernoon.com/ai-and-automation-in-the-logistic-systems-c07b6e7ed39b?source</td>
    </tr>
    <tr>
      <td>Valve appeals $2.4M fine as Australian legal battle rages on</td>
      <td>HackerNews</td>
      <td>2018-01-25</td>
      <td>Points: 50, Comments: 84</td>
      <td>https://www.gamasutra.com/view/news/313608/Valve_appeals_24M_fine_as_Australian_legal_battle_rages_on.php</td>
    </tr>
    <tr>
      <td>Huawei’s CEO going off-script to rage at US carriers was the best speech of CES</td>
      <td>HackerNews</td>
      <td>2018-01-11</td>
      <td>Points: 127, Comments: 76</td>
      <td>https://www.theverge.com/2018/1/9/16871538/huawei-ces-2018-event-ceo-richard-yu-keynote-speech</td>
    </tr>
    <tr>
      <td>How Raganwald Lost His Crown</td>
      <td>HackerNews</td>
      <td>2017-12-29</td>
      <td>Points: 137, Comments: 47</td>
      <td>http://braythwayt.com/2017/12/29/crown.html</td>
    </tr>
    <tr>
      <td>As epidemic rages, ER study finds opioids no better than Advil and Tylenol</td>
      <td>HackerNews</td>
      <td>2017-11-09</td>
      <td>Points: 186, Comments: 156</td>
      <td>https://arstechnica.com/science/2017/11/as-epidemic-rages-er-study-finds-opioids-no-better-than-advil-and-tylenol/</td>
    </tr>
    <tr>
      <td>Rage Disorder Linked with Toxoplasmosis (2016)</td>
      <td>HackerNews</td>
      <td>2017-10-01</td>
      <td>Points: 223, Comments: 66</td>
      <td>https://www.scientificamerican.com/article/rage-disorder-linked-with-parasite-found-in-cat-feces/</td>
    </tr>
    <tr>
      <td>Serpent.AI – Game Agent Framework in Python</td>
      <td>HackerNews</td>
      <td>2017-09-23</td>
      <td>Points: 86, Comments: 3</td>
      <td>https://github.com/SerpentAI/SerpentAI</td>
    </tr>
    <tr>
      <td>Automation, AI to make many IT jobs obsolete over next 5 years, says survey</td>
      <td>HackerNews</td>
      <td>2017-08-01</td>
      <td>Points: 2, Comments: 0</td>
      <td>http://www.firstpost.com/business/automation-artificial-intelligence-to-make-many-it-jobs-obsolete-over-next-5-years-says-survey-3880133.html</td>
    </tr>
    <tr>
      <td>The Disconnect Between Making America “Great” and the Reality of AI, Automation</td>
      <td>HackerNews</td>
      <td>2017-07-19</td>
      <td>Points: 1, Comments: 0</td>
      <td>http://thefuturedoesnotneedyou.com/2017/07/how-can-we-make-america-great-again-in-the-age-of-ai-automation/</td>
    </tr>
    <tr>
      <td>Measles outbreak rages after anti-vaccine groups target vulnerable community</td>
      <td>HackerNews</td>
      <td>2017-05-06</td>
      <td>Points: 87, Comments: 49</td>
      <td>https://arstechnica.com/science/2017/05/measles-outbreak-rages-after-anti-vaccine-groups-target-vulnerable-community/</td>
    </tr>
    <tr>
      <td>AI and Automation by the Numbers: Predictions, Perceptions, and Proposals</td>
      <td>HackerNews</td>
      <td>2017-04-18</td>
      <td>Points: 1, Comments: 1</td>
      <td>https://www.forbes.com/sites/gilpress/2017/03/30/ai-and-automation-by-the-numbers-predictions-perceptions-and-proposals/#1676bfdf2bb3</td>
    </tr>
    <tr>
      <td>How to Prepare a Career for AI-Driven Automation</td>
      <td>HackerNews</td>
      <td>2017-04-05</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://machinelearnings.co/how-to-prepare-your-career-for-artificial-intelligence-driven-automation-1bb153759b3b</td>
    </tr>
    <tr>
      <td>Raganwald's Tooling for Turing Machines</td>
      <td>HackerNews</td>
      <td>2017-04-01</td>
      <td>Points: 62, Comments: 18</td>
      <td>https://leanpub.com/tooling</td>
    </tr>
    <tr>
      <td>Changes to Ragel in Response to the CloudFlare Incident</td>
      <td>HackerNews</td>
      <td>2017-03-06</td>
      <td>Points: 84, Comments: 30</td>
      <td>https://www.colm.net/news/2017/02/28/changes-to-ragel-cloudflare.html</td>
    </tr>
    <tr>
      <td>Ragic – Editable forms with relational data</td>
      <td>HackerNews</td>
      <td>2017-02-25</td>
      <td>Points: 94, Comments: 37</td>
      <td>http://www.ragic.com</td>
    </tr>
    <tr>
      <td>AI and automation are about to implode blue collar jobs</td>
      <td>HackerNews</td>
      <td>2017-02-21</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://theoutline.com/post/1120/ai-and-automation-are-about-to-implode-us-blue-collar-jobs-trump-has-no-plan</td>
    </tr>
    <tr>
      <td>AutoGitHub (Automatically follow a lot of GitHub users)</td>
      <td>HackerNews</td>
      <td>2016-12-28</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://github.com/yfgeek/AutoGithub</td>
    </tr>
    <tr>
      <td>Ask HN: What will be the effects of the upcoming rise of AI and Automation?</td>
      <td>HackerNews</td>
      <td>2016-09-11</td>
      <td>I feel like we are living in a tipping point of human history. The rise of automation and AI will make our lives easier. We will finally be able to get rid of all the &amp;quot;useless&amp;quot; tasks we have to do.&lt;p&gt;However, my main concern is with ecomonical and sociological effects of this?&lt;p&gt;Will world GDP finally contract because of drastic reduction in cost of everything made?&lt;p&gt;Will joblessness become a norm and people can easily live off without working since humanity will finally be afford to</td>
      <td>https://news.ycombinator.com/item?id=12471490</td>
    </tr>
    <tr>
      <td>AI, automation and the merry-go-round of the mind</td>
      <td>HackerNews</td>
      <td>2016-06-24</td>
      <td>Points: 3, Comments: 0</td>
      <td>https://forrestbrazeal.com/2016/06/23/ai-automation-and-the-merry-go-round-of-the-mind/</td>
    </tr>
    <tr>
      <td>U.S. Congress Discusses AI, Automation, Robotics and Basic Income</td>
      <td>HackerNews</td>
      <td>2016-05-29</td>
      <td>Points: 2, Comments: 0</td>
      <td>https://www.youtube.com/watch?v=OX06f3DPXt4</td>
    </tr>
    <tr>
      <td>Rage Against the Finite-State Machines</td>
      <td>HackerNews</td>
      <td>2016-04-02</td>
      <td>Points: 153, Comments: 54</td>
      <td>http://learnyousomeerlang.com/finite-state-machines</td>
    </tr>
    <tr>
      <td>Cosmonaut Crashed into Earth 'Crying in Rage' (2011)</td>
      <td>HackerNews</td>
      <td>2016-02-10</td>
      <td>Points: 110, Comments: 63</td>
      <td>http://www.npr.org/sections/krulwich/2011/05/02/134597833/cosmonaut-crashed-into-earth-crying-in-rage</td>
    </tr>
    <tr>
      <td>Robotics, AI and automation in “Forbes 30 under 30″</td>
      <td>HackerNews</td>
      <td>2016-01-26</td>
      <td>Points: 4, Comments: 0</td>
      <td>http://robohub.org/robotics-ai-and-automation-in-forbes-30-under-30/</td>
    </tr>
    <tr>
      <td>Ragel State Machine Compiler</td>
      <td>HackerNews</td>
      <td>2015-11-15</td>
      <td>Points: 49, Comments: 21</td>
      <td>https://www.colm.net/open-source/ragel/</td>
    </tr>
    <tr>
      <td>ZPM Espresso and the Rage of the Jilted Crowdfunder</td>
      <td>HackerNews</td>
      <td>2015-04-30</td>
      <td>Points: 62, Comments: 23</td>
      <td>http://www.nytimes.com/2015/05/03/magazine/zpm-espresso-and-the-rage-of-the-jilted-crowdfunder.html</td>
    </tr>
    <tr>
      <td>Economics Panel on AI, Automation, and the Future of Work (UCSB Economics Summit)</td>
      <td>HackerNews</td>
      <td>2014-10-09</td>
      <td>Points: 2, Comments: 0</td>
      <td>http://www.econtalk.org/archives/2014/06/mcafee_mcardle.html</td>
    </tr>
    <tr>
      <td>The Twin Prime Hero: Rags, Riches, and Fame in Mathematics (2013)</td>
      <td>HackerNews</td>
      <td>2014-09-17</td>
      <td>Points: 60, Comments: 5</td>
      <td>http://nautil.us/issue/5/fame/the-twin-prime-hero</td>
    </tr>
    <tr>
      <td>Ragnarok MMO open-source HTML5 client</td>
      <td>HackerNews</td>
      <td>2014-09-09</td>
      <td>Points: 176, Comments: 52</td>
      <td>https://github.com/vthibault/roBrowser#</td>
    </tr>
    <tr>
      <td>Should I study towards a MD/PhD in light of advances in AI/robotics/automation?</td>
      <td>HackerNews</td>
      <td>2014-08-11</td>
      <td>I&amp;#x27;m considering becoming a radiation oncologist. Specifically, I would like to do a BSc in Electrical Engineering plus pre-med, followed by a joint MD&amp;#x2F;PhD (EE) degree. A BSc takes four years, and MD&amp;#x2F;PhD programs take an average of 7-8 years. On top of that there is a one year internship and a residency requirement of at least five years. All in all, it would take me 18 years to get to my dream job; even if I did away with the PhD and only went for a regular MD, it would still take</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>The Rage of the Mechwarrior Online Community (2013)</td>
      <td>HackerNews</td>
      <td>2014-06-26</td>
      <td>Points: 71, Comments: 39</td>
      <td>http://www.gamefront.com/mechwarrior-online-forum-ragesplosion/1/</td>
    </tr>
    <tr>
      <td>Fighting Fire with Fire</td>
      <td>HackerNews</td>
      <td>2014-05-29</td>
      <td>Points: 1, Comments: 0</td>
      <td>http://blog.pmarca.com/2010/08/24/fighting-fire-with-fire/</td>
    </tr>
    <tr>
      <td>What is Docker and When to Use It</td>
      <td>HackerNews</td>
      <td>2014-05-16</td>
      <td>Points: 5, Comments: 4</td>
      <td>http://www.centurylinklabs.com/what-is-docker-and-when-to-use-it/</td>
    </tr>
    <tr>
      <td>Growing Pains (2010)</td>
      <td>HackerNews</td>
      <td>2014-03-27</td>
      <td>Points: 2, Comments: 0</td>
      <td>http://blog.pmarca.com/2010/08/02/growing-pains/</td>
    </tr>
    <tr>
      <td>The Rags-To-Riches Tale Of How Jan Koum Built WhatsApp</td>
      <td>HackerNews</td>
      <td>2014-02-20</td>
      <td>Points: 59, Comments: 20</td>
      <td>http://www.forbes.com/sites/parmyolson/2014/02/19/exclusive-inside-story-how-jan-koum-built-whatsapp-into-facebooks-new-19-billion-baby</td>
    </tr>
    <tr>
      <td>Raganwald quits Hacker News</td>
      <td>HackerNews</td>
      <td>2014-02-17</td>
      <td>Points: 45, Comments: 32</td>
      <td>https://twitter.com/raganwald/status/435443764572598272</td>
    </tr>
    <tr>
      <td>Autogit - Automatic git checkins from your text editor saves</td>
      <td>HackerNews</td>
      <td>2013-09-23</td>
      <td>Points: 3, Comments: 1</td>
      <td>https://coderbits.com/posts/zAZyMg</td>
    </tr>
    <tr>
      <td>The End of Ragequitting</td>
      <td>HackerNews</td>
      <td>2013-01-21</td>
      <td>Points: 250, Comments: 96</td>
      <td>http://www.codinghorror.com/blog/2013/01/the-end-of-ragequitting.html</td>
    </tr>
    <tr>
      <td>Raganwald's Nifty Fifty</td>
      <td>HackerNews</td>
      <td>2012-06-14</td>
      <td>Points: 101, Comments: 28</td>
      <td>http://raganwald.posterous.com/raganwalds-nifty-fifty</td>
    </tr>
    <tr>
      <td>Everything's Made Up and The Points Don't Matter - raganwald's posterous</td>
      <td>HackerNews</td>
      <td>2012-04-03</td>
      <td>Points: 91, Comments: 41</td>
      <td>http://raganwald.posterous.com/everythings-made-up-and-the-points-dont-matte</td>
    </tr>
    <tr>
      <td>Yahoo Labs head Prabhakar Raghavan leaves (and joins Google)</td>
      <td>HackerNews</td>
      <td>2012-03-05</td>
      <td>Points: 78, Comments: 9</td>
      <td>http://allthingsd.com/20120304/exclusive-yahoo-labs-head-raghavan-departing-to-google/?mod=tweet</td>
    </tr>
    <tr>
      <td>Raganwald's "How to Do What You Love" is free today</td>
      <td>HackerNews</td>
      <td>2012-02-28</td>
      <td>Points: 203, Comments: 82</td>
      <td>http://leanpub.com/dowhatyoulove</td>
    </tr>
    <tr>
      <td>IOS RAGE rendered with WebGL</td>
      <td>HackerNews</td>
      <td>2011-05-16</td>
      <td>Points: 154, Comments: 10</td>
      <td>http://blog.tojicode.com/2011/05/ios-rage-rendered-with-webgl.html</td>
    </tr>
    <tr>
      <td>Cosmonaut Crashed Into Earth 'Crying In Rage' [in 1967]</td>
      <td>HackerNews</td>
      <td>2011-03-19</td>
      <td>Points: 339, Comments: 62</td>
      <td>http://www.npr.org/blogs/krulwich/2011/03/18/134597833/cosmonaut-crashed-into-earth-crying-in-rage?ft=1&amp;f=1026</td>
    </tr>
    <tr>
      <td>The perils of walking slow: scientists analyze sidewalk rage</td>
      <td>HackerNews</td>
      <td>2011-02-15</td>
      <td>Points: 43, Comments: 63</td>
      <td>http://online.wsj.com/article/SB10001424052748703786804576138261177599114.html?mod=WSJ_LifeStyle_LeadStoryNA</td>
    </tr>
    <tr>
      <td>John Carmack talks about Rage SD and HD, iOS, and what's next for iOS gaming</td>
      <td>HackerNews</td>
      <td>2010-11-19</td>
      <td>Points: 67, Comments: 22</td>
      <td>http://www.tuaw.com/2010/11/19/john-carmack-talks-about-rage-sd-and-hd-ios-and-whats-next-fo/</td>
    </tr>
    <tr>
      <td>Rage for iPhone</td>
      <td>HackerNews</td>
      <td>2010-11-09</td>
      <td>Points: 54, Comments: 13</td>
      <td>http://www.engadget.com/2010/08/12/carmack-blows-minds-with-id-softwares-rage-running-on-iphone-a/</td>
    </tr>
    <tr>
      <td>Dev Diary: John Carmack on RAGE for iOS</td>
      <td>HackerNews</td>
      <td>2010-10-29</td>
      <td>Points: 94, Comments: 38</td>
      <td>http://bethblog.com/index.php/2010/10/29/john-carmack-discusses-rage-on-iphoneipadipod-touch/</td>
    </tr>
    <tr>
      <td>Tell HN: Read Maxim and other trashy "guy" rags.</td>
      <td>HackerNews</td>
      <td>2010-10-03</td>
      <td>I went out to get a haircut today and had a chance to scan through crap magazines before my appointment.&lt;p&gt;Extremely worthwhile.&lt;p&gt;Anybody who is out of business ideas, specially "social apps" will do well consuming that garbage from time to time. It's simply full of insight into the mindset of a sizable segment of society. The ads within the pages are full of hints on what works.&lt;p&gt;I had a short stint as a reseller for luxury motorcycles, and I am 100% certain that my business would have benefi</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Finger-Pointing, Emails, Deleted Tweets, Rage. AngelGate Is Far From Over</td>
      <td>HackerNews</td>
      <td>2010-09-24</td>
      <td>Points: 118, Comments: 46</td>
      <td>http://techcrunch.com/2010/09/23/angelgate/?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+Techcrunch+%28TechCrunch%29&amp;utm_content=FaceBook</td>
    </tr>
    <tr>
      <td>John Carmack demos Rage on iPhone</td>
      <td>HackerNews</td>
      <td>2010-08-12</td>
      <td>Points: 206, Comments: 69</td>
      <td>http://kotaku.com/5611523/id-unleashes-rage-on-the-iphone</td>
    </tr>
    <tr>
      <td>Facebook 1: 0 Simon Cowell - Rage Against The Machine is UK #1 single for Xmas</td>
      <td>HackerNews</td>
      <td>2009-12-20</td>
      <td>Points: 59, Comments: 40</td>
      <td>http://www.sheamus.co.uk/ratm-xmas-number-one</td>
    </tr>
    <tr>
      <td>High Anxiety (raganwald on Go and learning new things)</td>
      <td>HackerNews</td>
      <td>2009-10-27</td>
      <td>Points: 69, Comments: 46</td>
      <td>http://github.com/raganwald/homoiconic/blob/master/2009-10-20/high_anxiety.md#readme</td>
    </tr>
    <tr>
      <td>"Unholy Rage": Eve Online bans 2% of accounts, sees 30% drop in CPU use</td>
      <td>HackerNews</td>
      <td>2009-08-23</td>
      <td>Points: 92, Comments: 31</td>
      <td>http://www.eveonline.com/devblog.asp?a=blog&amp;bid=687</td>
    </tr>
    <tr>
      <td>Don't just howl with rage. Try an idea that does away with banks altogether.</td>
      <td>HackerNews</td>
      <td>2009-08-19</td>
      <td>Points: 44, Comments: 26</td>
      <td>http://www.guardian.co.uk/commentisfree/2009/aug/18/bankers-bonuses-credit-zopa</td>
    </tr>
    <tr>
      <td>Ragel State Charts</td>
      <td>HackerNews</td>
      <td>2009-07-01</td>
      <td>Points: 67, Comments: 30</td>
      <td>http://www.zedshaw.com/essays/ragel_state_charts.html</td>
    </tr>
  </tbody>
</table>